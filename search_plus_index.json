{"./":{"url":"./","title":"示例","keywords":"","body":"OS课程练习 这里的习题用于清华大学计算机系2021年春季课程练习。 这里包括从互联网上搜集的操作系统课程相关习题和答案，包括部分考研试题，版权属于各出题单位或个人。由清华大学OS课的老师和助教撰写的习题和答案的文档版权属于清华大学，并采用 Creative Commons Attribution/Share-Alike (CC-BY-SA) License. OS习题集采用gitbook ## install sudo npm install -g gitbook-cli cd THIS-DIR gitbook install; ## publish gitbook serve; ... Starting server ... Serving book on http://localhost:4000 ## view contents netbrowser(firefox, chrome...) http://localhost:4000 的方式展现，可进行在线交互式答题。 下面是gitbook提供的试题编写的例子： mcqx test1 This is a question?\\n\",\"count\":4,\"id\":\"9b966c7bda4e8e14198714777a25f70e77adb7d7\"}\" data-id=\"9b966c7bda4e8e14198714777a25f70e77adb7d7\" class=\"mcqBox gitQuestion\">This is a question? A. B. C. D. Submit mcqx test2 This is a question?\\n\",\"hint\":\"This is a hint.\",\"count\":2,\"id\":\"6d819ae6fd26ae11217df08eb4166d581be1bc45\"}\" data-id=\"6d819ae6fd26ae11217df08eb4166d581be1bc45\" class=\"mcqBox gitQuestion\">This is a question? A. B. SubmitHint mcqx test3 This is a question?\\n\",\"count\":2,\"id\":\"16bbf41c732a5dcd8647373244bf9412de81907c\"}\" data-id=\"16bbf41c732a5dcd8647373244bf9412de81907c\" class=\"mcqBox gitQuestion\">This is a question? A. B. Submit mcqx test4 This is a question?\\n\",\"count\":4,\"id\":\"f7dfa916ea3bb0a57f768d7761ccf8cb264be3c9\"}\" data-id=\"f7dfa916ea3bb0a57f768d7761ccf8cb264be3c9\" class=\"mcqBox gitQuestion\">This is a question? A. B. C. D. Submit mcqx test5 spoiler test6 This is a spoiler: Hello World. fbq test7 Testing. Please type (hello) and (world).SubmitCorrect. quiz test8 What is gitbook used for? To read books To book hotel named git To write and publish beautiful books GitBook.com lets you write, publish and manage your books online as a service. Is it quiz? Yes No This is multiple dropdown quiz, in each dropdown select a correct number corresponding to the dropdown's order First Second Third Fourth First Second Third Fourth First Second Third Fourth First Second Third Fourth "},"all/1-intro.html":{"url":"all/1-intro.html","title":"操作系统概述","keywords":"","body":"操作系统概述 单选题 （华中科技大学，2005）程序正在试图读取某个磁盘的第100个逻辑块，使用操作系统提供的（ ）接口 [x] 系统调用 [ ] 图形用户 [ ] 原语 [ ] 键盘命令 操作系统作为用户和计算机硬件系统之间的接口，用户可以通过3种方式使用计算机，命令方式、系统调用方式、图形方式。系统调用按照功能分为进程管理、文件操作、设备管理等，本题描述的是文件操作系统调用相关的执行。 (2009计算机统考)单处理器系统中，可并行的是（ ） 1)进程与进程 2)处理器与设备 3)处理器与通道 4)设备与设备 [ ] 1 2 3 [ ] 1 2 4 [ ] 1 3 4 [x] 2 3 4 并行指同一时刻同时发生，同一时刻单个处理器只能运行一个进程。 (2010统考）下列选项中，操作系统提供给应用程序的接口是（ ） [x] 系统调用 [ ] 中断 [ ] 库函数 [ ] 原语 解释：略 (2011统考)下列选项中，在用户态执行的是（ ） [x] 命令解释程序 [ ] 缺页处理程序 [ ] 进程调度程序 [ ] 时钟中断处理程序 后3个选项都属于内核的功能，在内核态。命令解释程序则属于应用程序。 (2013联考)计算机开机后，操作系统最终被加载到（ ） [ ] BIOS [ ] ROM [ ] EPROM [x] RAM 操作系统被加载到内存（RAM）中 操作系统属于__（单选） [ ] 硬件 [x] 系统软件 [ ] 通用库 [ ] 应用软件 操作系统是管理计算机硬件与软件资源的计算机程序，例如Windows，Linux，Android，iOS等。应用软件一般是基于操作系统提供的接口，为针对使用者的某种应用目的所撰写的软件，例如Office Word，浏览器，手机游戏等。而通用库，一般是指为了便于程序开发，对常用的程序功能封装后被调用的程序。 以ucore OS为例，它通过I/O子系统和各种驱动程序直接控制时钟，串口，显示器等计算机硬件外设，并通过系统调用接口给在其上运行的应用软件提供服务，并通过进程管理子系统、CPU调度器、内存管理子系统、文件子系统、I/O子系统来管理应用软件的运行和实现具体的服务。 以下哪个不能用于描述操作系统（单选） [ ] 使计算机方便使用 [ ] 可以管理计算机硬件 [x] 可以控制应用软件的执行 [ ] 负责生成应用软件 解释：操作系统负责管理计算机的硬件资源，使得用户不需要关心硬件的工作过程，极大地方便了计算机的使用。我们日常使用计算机，往往已经在使用了特定的操作系统，例如Windows，而在操作系统上，会同时运行多个应用软件，例如浏览器，音乐播放器等，为了让一个或者多个软件能够正常使用有限的硬件资源，操作系统需要管理应用程序的执行过程。一般来说，像浏览器，音乐播放器，和其他应用软件，都是由特定的个人和团队开发的，操作系统不负责生成应用软件。 以ucore OS开发为例，有了ucore OS，应用软件访问硬件跟简单了，有统一的文件访问方式来访问磁盘或各种外设。ucore OS 可以通过I/O操作控制硬件和应用软件的运行等。但编写软件是程序员的工作，把基于C语言或汇编语言的程序转换并生成执行代码是编译器（如gcc,gas）、连接器(如link)的工作。操作系统可加载运行应用软件的执行代码。 以下不属于操作系统的功能是（） [ ] 进程调度 [ ] 内存管理 [x] 视频编辑 [ ] 设备驱动 解释：视频编辑是一个特定的功能，不是系统范围内的共性需求，具体完成这个功能的是视频编辑应用软件。当然，视频编辑应用软件在涉及文件访问时，是需要操作系统中的文件子系统支持；在涉及视频显示方面，需要操作系统的显卡/GPU等设备驱动支持。 操作系统中的多道程序设计方式用于提高__（单选） [ ] 稳定性 [x] 效率 [ ] 兼容性 [ ] 可靠性 解释：是在计算机内存中同时存放几道相互独立的程序，使它们在管理程序（早期的操作系统）控制之下，相互穿插的运行。两个或两个以上程序在计算机系统中同处于开始到结束之间的状态（这里用进程来表示，在后续课程中会讲解“进程管理”）。这样可以使得几道独立的程序可以并发地共同使用各项硬件资源，提高了资源的利用率。 以ucore OS为例，在lab5中支持了用户进程，从而可以在内存中存放多个程序，并以进程的方式被操作系统管理和调度。 下面对于分时操作系统的说法，正确的是（） [ ] 应用程序执行的先后顺序是完全随机的 [ ] 应用程序按照启动的时间依次执行 [x] 应用程序可以交替执行 [ ] 应用程序等待的时间越长，下一次调度被选中的概率一定越大 解释：选择3更合适。分时操作系统把多个程序放到内存中，将处理机（CPU）时间按一定的时间间隔（简称时间片）分配给程序运行，这样CPU就可以轮流地切换给各终端用户的交互式程序使用。由于时间片很短，远小于用户的交互响应延迟，用户感觉上好像独占了这个计算机系统。应用程序执行的先后顺序主要是由操作系统的调度算法和应用程序本身的行为特征来确定的。调度算法需要考虑系统的效率、公平性等因素。对于1,2而言，从系统的效率上看不会带来好处；对于4而言，可以照顾到公平性，但“一定”的表述太强了，比如如果调度算法是简单的时间片轮转算法（在后续章节“处理器调度”），则4的要求就不会满足了，且更实际的调度算法其实还需考虑等待的事件等诸多因素。 以ucore OS为例，在lab6中支持实现不同的调度算法。对于分时操作系统而言，体现其特征的一个关键点就是要实现时间片轮转调度算法或多级反馈队列调度算法（在后续章节“处理器调度”）。在ucore OS中，可以比较方便地实现这两种调度算法。 Unix操作系统属于__() [x] 分时操作系统 [ ] 批处理操作系统 [ ] 实时操作系统 [ ] 分布式操作系统 解释：选择1更合适。Unix操作系统支持交互式应用程序，属于分时操作系统。比早期的批处理操作系统要强大。且它更多地面向桌面和服务器领域，并没有很强的实时调度和实时处理功能，所以一边不划归为实时系统。它虽然有网络支持（如TCP/IP），但实际上它管理的主要还是单个计算机系统让的硬件和应用软件。 以ucore OS为例，它模仿的是Unix操作系统，实现了对应的分时调度算法（时间片轮转、多级反馈队列），所以也算是分时系统。如果ucore实现了实时进程管理、实时调度算法，并支持在内核中的抢占（preempt in kernel），则可以说它也是一个实时系统了。 批处理的主要缺点是__() [ ] 效率低 [x] 失去了交互性 [ ] 失去了并行性 [ ] 以上都不是 解释：批处理操作系统没有考虑人机交互所需要的分时功能，所以开发人员或操作人员无法及时与计算机进行交互。 以ucore OS为例，如果它实现的调度算法是先来先服务调度算法（在后续章节“处理器调度”，相对其他调度算法，具体实现更简单），那它就是一种批处理操作系统了，没有很好的人机交互能力。 多选题 关于操作系统，说法正确的是（） [x] 操作系统属于软件 [x] 操作系统负责资源管理 [x] 操作系统使计算机的使用更加方便 [ ] 操作系统必须要有用户程序才能正常启动 操作系统是一种软件，特定指是系统软件，其更功能是管理计算机资源，让用户和应用程序更方便高效地使用计算机。 以ucore OS为例，其实没有用户程序，操作系统也可以正常运行。所以选项4是部队的。 设备管理的功能包括__（） [x] 设备的分配和回收 [ ] 进程调度 [x] 虚拟设备的实现 [x] 外围设备启动 进程调度是属于操作系统的进程管理和处理器调度子系统要完成的工作，与设备管理没有直接关系 以ucore OS为例（lab5以后的实验），与进程调度相关的实现位于kern/process和kern/schedule目录下；与设备管理相关的实现主要位于kern/driver目录下 多道批处理系统主要考虑的是__() [ ] 交互性 [ ] 及时性 [x] 系统效率 [x] 吞吐量 解释：交互性和及时性是分时系统的主要特征。多道批处理系统主要考虑的是系统效率和系统的吞吐量。 以ucore OS为例（lab6实验）,这主要看你如何设计调度策略了，所以如果实现FCFS(先来想服务)调度算法，这可以更好地为多道批处理系统服务；如果实现时间片轮转（time-slice round robin）调度算法，则可以有比较好的交互性；如果采用多级反馈队列调度算法，则可以兼顾上述4个选项，但交互性用户程序获得CPU的优先级更高。 "},"all/01-2-spoc-discussion.html":{"url":"all/01-2-spoc-discussion.html","title":"lec1 SPOC讨论","keywords":"","body":"lec1: 操作系统概述 提前准备 （请在上课前完成） 完成lec1的视频学习和提交对应的在线练习 git pull ucore_os_lab, ucore_os_docs, os_tutorial_lab, os_course_exercises in github repos。这样可以在本机上完成课堂练习。 知道OS课程的入口网址，会使用在线视频平台，在线练习/实验平台，在线提问平台(piazza) http://os.cs.tsinghua.edu.cn/oscourse/OS2019spring 会使用linux shell命令，如ls, rm, mkdir, cat, less, more, gcc等，也会使用linux系统的基本操作。 在piazza上就学习中不理解问题进行提问。 思考题 填空题 当前常见的操作系统主要用__编程语言编写。 \"Operating system\"这个单词起源于__ 。 在计算机系统中，控制和管理 、有效地组织运行的系统软件称作__ 。 允许多用户将若干个作业提交给计算机系统集中处理的操作系统称为__操作系统 你了解的当前世界上使用最多的操作系统是__ 。 应用程序通过__接口获得操作系统的服务。 现代操作系统的特征包括 ， ， ， 。 操作系统内核的架构包括 ， ， __ 。 问答题 请总结你认为操作系统应该具有的特征有什么？并对其特征进行简要阐述。 为什么现在的操作系统基本上用C语言来实现？为什么没有人用python，java来实现操作系统？ 可选练习题 请分析并理解v9-computer以及模拟v9-computer的em.c。理解：在v9-computer中如何实现时钟中断的；v9 computer的CPU指令，关键变量描述有误或不全的情况；在v9-computer中的跳转相关操作是如何实现的；在v9-computer中如何设计相应指令，可有效实现函数调用与返回；OS程序被加载到内存的哪个位置,其堆栈是如何设置的；在v9-computer中如何完成一次内存地址的读写的；在v9-computer中如何实现分页机制。 请编写一个小程序，在v9-cpu下，能够输出字符 输入的字符并输出你输入的字符 请编写一个小程序，在v9-cpu下，能够产生各种异常/中断 请编写一个小程序，在v9-cpu下，能够统计并显示内存大小 请分析并理解RISC-V CPU以及会使用模拟RISC-V(简称RV)的qemu工具。理解：RV的特权指令，CSR寄存器和在RV中如何实现时钟中断和IO操作；OS程序如何被加载运行的；在RV中如何实现分页机制。 请编写一个小程序，在RV下，能够输出字符 输入的字符并输出你输入的字符 请编写一个小程序，在RV下，能够产生各种异常/中断 请编写一个小程序，在RV下，能够统计并显示内存大小 参考资料 www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html) v9 cpu architecture RISC-V cpu architecture OS相关经典论文 "},"all/01-3-lab0-quiz.html":{"url":"all/01-3-lab0-quiz.html","title":"lec2在线练习","keywords":"","body":"Lec2 在线练习 单选题 清华大学目前的操作系统实验中采用的OS对象是() [ ] Linux [ ] ucore/rcore [ ] xv6 [ ] Nachos 是参考了xv6, OS161, Linux的教学操作系统ucore/rcore OS 在ucore/rcore lab的实验环境搭建中，用来模拟x86-32 or RISC-V 64的软件是() [ ] apt [ ] git [ ] meld [ ] qemu qemu是一个支持模拟多种CPU的模拟软件 多选题 RISC-V CPU有多种特权模式，rcore lab中碰到和需要处理哪些特权模式() [x] M-mode [x] S-mode [ ] H-mode [x] U-mode rcore需要碰到和处理M/S/U-mode "},"all/01-3-lab0-spoc-discussion.html":{"url":"all/01-3-lab0-spoc-discussion.html","title":"lec2SPOC讨论","keywords":"","body":"lec2：SPOC思考题 提前准备 （请在上课前完成，option） 完成lec2的视频学习 了解代码段，数据段，执行文件，执行文件格式，堆，栈，控制流，函数调用,函数参数传递，用户态（用户模式），内核态（内核模式）等基本概念。思考一下这些基本概念在不同操作系统（如linux, ucore,etc.)与不同硬件（如 x86, riscv, v9-cpu,etc.)中是如何相互配合来体现的。 安装好ucore/rcore实验环境，能够编译运行ucore/rcore labs中的源码。 会使用实验中的常用的工具和命令: objdump，nm，file, strace，gcc, gdb等，了解这些命令的用途。 思考题 你理解的对于类似ucore这样需要进程/虚存/文件系统的操作系统，在硬件设计上至少需要有哪些直接的支持？至少应该提供哪些功能的特权指令？ 你理解的risc-v的特权模式有什么区别？不同 模式在地址访问方面有何特征？ 课堂实践练习 练习一 (option)请在rcore中找一段你认为难度适当的RV汇编代码，尝试解释其含义。 练习二 宏定义和引用在内核代码中很常用。请枚举ucore或rcore中宏定义的用途，并举例描述其含义。 问答题 Q1：应用程序能直接调用内核的函数吗？说明原因，举个例子。 A： Q2：内核能直接调用应用程序的函数吗？说明原因，举个例子。 A： Q3：请说出你知道的特权指令或特权寄存器（x86/arm/mips/risc-v） A: Q4: 除了基于页表的地址空间隔离，请问还能想到其他的地址空间隔离方式吗？ A： Q5：中断/异常有何区别？如果没有中断机制，应用程序/操作系统要如何与外设进行交互？ A： Q6：你是如何理解和描述OS与APP的交互接口？ A： Q7：你是如何理解和描述OS与CPU的交互接口？ A： Q8：我们理解的RISC-V的Supervisor特权模式适合运行哪种类型的软件？ A: Q9: 如果让一个通用操作系统（如Linux）运行在RISC-V的User模式，请问会发生什么现象？是否有相应的解决方法？ A： Q10：RISC-V的中断产生后，CPU首先会在哪种特权模式下运行？ A： Q11：根据课程介绍，安装qemu-RV64 v5.0+，通过qemu的monitor，查看ROM的指令是哪些？ A：https://rcore-os.github.io/rCore_tutorial_doc/chapter2/part5.html 参考资料 v9 cpu architecture RISC-V cpu architecture OS相关经典论文 "},"all/2-intr.html":{"url":"all/2-intr.html","title":"中断、异常和系统调用","keywords":"","body":"中断、异常和系统调用 单选题 (西北工业大学)CPU执行操作系统代码的时候称为处理机处于（ ） [ ] 自由态 [ ] 目态 [x] 管态 [ ] 就绪态 （知识点：3.4系统调用）内核态又称为管态 (2012统考)下列选项中，不可能在用户态发生的是（ ） [ ] 系统调用 [ ] 外部中断 [x] 进程切换 [ ] 缺页 （知识点：3.3中断、异常和系统调用比较）系统调用是提供给应用程序使用的，由用户态发出，进入内核态执行。外部中断随时可能发生；应用程序执行时可能发生缺页；进程切换完全由内核来控制。 （2012统考）中断处理和子程序调用都需要压栈以保护现场。中断处理一定会保存而子程序调用不需要保存其内容的是（ ） [ ] 程序计数器 [x] 程序状态字寄存器 [ ] 通用数据寄存器 [ ] 通用地址寄存器 （知识点：3.3中断、异常和系统调用比较）程序状态字（PSW）寄存器用于记录当前处理器的状态和控制指令的执行顺序，并且保留与运行程序相关的各种信息，主要作用是实现程序状态的保护和恢复。所以中断处理程序要将PSW保存，子程序调用在进程内部执行，不会更改PSW。 （2013统考）下列选项中，会导致用户进程从用户态切换到内核态的操作是（ ） 1）整数除以0 2）sin()函数调用 3）read系统调用 [ ] 1、2 [x] 1、3 [ ] 2、3 [ ] 1、2、3 （知识点：3.4系统调用）函数调用并不会切换到内核态，而除零操作引发中断，中断和系统调用都会切换到内核态进行相应处理。 （华中科技大学）中断向量地址是（ ） [ ] 子程序入口地址 [ ] 中断服务例程入口地址 [x] 中断服务例程入口地址的地址 [ ] 例行程序入口地址 （知识点：3.3中断、异常和系统调用比较） 中断向量地址，即存储中断向量的存储单元地址，中断服务例行程序入口地址的地址。 下列选项中， __可以执行特权指令？() [x] 中断处理例程 [ ] 普通用户的程序 [ ] 通用库函数 [ ] 管理员用户的程序 （知识点：3.3中断、异常和系统调用比较）中断处理例程（也可称为中断处理程序）需要执行打开中断，关闭中断等特权指令，而这些指令只能在内核态下才能正确执行，所以中断处理例程位于操作系统内核中。而1,3,4都属于用户程序和用于用户程序的程序库。 一般来讲，中断来源于__（） [x] 外部设备 [ ] 应用程序主动行为 [ ] 操作系统主动行为 [ ] 软件故障 （知识点：3.3中断、异常和系统调用比较）中断来源与外部设备，外部设备通过中断来通知CPU与外设相关的各种事件。第2选项如表示是应用程序向操作系统发出的主动行为，应该算是系统调用请求。第4选项说的软件故障也可称为软件异常，比如除零錯等。 系统调用的主要作用是（） [ ] 处理硬件问题 [ ] 应对软件异常 [x] 给应用程序提供服务接口 [ ] 管理应用程序 （知识点：3.4系统调用）应用程序一般无法直接访问硬件，也无法执行特权指令。所以，需要通过操作系统来间接完成相关的工作。而基于安全和可靠性的需求，应用程序运行在用户态，操作系统内核运行在内核态，导致应用程序无法通过函数调用来访问操作系统提供的各种服务，于是通过系统调用的方式就成了应用程序向OS发出请求并获得服务反馈的唯一通道和接口。 用户程序通过__向操作系统提出访问外部设备的请求（） [ ] I/O指令 [x] 系统调用 [ ] 中断 [ ] 创建新的进程 （知识点：3.3中断、异常和系统调用比较）具体内容可参见10.的回答。 应用程序引发异常的时候，操作系统可能的反应是（） [ ] 删除磁盘上的应用程序 [ ] 重启应用程序 [x] 杀死应用程序 [ ] 修复应用程序中的错误 （知识点：3.3中断、异常和系统调用比较）更合适的答案是3。因为应用程序发生异常说明应用程序有错误或bug，如果应用程序无法应对这样的错误，这时再进一步执行应用程序意义不大。如果应用程序可以应对这样的错误（比如基于当前c++或java的提供的异常处理机制，或者基于操作系统的信号（signal）机制（后续章节“进程间通信”会涉及）），则操作系统会让应用程序转到应用程序的对应处理函数来完成后续的修补工作。 下列关于系统调用的说法错误的是（） [ ] 系统调用一般有对应的库函数 [x] 应用程序可以不通过系统调用来直接获得操作系统的服务 [ ] 应用程序一般使用更高层的库函数而不是直接使用系统调用 [ ] 系统调用可能执行失败 （知识点：3.4系统调用）更合适的答案是2。根据对当前操作系统设计与实现的理解，系统调用是应用程序向操作系统发出服务请求并获得操作系统服务的唯一通道和结果。如果操作系统在执行系统调用服务时，产生了错误，就会导致系统调用执行失败。 以下关于系统调用和常规调用的说法中，错误的是（） [ ] 系统调用一般比常规函数调用的执行开销大 [ ] 系统调用需要切换堆栈 [ ] 系统调用可以引起特权级的变化 [x] 常规函数调用和系统调用都在内核态执行 （知识点：3.4系统调用）系统调用相对常规函数调用执行开销要大，因为这会涉及到用户态栈和内核态栈的切换开销，特权级变化带来的开销，以及操作系统对用户态程序传来的参数安全性检查等开销。如果发出请求的请求方和应答请求的应答方都在内核态执行，则不用考虑安全问题了，效率还是需要的，直接用常规函数调用就够了。 操作系统与用户的接口包括__（） [x] 系统调用 [ ] 进程调度 [ ] 中断处理 [ ] 程序编译 （知识点：3.3中断、异常和系统调用比较）解释： 更合适的答案是1。根据对当前操作系统设计与实现的理解，系统调用是应用程序向操作系统发出服务请求并获得操作系统服务的唯一通道和结果。 多选题 操作系统处理中断的流程包括__（） [x] 保护当前正在运行程序的现场 [x] 分析是何种中断，以便转去执行相应的中断处理程序 [x] 执行相应的中断处理程序 [x] 恢复被中断程序的现场 （知识点：3.3中断、异常和系统调用比较）解释：中断是异步产生的，会随时打断应用程序的执行，且在操作系统的管理之下，应用程序感知不到中断的产生。所以操作系统需要保存被打断的应用程序的执行现场，处理具体的中断，然后恢复被打断的应用程序的执行现场，使得应用程序可以继续执行。 下列程序工作在内核态的有__() [x] 系统调用的处理程序 [x] 中断处理程序 [x] 进程调度 [x] 内存管理 （知识点：3.3中断、异常和系统调用比较）这里说的“程序”是一种指称，其实就是一些功能的代码实现。而1-4都是操作系统的主要功能，需要执行相关的特权指令，所以工作在内核态。 s "},"all/02-1-spoc-discussion.html":{"url":"all/02-1-spoc-discussion.html","title":"lec3 SPOC讨论","keywords":"","body":"lec 3 SPOC Discussion 提前准备 （请在上课前完成） 了解控制流，异常控制流，函数调用,中断，异常(故障)，系统调用（陷阱）,切换，用户态（用户模式），内核态（内核模式）等基本概念。思考一下这些基本概念在linux, ucore, v9-cpu中的os*.c中是如何具体体现的。 思考为什么操作系统需要处理中断，异常，系统调用。这些是必须要有的吗？有哪些好处？有哪些不好的地方？ 第三讲 启动、中断、异常和系统调用-思考题 3.1 BIOS 请描述在“计算机组成原理课”上，同学们做的RISC-V CPU是从按复位键开始到可以接收按键输入之间的启动过程。 了解rcore中的RustSBI的基本功能。 3.2 系统启动流程 RV中RustSBI的启动过程大致包括哪些内容？ 3.3 中断、异常和系统调用比较 什么是中断、异常和系统调用？ 中断、异常和系统调用的处理流程有什么异同？ 3.4 linux系统调用分析 通过分析lab1_ex0了解Linux应用的系统调用编写和含义。(仅实践，不用回答) 通过调试lab1_ex1了解Linux应用的系统调用执行过程。(仅实践，不用回答) 3.5 请分析函数调用和系统调用的区别 系统调用与函数调用的区别是什么？ 通过分析RV中函数调用规范以及ecall、eret、jal和jalr的指令准确功能和调用代码。 课堂实践 （在课堂上根据老师安排完成，课后不用做） 练习一 通过静态代码分析，举例描述ucore/rcore系统调用过程，及调用参数和返回值的传递方法。 "},"all/02-2-lab1-quiz.html":{"url":"all/02-2-lab1-quiz.html","title":"lec4-lab2 在线练习","keywords":"","body":"lab2 在线练习 选择题 "},"all/02-2-lab1-spoc-discussion.html":{"url":"all/02-2-lab1-spoc-discussion.html","title":"lec4-lab2 SPOC讨论","keywords":"","body":"lec4: lab1 SPOC思考题 提前准备 了解GCC/Rust的RV内联汇编以及RV汇编 了解qemu的启动参数的含义 学会使用 qemu 在linux系统中，看看 /proc/cpuinfo的内容 思考题 4.1 中断处理过程 RV中断处理中硬件压栈内容？用户态中断和内核态中断的硬件压栈有什么不同？ 为什么在用户态的中断响应要使用内核堆栈？ 4.2 中断初始化 CPU加电初始化后中断是使能的吗？为什么？ 开放思考题 如果没有中断，操作系统设计会有哪些问题或困难？在这种情况下，能否完成对外设驱动和对进程的切换等操作系统核心功能？ 课堂实践 练习一 在Linux系统的应用程序中写一个函数print_stackframe()，用于获取当前位置的函数调用栈信息。实现如下一种或多种功能：函数入口地址、函数名信息、参数调用参数信息、返回值信息。 练习二 能否在ucore/rcore内核中写一个函数print_stackframe()，用于获取当前位置的函数调用栈信息。 "},"all/3&4-pmm.html":{"url":"all/3&4-pmm.html","title":"物理内存管理","keywords":"","body":"物理内存管理 单选题 (2009联考)分区分配内存管理方式的主要保护措施是（ ） [x] 界地址保护 [ ] 程序代码保护 [ ] 数据保护 [ ] 栈保护 为了防止程序的访问地址越界，所以需要进行界地址保护，由硬件负责检查程序访问地址是否合法。 以ucore为例，在ucore lab1中的，x86保护模式中的分段机制在某种程度上可以看成是一种分区方式的物理内存分配。bootloader在启动后，就要完成分段（分区）工作，即建立两个段，内核代码段和内核数据段，一个段就是一个分区。在表述段属性的段描述符（mmu.h中的segdesc数据结构）中，有两个重要的域（字段，field），起始地址（sd_base_15_0,sd_base_23_16,sd_base_31_24）、段限长(sd_lim_15_0,sd_lim_19_16)。这个段大小就是分区的界地址。80386 CPU在每一次内存寻址过程中，都会比较EIP（即段内偏移）是否大于段限长，如果大于段限长，这会产生一个内存访问错误异常。 (2010联考)某基于动态分区存储管理的计算机，其主存容量为55MB（初始为空），采用最佳适配（Best Fit）算法，分配和释放的顺序为：分配15MB，分配30MB，释放15MB，分配8MB，分配6MB，则此时主存中最大空闲分区的大小是（ ） [ ] 7MB [x] 9MB [ ] 10MB [ ] 15MB 空闲分区链变化：55（初始）；40（分配15MB后）；10（分配30MB后）；10->15（释放15MB后）；2->15（分配8MB后）；2->9（分配6MB后）。 以ucore为例，能否在ucore中做个试验完成上述算法？ (2009联考）一个分段存储系统中，地址长度为32位，其中段号占8位，则最大段长为（ ） [ ] 2^8字节 [ ] 2^16字节 [x] 2^24字节 [ ] 2^32字节 在段访问机制中，如果采用的是单地址方案，则段号的位数+段内偏移的位数=地址长度，所以段内偏移占了32 - 8 = 24 比特。 以ucore lab1为例，在段访问机制上，80386采用了不同，且更加灵活的段寄存器+地址寄存器方案，(可看OS原理部分的\"物理内存管理：第2部分\"ppt的第10页)，即CS中的值（称为选择子，selector）是段号，作为索引，指向了一个段描述符表中的一个段描述符。 段描述符中的一个字段是段基址（32位），这个32位段基址+段内偏移（即32位的EIP）形成了最终的线性地址（如果使能页机制，则也就是最终的物理地址了）。 所以，如果是这道题说明了采用80386方式，结果就不一样了。 (2010联考）某计算机采用二级页表的分页存储管理方式，按字节编址，页大小为2^10字节，页表项大小为2字节，逻辑地址结构为“|页目录号|页表|页内偏移量|”逻辑地址空间大小为2^16页，则表示整个逻辑地址空间的页目录表中包含表项的个数至少为（ ） [ ] 64 [x] 128 [ ] 256 [ ] 512 页大小为2^10B，页表项大小为2B，一页可以存放2^9个页表项，逻辑地址空间大小为2^16页，需要2^16个页表项，需要2^16/2^9 = 2^7 = 128个页面保存页表项。所以页目录表中包含的表项至少为128。 以ucore lab2为例，80386保护模式在使能页机制后，采用的是二级页表，32位地址空间，页大小为2^12字节，页表项为4字节，逻辑地址结构为“|页目录号|页表|页内偏移量|”逻辑地址空间大小为2^20页，则也目录表包含的表项个数为1024. 你觉得对吗？ (武汉理工大学）段式存储管理系统中，一个程序如何分段是在（ ）决定的。 [ ] 分配主存时 [x] 程序员编程时 [ ] 装作业时 [ ] 程序执行时 程序员在编程时，其实已经确定了哪些是代码，哪些是数据。所以编译器可以把代码放到代码段，数据放到数据段，操作系统可以根据编译器的设置把程序加载到内存中的代码段和数据段执行。 以ucore lab1为例，学员编写文件有代码和数据两部分，gcc把代码放到代码段，数据放到数据段，并形成ELF格式的ucore kernel（这其实也是一个程序）。bootloader把ucore的代码或数据放到它设置好的内核代码段和内核数据段中。ucore lab5以后，ucore也可以加载应用程序到用户代码段和用户数据段中。 一般情况下，____的速度最快 [x] L1 cache [ ] L2 cache [ ] Main Memory [ ] Disk 解释：访问速度上 cache > Main Memory > Disk; cache中 L1 > L2 > L3 ... 越靠近cpu速度越快，容量越小。 这个在qemu模拟器中无法体现，因为它没有模拟不同存储之间的访问速度。 :( 分页系统中, 逻辑地址到物理地址的变换是由____决定的 [ ] 段表 [x] 页表 [ ] 物理结构 [ ] 重定位寄存器 解释：分页系统中，页表负责转换逻辑地址到物理地址。 分段系统中, 逻辑地址到物理地址的变换是由____决定的 [x] 段表 [ ] 页表 [ ] 物理结构 [ ] 重定位寄存器 解释：看看ucore lab1，了解bootloader和ucore是如何建立段表的。 连续内存分配算法中的First Fit（首次适应）算法，其空闲分区链的顺序为____ [x] 空闲区首地址递增 [ ] 空闲区首地址递减 [ ] 空闲区大小递增 [ ] 空闲区大小递减 解释：First Fit是指按地址来寻找第一个满足要求的空闲块，其空闲分区链的顺序也就是按空闲块首地址递增。 以ucore为例，能否在ucore中做个试验完成上述算法？ 连续内存分配算法中的Best Fit（最佳适应）算法，其空闲分区链的顺序为____ [ ] 空闲区首地址递增 [ ] 空闲区首地址递减 [x] 空闲区大小递增 [ ] 空闲区大小递减 解释：Best Fit是指寻找一个大小最合适的空闲块，要求空闲块按照大小排列，其空闲分区链的顺序为按大小递增。 以ucore为例，能否在ucore中做个试验完成上述算法？ 连续内存分配算法First Fit的缺点是____ [ ] 算法复杂 [ ] 大的空闲分区会被分割 [x] 容易产生外部碎片 [ ] 分配速度慢 解释：First Fit算法非常简单，分配速度也较快。但是First Fit不考虑实际的需求和找到的空闲分区的大小的匹配度，所以容易产生外部碎片。 以ucore为例，能否在ucore中做个试验完成上述算法并看看其缺点能否重现？ 连续内存分配算法Best Fit的缺点是____ [ ] 算法复杂 [ ] 大的空闲分区会被分割 [ ] 分配速度慢 [x] 回收速度慢 解释：Best Fit算法也非常简单，分配速度较快。由于选取的空闲分区大小都很合适，所以基本不会出现大的空闲分区总是被分割的情况。但是在此算法中，内存回收则涉及了很多操作：判断左右邻居是否是空闲分区，如果不是，则插入此空闲分区到合适的地方，如果是则合并空闲块，并把合并后的结果插入到合适地方；但是由于空闲分区链不是按地址排序的，所以上述操作需要遍历几次链表用于查找和插入，速度较慢。 连续内存分配算法Worst Fit的缺点是____ [ ] 算法复杂 [x] 大的空闲分区会被分割 [ ] 分配速度慢 [ ] 容易产生很小的空闲分区 解释：Worst Fit每次使用最大的空闲分区，按照需求分割相应的大小，所以会造成大的空闲分区总是被分割。其算法比较简单，分配速度也很快。 以ucore为例，能否在ucore中做个试验完成上述算法并看看其缺点能否重现？ 应用程序中的逻辑地址到物理内存中的物理地址的转换机制建立的过程发生____程序过程中 [ ] 编译 [ ] 链接 [x] 加载 [ ] 运行 解释：在编译器编译和链接程序的过程中都只涉及到逻辑地址，跟机器的配置无关，这也是编译链接所生成的可执行文件可以直接在相同系统的其它机器上使用的原因。而在操作系统加载应用程序时，操作系统负责建立应用程序的段表或页表。将逻辑地址和实际物理地址对应起来，之后应用程序在运行过程中CPU才能根据逻辑地址通过段表或页表正确访问到物理地址。 以ucore lab5为例，在加载应用程序时，将建立应用程序对应的进程，并在建立过程中，把应用程序对应进程的页表也建立好了。 某一作业完成后，系统收回其主存空间，并与相邻空闲区合并，为此需修改空闲区表，如果待回收的空闲区有相邻的低址空闲区,也有相邻的高址空闲区，那么空闲区表将____ [ ] 项数不变，有一个空闲区的大小变大 [ ] 项数不变，有一个空闲区的起始地址变小，大小变大 [ ] 项数增加 [x] 项数减少 解释：合并之后，原本的2个相邻空闲分区和被回收的分区合并成一个分区，所以分区项数变为n - 2 + 1 = n - 1。 以ucore为例，能否在ucore中做个试验完成上述相邻空闲区合并功能，看看合并的效果如何？ 对于分页系统与分段系统,下列说法正确的是( ). [ ] 页的大小跟具体执行程序有关 [x] 都属于非连续分配 [ ] 段的大小固定且由系统确定 [ ] 分段技术和分页技术是不能共存在一个系统中的 解释：页的大小由CPU硬件规定的规范，并由操作系统进行初始化和管理，跟具体执行程序无关； 段的大小是指程序的数据段、代码段等每段的大小，和具体程序相关；分段技术和分页技术是按照需求进行动态的分配和回收，是非连续分配，它们可以融合使用，也称段页式管理。 以ucore为例，在lab2之后，就采用基于80386的段页式管理了，但段机制的功能没有太用。 采用段页式管理时，程序按逻辑被划分成____ [x] 段 [ ] 页 [ ] 区域 [ ] 块 解释：程序按逻辑划分各段。而页、区域、块由操作系统负责分配、映射和管理，和程序逻辑没有关系。 采用段页式管理的多道程序环境下，一个应用程序都有对应的____ [x] 一个段表和一个页表 [ ] 一个段表和一组页表 [ ] 一组段表和一个页表 [ ] 一组段表和一组页表 解释：每道程序有一个段表，且还要有一个页表，才能完成段页式的内存管理。 以ucore为例，在lab5之后，就采用基于80386的段页式管理了，一个程序有一个段表，也有一个页表。 在分页式存储管理系统中时，每次CPU取指令或取操作数，至少要访问____次主存。 [x] 0 [ ] 1 [ ] 2 [ ] 3 解释：0次。因为CPU会有cache和mmu 以ucore为例，在80386中，如果取的指令和取的操作数都在CPU的cache中，且放在页表中的地址映射关系被缓存在CPU的MMU中，则不需要访问主存。 在分段式存储管理系统中时，每次CPU取指令或取操作数，至少要访问____次主存。 [x] 0 [ ] 1 [ ] 2 [ ] 3 解释：0次。因为CPU会有cache，mmu和对段表项的缓存 以ucore为例，在80386中，如果取的指令和取的操作数都在CPU的cache中，且放在段表中的地址映射关系被缓存在CPU的段表项缓存中，则不需要访问主存。 在段页式存储管理系统中时，每次CPU取指令或取操作数，至少要访问____次主存。 [x] 0 [ ] 1 [ ] 2 [ ] 3 解释：0次。因为CPU会有cache和对段表项的缓存 以ucore为例，在80386中，如果取的指令和取的操作数都在CPU的cache中，且放在段表中的地址映射关系被缓存在CPU的段表项缓存中，且放在页表中的地址映射关系被缓存在CPU的MMU中，则不需要访问主存。 每道程序能在不受干扰的环境下运行，主要是通过____功能实现的。 [ ] 内存分配 [x] 内存保护 [ ] 内存回收 [ ] 内存扩充 解释：内存访问需要将逻辑地址和重定位寄存器(基址寄存器)进行加运算之后才能访问物理地址，而内存保护主要是使用界地址寄存器来实现对逻辑地址的限制，以免逻辑地址越界而造成物理地址访问越界，进而对别的程序进行干扰。 以ucore为例，在lab5中，ucore对每个应用程序设置的页表，可以完成对不同程序的地址空间的隔离，从而避免了程序间可能的干扰。 可变分区存储管理方案中____作为存储保护使用。 [ ] 逻辑地址寄存器 [x] 长度寄存器 [ ] 物理地址寄存器 [ ] 基址寄存器 解释：长度寄存器或称界地址寄存器，用于存储保护。 以ucore为例，在80386中，分段机制可以看成是一种可变分区存储管理方案，其段描述符中的段限长字段类似这里提到的“长度寄存器“ 分页系统中的页面对____透明，是____管理的。 [ ] 程序员、编译器 [x] 程序员、操作系统 [ ] 操作系统、编译器 [ ] 程序员、链接器 解释：分页由操作系统控制，用户并不能感知。 以ucore为例，在lab5以后，程序员写应用程序，确实不需要考虑有分页机制的存在。因为ucore已经为每个应用程序建立好了段表（也叫全局描述符表，简称GDT）和页表。 多选题 关于分段系统和分页系统说法正确有____。 [x] 页是系统层面的内存管理的单位，分页的目的主要是由于操作系统管理的需要；段是编写程序层面的内存管理的单位,分段的目的主要是为了能更好地满足程序员开发的需要 [x] 页的大小是固定的，而且由系统确定。段的长度却是不固定的，决定于程序员所编写的程序 [x] 分段系统会产生外碎片，分页系统会产生内碎片 [x] 分段可灵活的控制存取访问，可根据各段的特点决定访问权 解释：1,2,4解释略。3：分段系统中段的大小是跟程序相关的，分段系统中每次分配的大小就是相应段的真实大小所以没有内部碎片；但是却会产生不满足任何段大小的空闲分区，就是外部碎片。 "},"all/03-1-quiz.html":{"url":"all/03-1-quiz.html","title":"lec5 在线练习","keywords":"","body":"lec5 在线练习 选择题 操作系统中可采用的内存管理方式包括() s1 [x] 重定位(relocation) [x] 分段(segmentation [x] 分页(paging) [x] 段页式（segmentation+paging） 都有 在启动页机制的情况下，在CPU运行的用户进程访问的地址空间是() s2 [ ] 物理地址空间 [x] 逻辑地址空间 [ ] 外设地址空间 [ ] 都不是 用户进程访问的内存地址是虚拟地址 连续内存分配的算法中，会产生外碎片的是() s3 [x] 最先匹配算法 [x] 最差匹配算法 [x] 最佳匹配算法 [ ] 都不会 三种算法都会有外碎片 在使能分页机制的情况下，更合适的外碎片整理方法是() s4 [ ] 紧凑(compaction) [ ] 分区对换(Swapping in/out) [x] 都不是 分页方式不会有外碎片 描述伙伴系统(Buddy System)特征正确的是() s5 [x] 多个小空闲空间可合并为大的空闲空间 [x] 会产生外碎片 [x] 会产生内碎片 [ ] 都不对 前三个是对的。 "},"all/03-1-spoc-discussion.html":{"url":"all/03-1-spoc-discussion.html","title":"lec5 SPOC讨论","keywords":"","body":"lec5: SPOC思考题 提前准备 （请在上课前完成） 完成lec５的视频学习和提交对应的在线练习 git pull ucore_os_lab, v9_cpu, os_course_spoc_exercises in github repos。这样可以在本机上完成课堂练习。 理解连续内存动态分配算法的实现（主要自学和网上查找） NOTICE 有\"hard\"标记的题有一定难度，鼓励实现。 有\"easy\"标记的题很容易实现，鼓励实现。 有\"midd\"标记的题是一般水平，鼓励实现。 思考题 “连续内存分配”与视频相关的课堂练习 5.1 计算机体系结构和内存层次 1.操作系统中存储管理的目标是什么？ 5.2 地址空间和地址生成 1.描述编译、汇编、链接和加载的过程是什么？ 2.动态链接如何使用？尝试在Linux平台上使用LD_DEBUG查看一个C语言Hello world的启动流程。 (optional) 5.3 连续内存分配 1.什么是内碎片、外碎片？ 2.最先匹配会越用越慢吗？请说明理由（可来源于猜想或具体的实验）？ 3.最差匹配的外碎片会比最优适配算法少吗？请说明理由（可来源于猜想或具体的实验）？ 4.理解0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm算法中分区释放后的合并处理过程？ (optional) 5.4 碎片整理 1.对换和紧凑都是碎片整理技术，它们的主要区别是什么？为什么在早期的操作系统中采用对换技术？2.一个处于等待状态的进程被对换到外存（对换等待状态）后，等待事件出现了。操作系统需要如何响应？ 5.5 伙伴系统 1.伙伴系统的空闲块如何组织？ 2.伙伴系统的内存分配流程？伙伴系统的内存回收流程？ 课堂实践 观察最先匹配、最佳匹配和最差匹配这几种动态分区分配算法的工作过程，并选择一个例子进行分析分析整个工作过程中的分配和释放操作对维护数据结构的影响和原因。 算法演示脚本的使用说明 算法演示脚本 例如： python ./ostep3-malloc.py -S 100 -b 1000 -H 4 -a 4 -l ADDRSORT -p BEST -n 5 -c python ./ostep3-malloc.py -S 100 -b 1000 -H 4 -a 4 -l ADDRSORT -p FIRST -n 5 -c python ./ostep3-malloc.py -S 100 -b 1000 -H 4 -a 4 -l ADDRSORT -p WORST -n 5 -c 扩展思考题 (optional) 请参考xv6（umalloc.c），ucore lab2代码，选择四种（0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm）分配算法中的一种或多种，在Linux应用程序/库层面，用C、C++或python来实现malloc/free，给出你的设计思路，并给出可以在Linux上运行的malloc/free实现和测试用例。 阅读slab分配算法，尝试在应用程序中实现slab分配算法，给出设计方案和测试用例。 "},"all/03-2-quiz.html":{"url":"all/03-2-quiz.html","title":"lec6 在线练习","keywords":"","body":"lec6 在线练习 选择题 描述段管理机制正确的是() s2 [x] 段的大小可以不一致 [x] 段可以有重叠 [x] 段可以有特权级 [x] 段与段之间是可以不连续的 都对 描述页管理机制正确的是() s3 [x] 页表在内存中 [x] 页可以是只读的 [x] 页可以有特权级 [ ] 上诉说法都不对 前三个都对 页表项标志位包括() s4 [x] 存在位(resident bit) [x] 修改位(dirty bit) [x] 引用位(clock/reference bit) [x] 只读位(read only OR read/write bit) 都有 可有效应对大地址空间可采用的页表手段是() s7 [x] 多级页表 [x] 反置页表 [ ] 页寄存器方案 [ ] 单级页表 前两个是对的。 "},"all/03-2-spoc-discussion.html":{"url":"all/03-2-spoc-discussion.html","title":"lec6 SPOC讨论","keywords":"","body":"lec6 SPOC思考题 NOTICE 有\"w3l2\"标记的题是助教要提交到学堂在线上的。 有\"w3l2\"和\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的git repo上。 有\"hard\"标记的题有一定难度，鼓励实现。 有\"easy\"标记的题很容易实现，鼓励实现。 有\"midd\"标记的题是一般水平，鼓励实现。 与视频相关思考题 6.1 非连续内存分配的需求背景 为什么要设计非连续内存分配机制？ 非连续内存分配中内存分块大小有哪些可能的选择？大小与大小是否可变? 为什么在大块时要设计大小可变，而在小块时要设计成固定大小？小块时的固定大小可以提供多种选择吗？ 6.2 段式存储管理 什么是段、段基址和段内偏移？ 段式存储管理机制的地址转换流程是什么？为什么在段式存储管理中，各段的存储位置可以不连续？这种做法有什么好处和麻烦？ 6.3 页式存储管理 什么是页（page）、帧（frame）、页表（page table）、存储管理单元（MMU）、快表（TLB, Translation Lookaside Buffer）和高速缓存（cache）？ 页式存储管理机制的地址转换流程是什么？为什么在页式存储管理中，各页的存储位置可以不连续？这种做法有什么好处和麻烦？ 6.4 页表概述 每个页表项有些什么内容？有哪些标志位？它们起什么作用？ 页表大小受哪些因素影响？ 6.5 快表和多级页表 快表（TLB）与高速缓存（cache）有什么不同？ 为什么快表中查找物理地址的速度非常快？它是如何实现的？为什么它的的容量很小？ 什么是多级页表？多级页表中的地址转换流程是什么？多级页表有什么好处和麻烦？ 6.6 反置页表 页寄存器机制的地址转换流程是什么？ 反置页表机制的地址转换流程是什么？ 反置页表项有些什么内容？ 6.7 段页式存储管理 段页式存储管理机制的地址转换流程是什么？这种做法有什么好处和麻烦？ 如何实现基于段式存储管理的内存共享？ 如何实现基于页式存储管理的内存共享？ 个人思考题 （1） (w3l2) 请简要分析64bit CPU体系结构下的分页机制是如何实现的 小组思考题 （1）(spoc) 某系统使用请求分页存储管理，若页在内存中，满足一个内存请求需要150ns (10^-9s)。若缺页率是10%，为使有效访问时间达到0.5us(10^-6s),求不在内存的页面的平均访问时间。请给出计算步骤。 （2）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持32KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : VALID | PFN6 ... PFN0 PDE格式（8 bit） : VALID | PT6 ... PT0 其 VALID==1表示，表示映射存在；VALID==0表示，表示映射不存在。 PFN6..0:页帧号 PT6..0:页表的物理基址>>5 在物理内存模拟数据文件中，给出了4KB物理内存空间的值，请回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents。 1) Virtual Address 6c74 Virtual Address 6b22 2) Virtual Address 03df Virtual Address 69dc 3) Virtual Address 317a Virtual Address 4546 4) Virtual Address 2c03 Virtual Address 7fd7 5) Virtual Address 390e Virtual Address 748b 比如答案可以如下表示： (注意：下面的结果是错的，你需要关注的是如何表示) Virtual Address 7570: --> pde index:0x1d pde contents:(valid 1, pfn 0x33) --> pte index:0xb pte contents:(valid 0, pfn 0x7f) --> Fault (page table entry not valid) Virtual Address 21e1: --> pde index:0x8 pde contents:(valid 0, pfn 0x7f) --> Fault (page directory entry not valid) Virtual Address 7268: --> pde index:0x1c pde contents:(valid 1, pfn 0x5e) --> pte index:0x13 pte contents:(valid 1, pfn 0x65) --> Translates to Physical Address 0xca8 --> Value: 16 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，请说明原因。 （3）请基于你对原理课二级页表的理解，并参考Lab2建页表的过程，设计一个应用程序（可基于python、ruby、C、C++、LISP、JavaScript等）可模拟实现(2)题中描述的抽象OS，可正确完成二级页表转换。 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，提交你的实现，并说明区别。 （4）假设你有一台支持反置页表的机器，请问你如何设计操作系统支持这种类型计算机？请给出设计方案。 (5)X86的页面结构 扩展思考题 阅读64bit IBM Powerpc CPU架构是如何实现反置页表，给出分析报告。 interactive　understand VM Virtual Memory with 256 Bytes of RAM：这是一个只有256字节内存的一个极小计算机系统。按作者的特征描述，它具备如下的功能。 CPU的实现代码不多于500行； 支持14条指令、进程切换、虚拟存储和中断； 用C实现了一个小的操作系统微内核可以在这个CPU上正常运行； 实现了一个ANSI C89编译器，可生成在该CPU上运行代码； 该编译器支持链接功能； 用C89, Python, Java, Javascript这4种语言实现了该CPU的模拟器； 支持交叉编译； 所有这些只依赖标准C库。 针对op-cpu的特征描述，请同学们通过代码阅读和执行对自己有兴趣的部分进行分析，给出你的分析结果和评价。 "},"all/03-3-lab2-quiz.html":{"url":"all/03-3-lab2-quiz.html","title":"lec7-lab2 在线练习","keywords":"","body":"lec7: lab2在线练习 选择题 80386 CPU保护模式下的特权级个数是() s1 [ ] 1 [ ] 2 [ ] 3 [x] 4 ring0-ring3 ucore OS中使用了的80386 CPU保护模式下的特权级的级别包括() s1 [x] 0 [ ] 1 [ ] 2 [x] 3 ring 0 for OS， ring3 for application 在ucore OS的管理下，如果CPU在ring3特权级执行访存指令，读属于ring0特权级的数据段中的内存单元，将出现的情况是（） s1 [ ] 产生外设中断 [x] 产生访存异常 [ ] CPU继续正常执行 [ ] 系统重启 将产生General Protection Fault异常 段描述符中与特权级相关的一个组成部分的名称是（） s1 [x] DPL [ ] AVL [ ] Base [ ] Limit 是DPL CS段寄存器中的最低两位保存的是（） s1 [ ] DPL [x] CPL [ ] RPL [ ] NPL 是CPL DS段寄存器中的最低两位保存的是（） s1 [ ] DPL [ ] CPL [x] RPL [ ] NPL 是RPL CPU执行一条指令访问数据段时，硬件要做的特权级检查是（） s1 [x] MAX(CPL, RPL) [ ] MIN(CPL, RPL) [ ] MAX(CPL, DPL) [ ] MIN(CPL, DPL) 是MAX(CPL, RPL) 对于Task State Segment（TSS）而言，uCore OS可以利用它做（） s2 [x] 保存ring 0的SS [x] 保存ring 0的ESP [ ] 保存中断描述符表的基址 [ ] 保存全局描述符表的基址 是保存ring 0的SS和ESP 页目录表的基址是保存在寄存器（） s3 [ ] CR0 [ ] CR1 [ ] CR2 [x] CR3 CR3 在启动页机制后，不可能进行的操作包括（） s3 [x] 取消段机制，只保留页机制 [ ] 取消页机制，只保留段机制 [ ] 取消页机制，也取消段机制 [ ] 保留页机制，也保留段机制 不可能取消段机制，只保留页机制 给定一个虚页地址和物理页地址，在建立二级页表并建立正确虚实映射关系的过程中，需要完成的事务包括() s4 [x] 给页目录表动态分配空间，给页表分配空间 [x] 让页基址寄存器的高20位内容为页目录表的高20位物理地址 [x] 在虚地址高10位的值为index的页目录项中的高20位填写页表的高20位物理地址，设置有效位 [x] 在虚地址中10位的值为index的页表项中中的高20位填写物理页地址的高20位物理地址，设置有效位 都对，还要设置更多的一些属性。 "},"all/03-3-lab2-spoc-discussion.html":{"url":"all/03-3-lab2-spoc-discussion.html","title":"lec7lab2 SPOC讨论","keywords":"","body":"lec7: lab2 SPOC思考题 NOTICE 有\"w4l1\"标记的题是助教要提交到学堂在线上的。 有\"w4l1\"和\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的git repo上。 有\"hard\"标记的题有一定难度，鼓励实现。 有\"easy\"标记的题很容易实现，鼓励实现。 有\"midd\"标记的题是一般水平，鼓励实现。 提前准备 完成lec7(lab2)的视频学习和提交对应的在线练习 git pull ucore_os_lab, v9_cpu, os_course_spoc_exercises 　in github repos。这样可以在本机上完成课堂练习。 理解如何实现建立页表（主要自学和网上查找） 第七讲视频相关思考题 7.1 了解x86保护模式中的特权级 X86有几个特权级？ 不同特权级有什么区别？ 请说明CPL、DPL和RPL在中断响应、函数调用和指令执行时的作用。 写一个示例程序，完成4个特权级间的函数调用和数据访问时特权级控制的作用。 7.2 了解特权级切换过程 一条指令在执行时会有哪些可能的特权级判断？ 在什么情况下会出现特权级切换？ int指令在ring0和ring3的执行行为有什么不同？ 如何利用int和iret指令完成不同特权级的切换？ TSS和Task Register的作用是什么？ Task state segment Reference: Intel® 64 and IA-32 Architectures Software Developer Manuals Page 2897/4684: 7.2.1 Task-State Segment (TSS) 7.3 了解段/页表 一条指令执行时最多会出现多少次地址转换？ 描述X86-32的MMU地址转换过程； 7.4 了解UCORE建立段/页表 分析MMU的使能过程，尽可能详细地分析在执行进入保护械的代码“movl %eax, %cr0 ; ljmp $CODE_SEL, $0x0”时，CPU的状态和寄存器内容的变化。 分析页表的建立过程； 个人思考题 x86保护模式中权限管理无处不在，下面哪些时候要检查访问权限() (w4l1) [x] 内存寻址过程中 [x] 代码跳转过程中 [x] 中断处理过程中 [ ] ALU计算过程中 请描述ucore OS建立页机制的准备工作包括哪些步骤？ (w4l1) 小组思考题 （1）（spoc）请用lab1实验的基准代码（即没有修改的需要填空的源代码）来做如下实验： 执行make qemu，会得到一个输出结果，请给出合理的解释：为何qemu退出了？【提示】需要对qemu增加一些用于显示执行过程的参数，重点是分析其执行的指令和产生的中断或异常。 可试试\"qemu-system-i386 -d help\" （2）(spoc)假定你已经完成了lab1的实验,接下来是对lab1的中断处理的回顾：请把你的学号对37(十进制)取模，得到一个数x（x的范围是-1 intr_enable(); // enable irq interrupt 语句之后，加入如下语句(把x替换为你学号 mod 37得的值)： asm volatile (\"int $x\"); 然后，请回答加入这条语句后，执行make qemu的输出结果与你没有加入这条语句后执行make qemu的输出结果的差异，并解释为什么有差异或没差异？ （3）对于lab2的输出信息，请说明数字的含义 e820map: memory: 0009fc00, [00000000, 0009fbff], type = 1. memory: 00000400, [0009fc00, 0009ffff], type = 2. memory: 00010000, [000f0000, 000fffff], type = 2. memory: 07ee0000, [00100000, 07fdffff], type = 1. memory: 00020000, [07fe0000, 07ffffff], type = 2. memory: 00040000, [fffc0000, ffffffff], type = 2. 修改lab2，让其显示type=\"some string\" 让人能够读懂，而不是不好理解的数字1,2 (easy) [x] > （4）(spoc)有一台只有页机制的简化80386的32bit计算机，有地址范围位0~256MB的物理内存空间（physical memory），可表示大小为256MB，范围为0xC0000000~0xD0000000的虚拟地址空间（virtual address space）,页大小（page size）为4KB，采用二级页表，一个页目录项（page directory entry ，PDE）大小为4B,一个页表项（page-table entries PTEs）大小为4B，1个页目录表大小为4KB，1个页表大小为4KB。 PTE格式（32 bit） : PFN19 ... PFN0|NOUSE9 ... NOUSE0|WRITABLE|VALID PDE格式（32 bit） : PT19 ... PT0|NOUSE9 ... NOUSE0|WRITABLE|VALID 其中： NOUSE9 ... NOUSE0为保留位，要求固定为0 WRITABLE：1表示可写，0表示只读 VLAID：1表示有效，0表示无效 假设ucore OS已经为此机器设置好了针对如下虚拟地址物理地址映射的二级页表，设置了页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐），其值为0。ucore OS在物理内存空间（0x1000~0x41000）已经建立和配置好了整个二级页表（包括页目录表和页表），且页目录表的index为0x300~0x363的页目录项的(PT19 ... PT0)的值=(index-0x300+1)。请写出一个translation程序（可基于python、ruby、C、C++、LISP、JavaScript等），输入是一个虚拟地址和一个物理地址，能够自动计算出对应的页目录项的index值,页目录项内容的值，页表项的index值，页表项内容的值。即(pde_idx, pde_ctx, pte_idx, pte_cxt) 请用如下值来验证你写的程序的正确性： va 0xc2265b1f, pa 0x0d8f1b1f va 0xcc386bbc, pa 0x0414cbbc va 0xc7ed4d57, pa 0x07311d57 va 0xca6cecc0, pa 0x0c9e9cc0 va 0xc18072e8, pa 0x007412e8 va 0xcd5f4b3a, pa 0x06ec9b3a va 0xcc324c99, pa 0x0008ac99 va 0xc7204e52, pa 0x0b8b6e52 va 0xc3a90293, pa 0x0f1fd293 va 0xce6c3f32, pa 0x007d4f32 参考的输出格式为： va 0xcd82c07c, pa 0x0c20907c, pde_idx 0x00000336, pde_ctx 0x00037003, pte_idx 0x0000002c, pte_ctx 0x0000c20b >> 注意：上述参考输出只是表示了正确的格式，其数值并不正确。 (5) 尝试在内存为256字节的OP-CPU机器上，设计一个支持自映射的内存空间部局。说明其页表起始逻辑地址、一级和二级虚拟地址计算公式。 开放思考题 （1）请简要分析Intel的x64 64bit体系结构下的分页机制是如何实现的 （2）Intel8086不支持页机制，但有hacker设计过包含未做任何改动的8086CPU的分页系统。猜想一下，hacker是如何做到这一点的？提示：想想MMU的逻辑位置 页表自映射机制思考题 (easy) 自映射的目的是什么？它相比线性映射的好处、不足是什么？ (easy) Linux和Windows分别采用哪种映射机制（线性映射or自映射）？它们的选择背后有什么原因吗？ 以下为optional： (midd) 在x86-32中，假设页目录的第R个页表项是自映射的，那么： 可以通过哪个虚拟地址访问到页目录？ 控制虚地址vaddr所在页的页表项地址是多少？（假设在vaddr发生了缺页异常，根据你给出的答案，就可以快速地修改相应的页表项） 当你试图访问上述页表项时，又发生了缺页异常。这可能是什么原因？ (midd) 如何合理设置自映射页表，使得用户程序可以看到自己的页表，但不能修改或是看到内核部分？（参考ucore lab中的sys_pgdir） (hard) 修改自映射页表：现在有两个自映射页表A和B，其中A是活动的（CR3指向pgdir），B是非活动的。如何在不切换页表（不修改CR3）的条件下，通过自映射区域修改页表B？ (challenge) RISCV中的自映射机制： 如果照搬x86的方式，在RISCV中配置自映射页表，那么会在访问页目录时触发PageFault。原因是，根据规范，RISCV中的页表项不能被同时解读为【指向页表】和【指向数据页】（前者的flags是V，后者是VRW）。如果设置为V，那么在解读最后一级时会触发异常，如果设置为VRW，则会在第一级被认为是一个大数据页。而在x86中，同一个页表项在最后一级被解读为指向数据页，在中间级则被解读为指向页表，因此方便实现自映射。 请你在x86自映射的基础上进行一些修改，为RISCV32设计一种自映射的实现方案。并描述一次修改页表项的完整过程。 参考阅读：Advanced Paging v9-cpu相关 [challenge]在v9-cpu上，设定物理内存为64MB。在os2.c和os4.c的基础上实现页机制管理，内核空间的映射关系： kernel_virt_addr=0xc00000000+phy_addr，内核空间大小为64MB，虚拟空间范围为0xc0000000--x0xc4000000, 物理空间范围为0x00000000--x0x04000000；用户空间的映射关系：user_virt_addr=0x40000000+usr_phy_addr，用户空间可用大小为1MB，虚拟空间范围为0x40000000--0x40100000，物理空间范围为0x02000000--x0x02100000。可参考v9-cpu git repo的testing分支中的os.c和mem.h。修改代码为os5.c (1)在内核态可正确访问这两个空间 (2)在用户态可正确访问这两个空间 在使能页机制的前一条指令和后一条指令的内存地址的访问会出现什么不同/变化？ 如果在建立页表过程中，使能页机制前，如果不加上pg_dir[0]=....，为何v9-cpu模拟器会出现\"kernel stack fault\"的fatal error并推出？ 请比较一下os在v9-cpu和x86上建立页表过程的不同之处，需要考虑硬件设计上的差异 [x] "},"all/5&6-vmm.html":{"url":"all/5&6-vmm.html","title":"虚拟内存管理","keywords":"","body":"Virtual Memory Management 单选题 (2012联考)下列关于虚拟存储器的叙述中，正确的是（ ） [ ] 虚拟存储只能基于连续分配技术 [x] 虚拟存储只能基于非连续分配技术 [ ] 虚拟存储容量只受外存容量的限制 [ ] 虚拟存储容量只受内容容量的限制 采用连续分配方式的时候，会使得相当一部分内存空间都处于空闲状态，造成内存资源的严重浪费，无法从逻辑上扩大内存容量。 （2011年联考）在缺页处理过程中，操作系统执行的操作可能是（ ） 1)修改页表 2)磁盘I/O 3)分配页框 [ ] 仅1、2 [ ] 仅2、3 [ ] 仅1、3 [x] 1、2、3 如果还有可分配给程序的内存，那么会分配新的页框，修改页表，从磁盘读取内容放入到分配的页框中。 （2013计算机联考）若系统发生抖动(Thrashing)时，可用采取的有效措施是（ ） 1）撤销部分进程 2）增加磁盘交换区的容量 3）提高用户进程的优先级 [x] 仅1 [ ] 仅2 [ ] 仅3 [ ] 仅1、2 撤销部分进程可以增大可用内存，减少抖动。而磁盘交换区容量和进程优先级则跟抖动无关。 (南昌大学)一个虚拟存储器系统中，主存容量16MB，辅存容量1GB，地址寄存器位数32位。那么虚存最大容量为（ ） [ ] 1GB [ ] 16MB [ ] 1GB + 16MB [x] 4GB 虚拟存储器的最大容量跟虚拟地址空间有关，是2^32。 （上海交通大学）分页式虚拟存储管理系统中，分页是（ ）实现的 [ ] 程序员 [ ] 编译器 [ ] 系统调用 [x] 系统 分页是系统内部实现的，对用户透明。 为了使得内存需求较大的程序能够正常运行，常需要通过外存和内存的交换技术，这被叫做__技术 [ ] 虚拟机 [ ] 内存分配 [ ] 进程调度 [x] 虚拟存储 解释：虚拟机用于模拟真实物理机器，单独的内存分配技术可以不考虑使用外存，进程调度则用于管理进程的执行时间和次序等。虚拟存储是指当真实内存不能满足需求的时候，可以将程序需要的代码和数据放到内存中，暂时不需要的放到外存上；通过内存和外存的不断交换，来满足程序的运行需求。 虚拟内存是为了应对__的问题（） [ ] 内存访问速度过慢 [ ] 内存管理困难 [x] 内存容量不满足程序需求 [ ] 磁盘访问过慢 解释：虚拟内存是应对内存容量不能满足程序需求的情况，并不能解决内存内存和外存访问速度的问题。 一般来讲，虚拟内存使得程序的运行速度__ [ ] 加快 [ ] 不变 [x] 变慢 [ ] 变得极不稳定 解释：由于虚拟内存有可能造成外存和内存的不断交换，虽然能够满足大程序的运行需求，但是程序的运行速度相比没有虚拟内存的情况下会变慢。 虚拟内存常用的页面淘汰技术，主要利用了程序的__特征 [ ] 健壮性 [ ] 完整性 [x] 局部性 [ ] 正确性 解释：程序的局部性是指程序呈现在某段时间内只访问程序的某一部分代码和数据的特性，而页面置换算法可以利用这一特性使常被访问的页面不被淘汰也就减少了缺页率。 在一个系统中，页面大小设定为4k，分配给每个进程的物理页面个数为1，在某应用程序中需要访问一个int[1024][1024]的数组（逐行访问），那么按行存储和按列存储的不同情况下，__ [x] 按行存储时，执行效率高 [ ] 按列存储时，执行效率高 [ ] 执行效率相同 [ ] 执行效率不确定 解释：按行存储的时候，每访问一行才会出现一次页面置换；而按列存储，则每访问一次就发生一次缺页。由于缺页的时候需要调用页面置换算法进行内外存交换，所以缺页率高的时候效率就低。 虚拟内存技术__ [ ] 只能应用于分段系统 [ ] 只能应用于分页系统 [x] 可应用于分段系统、分页系统 [ ] 只能应用于段页式系统 解释：虚拟内存技术是一种内外存交换的思想，可应用与分段系统、分页系统等。而目标系统是分段系统还是分页系统，影响的只是虚拟内存技术思想的具体实现。 在虚拟页式内存管理系统中，页表项中的‘访问位’给__提供参考价值。 [ ] 分配页面 [x] 页面置换算法 [ ] 换出页面 [ ] 程序访问 解释：页面置换算法可能需要根据不同页面是否被访问，访问时间和访问频率等进行淘汰页面的选择。 在虚拟页式内存管理系统中，页表项中的‘修改位’供__使用 [ ] 分配页面 [ ] 页面置换算法 [x] 换出页面 [ ] 程序访问 解释：页面换出的时候，需要判断外存上的相应页面是否需要重写。如果内存中该页面在使用期间发生了修改，则相应的修改位被设置，用于换出的时候通知操作系统进行外存相应页面的修改。 在虚拟页式内存管理系统中，页表项中的__供程序访问时使用 [ ] 访问位 [ ] 修改位 [x] 状态位 [ ] 保护位 解释：页表项的状态位用于指示该页是否已经调入内存，供程序访问时使用，如果发现该页未调入内存，则产生缺页中断，由操作系统进行相应处理。 在虚拟页式内存管理系统中，发生缺页的概率一般取决于__ [ ] 内存分配算法 [ ] 内存读取速度 [ ] 内存写入速度 [x] 页面置换算法 解释：缺页率的高低跟实际能分配的物理内存的大小，以及系统中的页面置换算法相关。差的页面置换算法可能造成需要访问的页面经常没有在内存中，而需要进行缺页中断处理。 页面置换算法的优劣，表现在__ [ ] 程序在运行时能够分配到的页面数 [ ] 单位时间内，程序在运行时得到的CPU执行时间 [x] 程序在运行时产生的页面换入换出次数 [ ] 程序本身的访存指令个数 解释：页面置换算法在满足程序运行需求的同时，应尽量降低页面的置换次数，从而降低运行开销。 选择在将来最久的时间内不会被访问的页面作为换出页面的算法叫做__ [x] 最优页面置换算法 [ ] LRU [ ] FIFO [ ] CLOCK 解释：LRU是换出在过去的时间里最久未被访问的页面；FIFO是换出最先被换入的页面；CLOCK类似于LRU，也是对FIFO的改进。但是以上三种算法都是根据过去一段时间内的页面访问规律进行换出页面的选择。而最优页面置换算法是指换出将来在最久的时间内不会被访问的页面，是一种理想情况也是不可能实现的。 Belady异常是指__ [ ] 频繁的出页入页现象 [x] 分配的物理页数变多，缺页中断的次数却增加 [ ] 进程的内存需求过高，不能正常运行 [ ] 进程访问内存的时间多于读取磁盘的时间 解释：一般情况下，分配的物理页数越多，缺页率会越低。但是某些页面置换算法如FIFO就可能造成相反的情况，也即分配的物理页数增多，缺页率却增高的情况。这种情况称为Belady异常。 在各种常见的页面置换算法中，__会出现Belady异常现象 [x] FIFO [ ] LRU [ ] LFU [ ] CLOCK 解释：FIFO可能出现Belady异常，如访问顺序1,2,3,4,1,2,5,1,2,3,4,5，在最多分配3个物理块的情况下缺页9次，而在最多分配4个物理块的情况下缺页10次。 当进程访问的页面不存在，且系统不能继续给进程分配物理页面的时候，系统处理过程为__ [ ] 确定换出页面->页面换出->页面换入->缺页中断 [ ] 缺页中断->页面换入->确定换出页面->页面换出 [ ] 缺页中断->确定换出页面->页面换入->页面换出 [x] 缺页中断->确定换出页面->页面换出->页面换入 解释：首先在程序访问的时候发现页面不在内存中，从而发出缺页中断，进入页面置换的流程。需要确定换出页面才能执行页面交换，而页面换入之前要保证页面已经正确的换出，因为页面换出可能需要重写外存中相应的页面。 某进程的页面访问顺序为1、3、2、4、2、3、1、2，系统最多分配3个物理页面，那么采用LRU算法时，进程运行过程中会发生__缺页。 [ ] 三次 [ ] 四次 [x] 五次 [ ] 六次 解释：1（缺页） - 3（缺页） - 2（缺页） - 4（缺页，换出1） - 2 - 3 - 1（缺页，换出4） - 2 在现代提供虚拟内存的系统中，用户的逻辑地址空间__ [ ] 不受限制 [ ] 受物理内存空间限制 [ ] 受页面大小限制 [x] 受指令地址结构 解释：逻辑地址空间受到逻辑地址的结构限制，也即为指令地址的结构限制。 多选题 以下哪些页面置换算法是可以实现的__ [ ] 最优页面置换算法 [x] LRU [x] FIFO [x] CLOCK 解释：最优页面置换算法是根据将来的页面访问次序来选择应该换出的页面，因为在程序执行之前不可能已知将来的页面访问次序，所以不可能实现。而其它的页面置换算法则是根据已经发生的页面访问次序来决定换出的页面，都是可以实现的。 影响缺页率的因素有__ [x] 页面置换算法 [x] 分配给进程的物理页面数 [x] 页面本身的大小 [x] 程序本身的编写方法 解释：总体来讲，缺页率的主要影响因素的页面置换算法和分配给进程的物理页面数。但是页面本身的大小和程序本身的编写方法则涉及到页面访问次序的变化，对缺页率也会造成影响。 判断题 发生缺页的时候，一定会使用页面置换算法__ [ ] 对 [x] 错 解释：发生缺页的时候，如果分配给程序的物理页面数还有空闲，则直接换入新的页面，不需要使用页面置换算法来挑选需要换出的页面。 "},"all/04-1-quiz.html":{"url":"all/04-1-quiz.html","title":"lec8 在线练习","keywords":"","body":"lec8 在线练习 选择题 操作系统中可采用的内存管理方式包括() s1 [x] 重定位(relocation) [x] 分段(segmentation [x] 分页(paging) [x] 段页式（segmentation+paging） 都有 在启动页机制的情况下，在CPU运行的用户进程访问的地址空间是() s2 [ ] 物理地址空间 [x] 逻辑地址空间 [ ] 外设地址空间 [ ] 都不是 用户进程访问的内存地址是虚拟地址 连续内存分配的算法中，会产生外碎片的是() s3 [x] 最先匹配算法 [x] 最差匹配算法 [x] 最佳匹配算法 [ ] 都不会 三种算法都会有外碎片 在使能分页机制的情况下，更合适的外碎片整理方法是() s4 [ ] 紧凑(compaction) [ ] 分区对换(Swapping in/out) [x] 都不是 分页方式不会有外碎片 描述伙伴系统(Buddy System)特征正确的是() s5 [x] 多个小空闲空间可合并为大的空闲空间 [x] 会产生外碎片 [x] 会产生内碎片 [ ] 都不对 前三个是对的。 "},"all/04-1-spoc-discussion.html":{"url":"all/04-1-spoc-discussion.html","title":"lec8 SPOC讨论","keywords":"","body":"lec8: 虚拟内存spoc练习 NOTICE 有\"w4l2\"标记的题是助教要提交到学堂在线上的。 有\"w4l2\"和\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的git repo上。 有\"hard\"标记的题有一定难度，鼓励实现。 有\"easy\"标记的题很容易实现，鼓励实现。 有\"midd\"标记的题是一般水平，鼓励实现。 提前准备 完成lec8的视频学习和提交对应的在线练习 git pull uco re_os_lab, v9_cpu, os_course_spoc_exercises 　in github repos。这样可以在本机上完成课堂练习。 理解如何实现建立页表，给用户态建立页表，在用户态使用虚地址，产生各自也访问错误的基本应对 视频相关思考题 8.1 虚拟存储的需求背景 寄存器、高速缓存、内存、外存的访问特征？ 如何理解计算机中的存储层次结构所的理想状态是“均衡繁忙”状态？ 在你写程序时遇到过内存不够的情况吗？尝试过什么解决方法？ 8.2 覆盖和交换 什么是覆盖技术？使用覆盖技术的程序开发者的主要工作是什么？ 什么是交换技术？覆盖与交换有什么不同？ 覆盖和交换技术在现代计算机系统中还有需要吗？可能用在什么地方？ 如何分析内核模块间的依赖关系？ 如何获取内核模块间的函数调用列表？ 8.3 局部性原理 什么是时间局部性、空间局部性和分支局部性？ 如何提高程序执行时的局部性特征？ 排序算法的局部性特征？ 参考：九大排序算法再总结 8.4 虚拟存储概念 什么是虚拟存储？它与覆盖和交换的区别是什么？它有什么好处和挑战？ 虚拟存储需要什么样的支持技术？ 8.5 虚拟页式存储 什么是虚拟页式存储？缺页中断处理的功能是什么？ 为了支持虚拟页式存储的实现，页表项有什么修改？ 页式存储和虚拟页式存储的区别是什么？ 8.6 缺页异常 缺页异常的处理流程？ 虚拟页式存储管理中有效存储访问时间是如何计算的？ 个人思考题 内存访问局部性的应用程序例子 (1)(w4l2)下面是一个体现内存访问局部性好的简单应用程序例子，请参考，在linux中写一个简单应用程序，体现内存局部性差，并给出其执行时间。 #include #define NUM 1024 #define COUNT 10 int A[NUM][NUM]; void main (void) { int i,j,k; for (k = 0; k可以用下的命令来编译和运行此程序： gcc -O0 -o goodlocality goodlocality.c time ./goodlocality 可以看到其执行时间。 小组思考题目 缺页异常嵌套 （1）缺页异常可用于虚拟内存管理中。如果在中断服务例程中进行缺页异常的处理时，再次出现缺页异常，这时计算机系统（软件或硬件）会如何处理？请给出你的合理设计和解释。 提示：https://en.wikipedia.org/wiki/Double_fault 和 https://en.wikipedia.org/wiki/Triple_fault 缺页异常次数计算 （2）如果80386机器的一条机器指令(指字长4个字节)，其功能是把一个32位字的数据装入寄存器，指令本身包含了要装入的字所在的32位地址。这个过程在OS合理处理情况下最多会引起几次缺页异常？ 提示：内存中的指令和数据的地址需要考虑地址对齐和不对齐两种情况。需要考虑页目录表项invalid、页表项invalid、TLB缺失等是否会产生异常？ 虚拟页式存储的地址转换 （3）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持8KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : VALID | PFN6 ... PFN0 PDE格式（8 bit） : VALID | PT6 ... PT0 其 VALID==1表示，表示映射存在；VALID==0表示，表示内存映射不存在（有两种情况：a.对应的物理页帧swap out在硬盘上；b.既没有在内存中，页没有在硬盘上，这时页帧号为0x7F）。 PFN6..0:页帧号或外存中的后备页号 PT6..0:页表的物理基址>>5 已经建立好了1个页目录表和8个页表，且页目录表的index为0~7的页目录项分别对应了这8个页表。 在物理内存模拟数据文件中，给出了4KB物理内存空间和4KBdisk空间的值，PDBR的值。 请手工计算后回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents，the value of addr in phy page OR disk sector。 1) Virtual Address 6653: 2) Virtual Address 1c13: 3) Virtual Address 6890: 4) Virtual Address 0af6: 5) Virtual Address 1e6f: 请写出一个translation程序（可基于rust、python、ruby、C、C++、LISP、JavaScript等），输入是一个虚拟地址，依据物理内存模拟数据文件自动计算出对应的pde index, pde contents, pte index, pte contents，the value of addr in phy page OR disk sector。 提示: 页大小（page size）为32 Bytes(2^5) 页表项1B 8KB的虚拟地址空间(2^13) 一级页表：2^5 PDBR content: 0xd80（1101_100 0_0000, page 0x6c） page 6c: e1(1110 0001) b5(1011 0101) a1(1010 0001) c1(1100 0001) b3(1011 0011) e4(1110 0100) a6(1010 0110) bd(1011 1101) 二级页表：2^5 页内偏移：2^5 4KB的物理内存空间（physical memory）(2^12) 物理帧号：2^7 Virtual Address 0330(0 00000 11001 1_0000): --> pde index:0x0(00000) pde contents:(0xe1, 11100001, valid 1, pfn 0x61(page 0x61)) page 6c: e1 b5 a1 c1 b3 e4 a6 bd 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f page 61: 7c 7f 7f 4e 4a 7f 3b 5a 2a be 7f 6d 7f 66 7f a7 69 96 7f c8 3a 7f a5 83 07 e3 7f 37 62 30 7f 3f --> pte index:0x19(11001) pte contents:(0xe3, 1 110_0011, valid 1, pfn 0x63) page 63: 16 00 0d 15 00 1c 1d 16 02 02 0b 00 0a 00 1e 19 02 1b 06 06 14 1d 03 00 0b 00 12 1a 05 03 0a 1d --> To Physical Address 0xc70(110001110000, 0xc70) --> Value: 02 Virtual Address 1e6f(0 001_11 10_011 0_1111): --> pde index:0x7(00111) pde contents:(0xbd, 10111101, valid 1, pfn 0x3d) page 6c: e1 b5 a1 c1 b3 e4 a6 bd 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f page 3d: f6 7f 5d 4d 7f 04 29 7f 1e 7f ef 51 0c 1c 7f 7f 7f 76 d1 16 7f 17 ab 55 9a 65 ba 7f 7f 0b 7f 7f --> pte index:0x13 pte contents:(0x16, valid 0, pfn 0x16) disk 16: 00 0a 15 1a 03 00 09 13 1c 0a 18 03 13 07 17 1c 0d 15 0a 1a 0c 12 1e 11 0e 02 1d 10 15 14 07 13 --> To Disk Sector Address 0x2cf(0001011001111) --> Value: 1c 扩展思考题 (1)请分析原理课的缺页异常的处理流程与lab3中的缺页异常的处理流程（分析粒度到函数级别）的异同之处。 (2)在X86-32虚拟页式存储系统中，假定第一级页表的起始地址是0xE8A3 B000，进程地址空间只有第一级页表的4KB在内存。请问这4KB的虚拟地址是多少？它对应的第一级页表项和第二级页表项的物理地址是多少？页表项的内容是什么？ v9-cpu相关 [challenge]在v9-cpu上，设定物理内存为64MB。在os.c,os2.c,os4.c,os5的基础上实现os6.c，可体现基本虚拟内存管理机制，内核空间的映射关系： kernel_virt_addr=0xc00000000+phy_addr，内核空间大小为64MB，虚拟空间范围为0xc0000000--x0xc4000000, 物理空间范围为0x00000000--x0x04000000；用户空间的映射关系：user_virt_addr=0x40000000+usr_phy_addr，用户空间可用大小为2MB，虚拟空间范围为0x40000000--0x40200000，物理空间范围为0x02000000--x0x02200000，但只建立低地址的1MB的用户空间页表映射。可参考v9-cpu git repo的testing分支中的os.c和mem.h。修改代码为os5.c (1)在建立页表后，进入用户态，能够在用户态访问基于用户空间的映射关系 (2)在用户态和内核态产生各种也访问的错误，并能够通过中断服务例程进行信息提示 (3)内核通过中断服务例程在感知到用户态访问高地址的空间，且没有超过0x40200000时，内核动态建立页表，确保用户态程序可以正确运行 如果一个用户态进程访问一个合法用户地址，产生内存访问异常后，v9-cpu会把产生异常的pc存在哪里？中断服务例程应该如何设计，可以返回到用户态产生错误的地址再次执行? "},"all/04-2-quiz.html":{"url":"all/04-2-quiz.html","title":"lec9 在线练习","keywords":"","body":"lec9 在线练习 选择题 物理页帧数量为3，且初始时没有对应的虚拟页。虚拟页访问序列为 0,1,2,0,1,3,0,3,1,0,3，请问采用最优置换算法的缺页次数为（） s2 [ ] 1 [ ] 2 [ ] 3 [x] 4 4 物理页帧数量为3，且初始时没有对应的虚拟页。虚拟页访问序列为 0,1,2,0,1,3,0,3,1,0,3，请问采用LRU置换算法的缺页次数为（） s2 [ ] 1 [ ] 2 [ ] 3 [x] 4 4 物理页帧数量为3，且初始时没有对应的虚拟页。虚拟页访问序列为 0,1,2,0,1,3,0,3,1,0,3，请问采用FIFO置换算法的缺页次数为（） s2 [ ] 1 [ ] 2 [ ] 4 [x] 6 6 物理页帧数量为4，且初始时没有对应的虚拟页。虚拟页访问序列为 0,3,2,0,1,3,4,3,1,0,3,2,1,3,4 ，请问采用CLOCK置换算法（用1个bit表示存在时间）的缺页次数为（） s3 [ ] 8 [x] 9 [ ] 10 [ ] 11 9 物理页帧数量为4，且初始时没有对应的虚拟页。虚拟页访问序列为 0,3,2,0,1,3,4,3,1,0,3,2,1,3,4 ，请问采用CLOCK置换算法（用2个关联，bit表示存在时间,可以表示4,）的缺页次数为（） s3 [x] 7 [ ] 8 [ ] 9 [ ] 10 7 物理页帧数量为4 0,3,2,0,1,3,4,3,1,0,3,2,1,3,4 1 0 0 f 1 0 01 0 1 00 虚拟页访问序列为 1,2,3,4,1,2,5,1,2,3,4,5，物理页帧数量为3和4，采用FIFO置换算法，请问是否会出现bealdy现象() s4 [x] 会 [ ] 不会 3页时9次缺页，4页时10次缺页。 下面哪些页面淘汰算法不会产生Belady异常现象 s4 [ ] 先进先出页面置换算法（FIFO) [ ] 时钟页面置换算法（CLOCK) [x] 最佳页面置换算法（OPT） [x] 最近最少使用页面置换算法（LRU） LRU和OPT属于一种栈算法 物理页帧数量为5，且初始时没有对应的虚拟页，虚拟页访问序列为 4,3,0,2,2,3,1,2,4,2,4,0,3，请问采用工作集置换算法（工作集窗口T=4）的缺页次数为（） s5 [ ] 6 [ ] 7 [x] 8 [ ] 9 8 T:1.2.3.4.5.6.7.8.9.a,b,c,d P:4,3,0,2,2,3,1,2,4,2,4,0,3 1 4 f 1 2 3 3,4 f 2 3 0 0,3,4 f 3 4 2 2,0,3,4 f 4 5 2 2,0,3 f 4 6 3 3,2,0 f 4 7 1 1,3,2 f 5 8 2 2,1,3 f 5 9 4 4,2,1,3 f 6 10 2 2,4,1 11 4 4,2 12 0 0,4,2 f 7 13 3 3,0,4,2 f 8 物理页帧数量为5，且初始时没有对应的虚拟页，虚拟页访问序列为 4,3,0,2,2,3,1,2,4,2,4,0,3，请问采用缺页率置换算法（窗口T=2）的缺页次数为（） s6 [ ] 6 [ ] 7 [x] 8 [ ] 9 8 4,3,0,2,2,3,1,2,4,2,4,0,3 1 4 f 1 2 3,4 f 2 3 0,3,4 f 3 4 2 2,0,3,4 f 4 5 2 2,0,3,4 n f 6 3 3,2,0,4 n f 7 1 f 5 t=3 >2 [4,7] 1,3,2 ^0,4 8 2 2,1,3 9 4 f 6 t=9-72 0,4,2,1 ^3 13 3 f 8 13-12=1"},"all/04-2-spoc-discussion.html":{"url":"all/04-2-spoc-discussion.html","title":"lec9 SPOC讨论","keywords":"","body":"lec9: 虚存置换算法spoc练习 视频相关思考题 9.1 页面置换算法的概念 设计置换算法时需要考虑哪些影响因素？如何评判的好坏？ 全局和局部置换算法的不同？ 9.2 最优算法、先进先出算法和最近最久未使用算法 最优算法、先进先出算法和LRU算法的思路？ 9.3 时钟置换算法和最不常用算法 时钟置换算法的思路？ 改进的时钟置换算法与时钟置换算法有什么不同？ LFU算法的思路？ 9.4 Belady现象和局部置换算法比较 什么是Belady现象？如何判断一种置换算法是否存在Belady现象？ 请证明LRU算法不存在Belady现象。 9.5 工作集置换算法 CPU利用率与并发进程数的关系是什么？ 什么是工作集？ 什么是常驻集？ 工作集算法的思路？ 9.6 缺页率置换算法 缺页率算法的思路？ 9.7 抖动和负载控制 什么是虚拟内存管理的抖动现象？ 操作系统负载控制的最佳状态是什么状态？ 局部置换算法（如FIFO, LRU等）是否能作为全局置换算法来使用？为什么？ 扩展思考题 改进时钟置换算法的极端情况: 如果所有的页面都被修改过了，这时需要分配新的页面时，算法的performance会如何？能否改进在保证正确的前提下提高缺页中断的处理时间？ 如何设计改进时钟算法的写回策略? （spoc）根据你的学号 mod 4的结果值，确定选择四种页面置换算法（0：LRU置换算法，1:改进的clock 页置换算法，2：工作集页置换算法，3：缺页率置换算法）中的一种来设计一个应用程序（可基于python, ruby, C, C++，LISP等）模拟实现，并给出测试用例和测试结果。请参考如python代码或独自实现。 页置换算法实现的参考实例 请判断OPT、LRU、FIFO、Clock和LFU等各页面置换算法是否存在Belady现象？如果存在，给出实例；如果不存在，给出证明。 了解LIRS页置换算法的设计思路，尝试用高级语言实现其基本思路。此算法是江松博士（导师：张晓东博士）设计完成的，非常不错！ 参考信息： LIRS conf paper LIRS journal paper LIRS-replacement ppt1-LIRS-replacement.pdf) LIRS-replacement ppt2 "},"all/04-3-lab3-quiz.html":{"url":"all/04-3-lab3-quiz.html","title":"lec10-lab3 在线练习","keywords":"","body":"lec10: lab3 在线练习 选择题 lab3中虚存管理需要直接借助的机制包括() s1 [x] 页映射机制 [ ] 段映射机制 [x] 中断异常处理机制 [x] IDE硬盘读写机制 段映射机制不直接需要 lab3中实现虚存管理的过程包括() s2 [x] 实现对硬盘swap分区的读写 [x] 建立处理页访问错误的异常/中断服务例程 [x] 实现页替换算法 [x] 定义不在物理内存中的“合法”虚拟页 都包括 lab3中用于描述“合法”虚拟页的数据结构是（）s3 [x] vma_struct [ ] trapframe [ ] gatedesc [ ] segdesc vma_struct lab3中访问“合法”虚拟页产生缺页异常的原因是（）s4 [x] 页表项的P bit为0 [ ] 页目录项的I/D bit为0 [ ] 页表项的U/S bit为0 [ ] 页目录项的W/R bit位0 页表项的P bit为0，表示此页不存在 lab3中把扇区索引信息放在（）s5 [x] 页表项中 [ ] 页目录项中 [ ] 内存中的Page结构中 [ ] 内存中的vma_struct结构中 页表项中的高24位 "},"all/04-3-lab3-spoc-discussion.html":{"url":"all/04-3-lab3-spoc-discussion.html","title":"lec10-lab3 SPOC讨论","keywords":"","body":"lec10: lab3 SPOC思考题 视频相关思考题 10.1 实验目标：虚存管理 缺页和页访问非法的返回地址有什么不同？ 虚拟内存管理中是否用到了段机制？ ucore如何知道页访问异常的地址？ 10.2 回顾历史和了解当下 中断处理例程的段表在GDT还是LDT？ 物理内存管理的数据结构在哪？ 页表项的结构？ 页表项的修改代码？ 如何设置一个虚拟地址到物理地址的映射关系？ 为了建立虚拟内存管理，需要在哪个数据结构中表示“合法”虚拟内存 10.3 处理流程、关键数据结构和功能 swap_init()做了些什么？ vmm_init()做了些什么？ vma_struct数据结构的功能？ mmap_list是什么列表？ 外存中的页面后备如何找到？ vma_struct和mm_struct的关系是什么？ 画数据结构图，描述进程的虚拟地址空间、页表项、物理页面和后备页面的关系； 10.4 页访问异常 页面不在内存和页面访问非法的处理中有什么区别？对应的代码区别在哪？ find_vma()做了些什么？ swapfs_read()做了些什么？ 缺页时的页面创建代码在哪？ struct rb_tree数据结构的原理是什么？在虚拟管理中如何用它的？ 页目录项和页表项的dirty bit是何时，由谁置1的？ 页目录项和页表项的access bit是何时，由谁置1的？ 10.5 页换入换出机制 虚拟页与磁盘后备页面的对应有关系？ 如果在开始加载可执行文件时，如何改？ check_swap()做了些什么检查？ swap_entry_t数据结构做什么用的？放在什么地方？ 空闲物理页面的组织数据结构是什么？ 置换算法的接口数据结构？ ================ 小组思考题 (1)请参考lab3_result的代码，思考如何在lab3_results中实现clock算法，给出你的概要设计方案。可4人一个小组。要求说明你的方案中clock算法与LRU算法上相比，潜在的性能差异性。进而说明在lab3的LRU算法实现的可能性评价（给出理由）。 (2) 理解内存访问的异常。在x86中内存访问会受到段机制和页机制的两层保护，请基于lab3_results的代码（包括lab1的challenge练习实现），请实践并分析出段机制和页机制各种内存非法访问的后果。，可4人一个小组，，找出尽可能多的各种内存访问异常，并在代码中给出实现和测试用例，在执行了测试用例后，ucore能够显示出是出现了哪种异常和尽量详细的错误信息。请在说明文档中指出：某种内存访问异常的原因，硬件的处理过程，以及OS如何处理，是否可以利用做其他有用的事情（比如提供比物理空间更大的虚拟空间）？哪些段异常是否可取消，并用页异常取代？ 课堂实践练习 请分析ucore中与物理内存管理和虚拟存储管理相关的数据结构组织；分析访问这些数据结构的函数，说明其对存储管理相关数据结构的修改情况；最后通过一个数据结构图示，描述进程的虚拟地址空间、页表项、物理页面和后备页面的关系。 struct Page struct mm_struct struct vma_struct struct swap_entry v9-cpu相关 (1)分析并编译运行v9-cpu git repo的testing branch中的,root/etc/os_lab2.c os_lab3.c os_lab3_1.c,理解虚存机制是如何在v9-cpu上实现的，思考如何实现clock页替换算法，并给出你的概要设计方案。 (2)分析并编译运行v9-cpu git repo的testing branch中的,root/etc/os_lab2.c os_lab3.c os_lab3_1.c，理解内存访问异常的各种情况，并给出你的分析结果。 "},"all/7-process&thread.html":{"url":"all/7-process&thread.html","title":"进程、线程管理","keywords":"","body":"进程、线程管理 单选题 (2010年计算机联考真题)下列选项中，导致创建新进程的操作是（） 1)用户登陆成功 2)设备分配 3)启动程序执行 [ ] 仅1和2 [ ] 仅2和3 [x] 仅1和3 [ ] 1、2、3 解释：设备分配是通过系统中设置相应的数据结构实现的，不需要创建进程 （2012年计算机联考真题）下列关于进程和线程的叙述中，正确的是（） [x] 不管系统是否支持线程，进程都是资源分配的基本单位 [ ] 线程是资源分配的基本单元，进程是调度的基本单位 [ ] 系统级线程和用户级线程的切换都需要内核的支持 [ ] 同一进程中的各个线程拥有各自不同的地址空间 解释：引入线程的操作系统中，通常都是把进程作为资源分配的基本单位，而把线程作为独立运行的基本单位。同一进程中的各个线程都可以共享进程所拥有的系统资源，这表现在所有线程都有相同的地址空间。对于用户级线程的切换，通常是发生在一个应用进程的诸多线程之间，这时，也同样无须内核的支持 (2010年计算机联考真题)下列选项中，降低进程优先级的合理时机是（） [x] 进程时间片用完 [ ] 进程刚完成I/O操作，进入就绪队列 [ ] 进程长期处于就绪队列 [ ] 进程从就绪状态转为运行状态 解释：进程时间片用完，从执行态进入就绪态应降低优先级以让别的进城那个调度进入执行状态，B中进程刚完成I/O，进入就绪队列后应该等待被处理器调度，故应提高优先级，C中类似，D中不应该降低，应该在时间片用完后再降低 （上海交通大学）OS对（）分配内存资源 [ ] 线程 [ ] 高速缓冲存储器 [x] 进程 [ ] 快表 解释：进程是系统资源分配的基本单位，线程是调度的基本单位，高速缓冲存储器和快表都是硬件 (四川大学)一进程基本状态可以从其他两种基本状态转变过去，这个基本状态一定是（） [ ] 执行状态 [ ] 阻塞状态 [x] 就绪状态 [ ] 完成状态 解释：处于就绪状态的进程，已具备了运行条件，但由于未能获得CPU，故仍不能运行，就绪状态可以从运行状态和阻塞状态转换得到 （上海交通大学）下列说法（）不是创建进程必须的 [ ] 建立一个进程的进程表项 [ ] 为进程分配内存 [x] 为进程分配CPU [ ] 将进程表项放入就绪队列 解释：进程刚被创建时，实际上是处于就绪状态的，所以不需为进程分配CPU （2011年全国统考）在支持多线程的系统中，进程P创建的若干个线程不能共享的是（） [ ] 进程P的代码段 [ ] 进程P打开的文件 [ ] 进程P的全局变量 [x] 进程P中某线程的栈指针 解释：多线程系统中，一个进程的多个线程共享进程的代码段、文件和全局变量，进程中某线程的栈指针是归该线程所独有，对其他线程透明，但不恩能够与其他线程共享。 （2011年全国统考）下列选项中，在用户态执行的是（） [x] 命令解释程序 [ ] 缺页处理程序 [ ] 进程调度层序 [ ] 时钟中断处理程序 解释：缺页处理程序和时钟中断都属于中断，进程调度属于系统调用，均在核心态执行，命令解释程序属于命令借口，它在用户态执行 （南京理工大学）进程和程序之间有密切联系，但又有不同的概念，两者的一个本质区别是（） [x] 程序是静态概念，进程是动态概念 [ ] 程序是动态概念，进程是静态概念 [ ] 程序保存在文件中，进程存放在内存中 [ ] 程序顺序执行，进程并发执行 解释：进程和程序的本质区别是程序是静态的，进程是动态的 （电子科技大学）若一进程拥有100个线程，这些线程属于用户级线程，则在系统调度执行时间上占用（）个时间片 [x] 1 [ ] 100 [ ] 1/100 [ ] 0 解释：在引入线程的系统中，资源仍然是按进程分配的，由于分配给该进程1个时间片，所以在执行时间上总共占1个时间片 (上海交通大学)一个进程被唤醒，意味着（） [x] 该进程可以重新占用CPU [ ] 优先级变为最大 [ ] PCB移到就绪队列之首 [ ] 进程变为运行态 解释：在一个进程被唤醒时，它将从阻塞状态变成就绪状态，从而可以重新获得CPU并投入运行 对进程的描述中，下列说法错误的是（） [x] 一个程序只对应一个进程 [ ] 一个进程可以包含若干个程序 [ ] 进程是有生命周期的 [ ] 一个程序可以对应多个进程 解释：进程是执行中的程序，它是有生命周期的，程序本身不是进程，程序只是被动实体，一个程序可能会有多个进程相关 下列的进程状态变化中，()变化是不可能发生的 [ ] 运行一等待 [x] 等待一运行 [ ] 等待一就绪 [ ] 运行一就绪 解释： 进程状态是由当前活动所定义，运行状态表示指令正在被执行，等待状态表示进程等待某个事件的发生，就绪态表示进程等待分配处理器，由进程状态图我们可以看到等待状态无法直接转变成运行状态，需要从等待态先变成就绪态 一个运行的进程用完了分配给它的时间片后，它的状态变为（） [ ] 运行 [ ] 等待 [x] 就绪 [ ] 终止 解释： 当一个进程用完了分配给它的时间片后，状态会变为就绪态，之后会继续等待分配处理器 将进程的（）连接在一起形成进程队列 [ ] 堆栈段 [ ] 数据段 [ ] 堆 [x] PCB 解释：进程调度选择一个可用的进程到CPU上执行，而进程进入洗头膏时，会被加到作业队列中，改队列包括系统中的所有进程，驻留在内存中就绪、等待运行的进程保存在就绪队列中，改队列通常用链表来实现，其头节点指向链表的第一个和最后一个PCB块的指针。 下列关于进程控制块的描述中，说法错误的是（） [ ] 进程控制块记录进程的状态及名称等 [ ] 进程控制块位于主存储区内 [x] 进程控制块对每个进程不止有一个 [ ] 进程控制块的内容、格式及大小可能不同 解释：每个进程在操作系统内用一个进程控制块来表示，每个进程控制块都记录进程的状态及名称等，并且每个进程对应一个进程控制块，进程控制块的内容、格式及大小可能不同，并且进程控制快位于主存储区内 PCB是进程存在的唯一标志，下列（）不属于PCB [ ] 堆栈指针 [ ] 全局变量 [ ] 进程ID [x] CPU状态 解释：进程描述块包含许多与一个特定进程相关的信息，主要有：进程状态、程序计数器、CPU调度信息、内存管理信息、记账信息以及I/O状态信息。从题目中我们可以看出CPU状态信息并不包含在内。 对于标准的线程，下列叙述中，错误的是（） [ ] 进程中可以包含多个线程 [ ] 线程并不拥有资源，只是使用他们 [ ] 线程可以创建其他线程 [x] 线程没有生命期 解释：线程依然有生命周期 （）系统调用是用来被父进程等待子进程结束的 [x] wait() [ ] fork() [ ] exit() [ ] exec() 解释：当进程完成执行最后的语句并使用系统调用的exit()请求操作系统删除自身时，进程终止。这时，进程可以返回状态值到父进程，而这个父进程等待子进程结束的方法是通过父进程系统调用wait() 多个进程的实体能存在于同一内存中，在一段时间内都得到运行。这种性质称为进程的（） [ ] 动态性 [ ] 调度性 [x] 并发性 [ ] 独立性 解释：概念题,进程有四个特性，动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的；并发性：任何进程都可以同其他进程一起并发执行；独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位；异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进 现在操作系统中，（）是资源分配的基本单位,（）是CPU调度的基本单位。 [ ] 作业，程序 [ ] 内存，进程 [x] 进程，线程 [ ] 代码，数据 解释：概念题，在现代操作系统中，进程使资源分配的基本单位，线程是CPU调度的基本单位。其中线程与属于同一进程的其他线程共享代码段、数据段和其他操作系统资源，如果进程有多个控制线程，那么它能同时做多个任务 下列各项工作步骤中，()不是创建进程所必需的步骤 [ ] 为进程分配内存等资源 [ ] 将PCB链入进程就绪队列 [x] 作业调度程序为进程分配CPU [ ] 建立一个PCB 解释：创建进程时不需要用作业调度程序为进程分配CPU 在多线程操作系统中，对线程具有属性阐述正确的是（） [x] 具有进程控制块，共享所属进程资源，处理机的独立调度单位，具有动态性 [ ] 具有线程控制块，共享所属进程资源，处理机的独立调度单位，具有动态性 [ ] 具有进程控制块，独享所属进程资源，处理机的独立调度单位，具有动态性 [ ] 具有进程控制块，共享所属进程资源，处理机的独立调度单位，具有静态性 解释：概念题，线程具有进程控制块，共享所属进程资源，处理机的独立调度单位，具有动态 多选题 （西安电子科技大学）能正确描述进程和线程的概念是（） [x] 线程可以是进程中独立执行的实体，一个进程可以包含一个或多个线程 [ ] 线程又称为轻型进程，因为线程都比进程小 [x] 多线程计数具有明显的优越性，如速度快、通信简便、设备并行性高 [ ] 由于线程不作为资源分配单位，线程之间可以无约束地并行执行 [x] 一个线程可以属于一个或多个进程 解释：虽然线程被称为轻量级线程，这并不意味着线程比进程小，进程和线程之间无法进行大小比较 （电子科技大学）引起挂起状态的原因有（） [x] 终端用户的请求 [x] 父进程请求 [x] 负荷调节的需要 [ ] 操作系统的需要 [ ] 平衡各队列中的进程控制块 解释：考察引起挂起的原因 下列各项中属于进程特性的是（） [x] 动态性 [x] 异步性 [x] 独立性 [x] 并发性 解释：概念题,进程有四个特性,动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的;并发性：任何进程都可以同其他进程一起并发执行;独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位；异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进 采用多线程技术的操作系统具有() [x] 一个进程中可以有一个或多个线程 [x] 把进程作为资源分配单位,把线程作为调度和执行单位 [ ] 不同的线程一定执行不同的程序 [x] 允许多个线程并发执行 解释：不同的线程可能执行相同的程序，一个线程中可以有一个或多个线程，把进程作为资源分配单位,把线程作为调度和执行单位，允许多个线程并发执行 判断题： （北京工业大学）子进程可以继承它的父进程所拥有的所有资源（） [ ] 对 [x] 错 解释：子进程继承了父进程的代码段和数据段资源，堆栈段则是自己的 （首都师范大学）属于同一进程的用户级线程阻塞了，那么同一个进程的其他用户级线程还可以占有CPU运行，直到时间片用完（） [x] 对 [ ] 错 解释：在同一进程中，线程的切换不会引起进程的切换，在由一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换 在操作系统中，进程是一个静态的概念（） [ ] 对 [x] 错 解释：动态概念 一般来说用户进程的PCB存放在用户区，系统进程的PCB存放在操作系统区（） [ ] 对 [x] 错 解释： PCB通常是系统内存占用区中的一个连续存区，它存放着操作系统用于描述进程情况及控制进程运行所需的全部信息。 在linux环境里使用fork（）来创建新进程（） [x] 对 [ ] 错 解释： 概念题，了解进程的创建是如何进行的 在多对一模型的线程中，如果一个线程执行了阻塞系统调用，并不影响整个进程（） [ ] 对 [x] 错 解释： 多对一模型的线程中，如果一个线程执行了阻塞系统调用，会影响整个进程，整个进程会阻塞 启动一个线程使用的是start()方法（） [x] 对 [ ] 错 解释： 概念题 在父进程还存活的情况下, 不会产生僵死状态（） [ ] 对 [x] 错 解释：一个已经终止但是其父进程尚未对其进行善后处理（获取终止子进程的有关信息，释放它仍占用的资源）的进程称为僵尸进程(zombie)。这时进程在调用exit命令结束自己的生命的时候，其实它并没有真正的被销毁，而是留下一个称为僵尸进程（Zombie）的数据结构 "},"all/05-1-quiz.html":{"url":"all/05-1-quiz.html","title":"lec11 在线练习","keywords":"","body":"lec11 进程与线程　在线练习 选择题 进程与程序的关系描述正确的是（） s1 [x] 进程是指一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程 [ ] 进程是一个具有一定独立功能的程序 [ ] 程序是一个动态执行的进程 [x] 进程包含了正在运行的一个程序的所有状态信息 1,4 关于进程控制块的描述正确的是（） s2 [x] 操作系统用进程控制块来描述进程的基本情况以及运行变化的过程 [x] 进程控制块是进程存在的唯一标志 [x] 每个进程都在操作系统中有一个对应的进程控制块 [x] 操作系统管理控制进程运行所用的信息集合是进程控制块 都对 关于进程的生命周期的描述正确的是（） s3 [x] 内核选择一个就绪态的进程，让它占用处理机并执行，此时进程处于运行态 [x] 进程请求并等待系统服务，无法马上完成，此时进程处于等待态 [x] 进程执行的当前时间片用完了，此时进程处于就绪态 [x] 进程退出了，但还没被父进程回收，此时进程处于zombie态 都对 操作系统来维护一组队列，表示系统中所有进程的当前状态，有关管理进程的描述正确的是（） s5 [x] 就绪态进程维护在进程就绪队列中 [x] 等待态进程维护在进程等待队列中 [ ] 运行态进程维护在进程运行队列中 [ ] zombie态进程不在任何队列中 1,2 有关线程或进程的描述正确的是（） s6 [x] 进程是资源分配单位，线程是CPU调度单位 [x] 进程拥有一个完整的资源平台，而线程只独享指令流执行的必要资源，如寄存器和栈 [x] 线程能减少并发执行的时间和空间开销 [x] 同一进程的各线程间共享内存和文件资源，可不通过内核进行直接通信 都对 常见的线程种类有() s7 [x] 用户线程 [x] 内核线程 [x] 轻量级进程 都对 内核线程的描述正确的是() s8 [x] 由内核维护内核线程的线程控制块 [ ] 由用户线程库维护内核线程的线程控制块 [ ] 内核无法调度内核线程 [ ] 内核线程间无法共享所属进程的资源 1 "},"all/05-1-spoc-discussion.html":{"url":"all/05-1-spoc-discussion.html","title":"lec11 SPOC讨论","keywords":"","body":"lec11: 进程／线程概念spoc练习 视频相关思考题 11.1 进程的概念 什么是程序？什么是进程？ 进程有哪些组成部分？ 请举例说明进程的独立性和制约性的含义。 程序和进程联系和区别是什么？ 11.2 进程控制块 进程控制块的功能是什么？ 进程控制块中包括什么信息？ ucore的进展控制块数据结构定义中哪些字段？有什么作用？ 11.3 进程状态 进程生命周期中的相关事件有些什么？它们对应的进程状态变化是什么？ 11.4 三状态进程模型 运行、就绪和等待三种状态的含义？7个状态转换事件的触发条件是什么？ 11.5 挂起进程模型 引入挂起状态的目的是什么？ 引入挂起状态后，状态转换事件和触发条件有什么变化？ 内存中的什么内容放到外存中，就算是挂起状态？ 11.6 线程的概念 引入线程的目的是什么？ 什么是线程？ 进程与线程的联系和区别是什么？ 11.7 用户线程 什么是用户线程？ 用户线程的线程控制块保存在用户地址空间还是在内核地址空间？ 11.8 内核线程 用户线程与内核线程的区别是什么？ 同一进程内的不同线程可以共用一个相同的内核栈吗？ 同一进程内的不同线程可以共用一个相同的用户栈吗？ 选做题 请尝试描述用户线程堆栈的可能维护方法。 小组思考题 (1) 熟悉和理解下面的简化进程管理系统中的进程状态变化情况。 简化的三状态进程管理子系统使用帮助 简化的三状态进程管理子系统实现脚本 (2) (spoc)设计一个简化的进程管理子系统，可以管理并调度如下简化进程。在理解参考代码的基础上，完成＂YOUR CODE\"部分的内容。然后通过测试用例和比较自己的实现与往届同学的结果，评价自己的实现是否正确。可２个人一组。 进程的状态 RUNNING - 进程正在使用CPU READY - 进程可使用CPU DONE - 进程结束 进程的行为 使用CPU, 发出YIELD请求,放弃使用CPU 进程调度 使用FIFO/FCFS：先来先服务, 先查找位于proc_info队列的curr_proc元素(当前进程)之后的进程(curr_proc+1..end)是否处于READY态， 再查找位于proc_info队列的curr_proc元素(当前进程)之前的进程(begin..curr_proc-1)是否处于READY态 如都没有，继续执行curr_proc直到结束 关键模拟变量 进程控制块PROC_CODE = 'code_' PROC_PC = 'pc_' PROC_ID = 'pid_' PROC_STATE = 'proc_state_' 当前进程 curr_proc 进程列表：proc_info是就绪进程的队列（list）， 在命令行（如下所示）需要说明每进程的行为特征：（１）使用CPU ;(2)等待I/O-l PROCESS_LIST, --processlist= X1:Y1,X2:Y2,... X 是进程的执行指令数; Ｙ是执行CPU的比例(0..100) ，如果是100，表示不会发出yield操作 进程切换行为：系统决定何时(when)切换进程:进程结束或进程发出yield请求 进程执行 instruction_to_execute = self.proc_info[self.curr_proc][PROC_CODE].pop(0) 关键函数 系统执行过程：run 执行状态切换函数:　move_to_ready/running/done　 调度函数：next_proc 执行实例 例１ $./process-simulation.py -l 5:50 Process 0 yld yld cpu cpu yld Important behaviors: System will switch when the current process is FINISHED or ISSUES AN YIELD Time PID: 0 1 RUN:yld 2 RUN:yld 3 RUN:cpu 4 RUN:cpu 5 RUN:yld 例２ $./process-simulation.py -l 5:50,5:50 Produce a trace of what would happen when you run these processes: Process 0 yld yld cpu cpu yld Process 1 cpu yld cpu cpu yld Important behaviors: System will switch when the current process is FINISHED or ISSUES AN YIELD Time PID: 0 PID: 1 1 RUN:yld READY 2 READY RUN:cpu 3 READY RUN:yld 4 RUN:yld READY 5 READY RUN:cpu 6 READY RUN:cpu 7 READY RUN:yld 8 RUN:cpu READY 9 RUN:cpu READY 10 RUN:yld READY 11 RUNNING DONE "},"all/05-2-quiz.html":{"url":"all/05-2-quiz.html","title":"lec12 在线练习","keywords":"","body":"lec12 进程控制　在线练习 选择题 关于进程切换描述正确的是（） s1 [x] 进程切换会暂停当前运行进程，使其从运行状态变成就绪等其他状态 [x] 进程切换要保存当前进程的上下文 [x] 进程切换要恢复下一个进程的上下文 [ ] 进程切换的进程上下文不包括CPU的寄存器等硬件信息 1,2,3 关于创建新进程的描述正确的是（） s2 [x] fork() 创建子进程中，会复制父进程的所有变量和内存 [x] 子进程的fork()返回0 [x] 父进程的fork()在创建子进程成功后，返回子进程标识符 [x] fork() 创建子进程中，会复制父进程的页表 都对 关于进程加载执行的描述正确的是（） s3 [x] 系统调用exec( )加载新程序取代当前运行进程 [x] 系统调用exec( )允许进程“加载”一个完全不同的程序，并从main开始执行 [x] exec调用成功时，它是相同的进程，但是运行了不同的程序 [x] exec调用成功时，代码段、堆栈和堆(heap)等完全重写了 都对 有关管理进程等待的描述正确的是（） s４ [x] wait()系统调用用于父进程等待子进程的结束 [x] 子进程结束时通过exit()向父进程返回一个值 [x] 当某子进程调用exit()时,唤醒父进程，将exit()返回值作为父进程中wait的返回值 [x] 进程结束执行时调用exit()，完成进程的部分占用资源的回收 都对 "},"all/05-2-spoc-discussion.html":{"url":"all/05-2-spoc-discussion.html","title":"lec12 SPOC讨论","keywords":"","body":"lec12: 进程／线程控制spoc练习 视频相关思考题 12.1 进程切换 进程切换的可能时机有哪些？ 分析ucore的进程切换代码，说明ucore的进程切换触发时机和进程切换的判断时机都有哪些。 ucore的进程控制块数据结构是如何组织的？主要字段分别表示什么？ 12.2 进程创建 fork()的返回值是唯一的吗？父进程和子进程的返回值是不同的。请找到相应的赋值代码。 新进程创建时的进程标识是如何设置的？请指明相关代码。 请通过fork()的例子中进程标识的赋值顺序说明进程的执行顺序。 请在ucore启动时显示空闲进程（idleproc）和初始进程（initproc）的进程标识。 请在ucore启动时显示空闲线程（idleproc）和初始进程(initproc)的进程控制块中的“pde_t *pgdir”的内容。它们是否一致？为什么？ 12.3 进程加载 加载进程后，新进程进入就绪状态，它开始执行时的第一条指令的位置，在elf中保存在什么地方？在加载后，保存在什么地方？ 第一个用户进程执行的代码在哪里？它是什么时候加载到内存中的？ 12.4 进程等待与退出 试分析wait()和exit()的结果放在什么地方？exit()是在什么时候放进去的？wait()在什么地方取到出的？ 试分析ucore操作系统内核是如何把子进程exit()的返回值传递给父进程wait()的？ 什么是僵尸进程和孤儿进程？ 试分析sleep()系统调用的实现。在什么地方设置的定时器？它对应的等待队列是哪个？它的唤醒操作在什么地方？ 通常的函数调用和函数返回都是一一对应的。有不是一一对应的例外情况？如果有，请举例说明。 小组思考题 (1) (spoc)设计一个简化的进程管理子系统，可以管理并调度支持“就绪”和“等待”状态的简化进程。给出了参考代码，请理解代码，并完成＂YOUR CODE\"部分的内容．　可２个人一组 进程的状态 - RUNNING - 进程正在使用CPU - READY - 进程可使用CPU - WAIT - 进程等待I/O完成 - DONE - 进程结束 进程的行为 - 使用CPU, - 发出YIELD请求,放弃使用CPU - 发出I/O操作请求,放弃使用CPU 进程调度 使用FIFO/FCFS：先来先服务, 只有进程done, yield, io时才会执行切换 先查找位于proc_info队列的curr_proc元素(当前进程)之后的进程(curr_proc+1..end)是否处于READY态， 再查找位于proc_info队列的curr_proc元素(当前进程)之前的进程(begin..curr_proc-1)是否处于READY态 如都没有，继续执行curr_proc直到结束 关键模拟变量 io_length : IO操作的执行时间 进程控制块PROC_CODE = 'code_' PROC_PC = 'pc_' PROC_ID = 'pid_' PROC_STATE = 'proc_state_' 当前进程 curr_proc 进程列表：proc_info是就绪进程的队列（list）， 在命令行（如下所示）需要说明每进程的行为特征：（１）使用CPU ;(2)等待I/O-l PROCESS_LIST, --processlist= X1:Y1,X2:Y2,... X 是进程的执行指令数; Ｙ是执行yield指令（进程放弃CPU,进入READY状态）的比例(0..100) Ｚ是执行I/O请求指令（进程放弃CPU,进入WAIT状态）的比例(0..100) 进程切换行为：系统决定何时(when)切换进程:进程结束或进程发出yield请求 进程执行 instruction_to_execute = self.proc_info[self.curr_proc][PROC_CODE].pop(0) 关键函数 系统执行过程：run 执行状态切换函数:　move_to_ready/running/done　 调度函数：next_proc 执行实例 例1 $./process-simulation.py -l 5:30:30,5:40:30 -c Produce a trace of what would happen when you run these processes: Process 0 io io yld cpu yld Process 1 yld io yld yld yld Important behaviors: System will switch when the current process is FINISHED or ISSUES AN YIELD or IO Time PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING RUN:yld 1 1 3 WAITING RUN:io 1 1 4 WAITING WAITING 2 5 WAITING WAITING 2 6* RUN:io WAITING 1 1 7 WAITING WAITING 2 8* WAITING RUN:yld 1 1 9 WAITING RUN:yld 1 1 10 WAITING RUN:yld 1 1 11* RUN:yld DONE 1 12 RUN:cpu DONE 1 13 RUN:yld DONE 1 "},"all/05-3-lab4-quiz.html":{"url":"all/05-3-lab4-quiz.html","title":"lec13-lab4 在线练习","keywords":"","body":"lec13: lab4 　在线练习 选择题 关于进程切换描述正确的是（） s1 [x] 进程切换会暂停当前运行进程，使其从运行状态变成就绪等其他状态 [x] 进程切换要保存当前进程的上下文 [x] 进程切换要恢复下一个进程的上下文 [ ] 进程切换的进程上下文不包括CPU的寄存器等硬件信息 1,2,3 关于创建新进程的描述正确的是（） s2 [x] fork() 创建子进程中，会复制父进程的所有变量和内存 [x] 子进程的fork()返回0 [x] 父进程的fork()在创建子进程成功后，返回子进程标识符 [x] fork() 创建子进程中，会复制父进程的页表 都对 关于进程加载执行的描述正确的是（） s3 [x] 系统调用exec( )加载新程序取代当前运行进程 [x] 系统调用exec( )允许进程“加载”一个完全不同的程序，并从main开始执行 [x] exec调用成功时，它是相同的进程，但是运行了不同的程序 [x] exec调用成功时，代码段、堆栈和堆(heap)等完全重写了 都对 有关管理进程等待的描述正确的是（） s４ [x] wait()系统调用用于父进程等待子进程的结束 [x] 子进程结束时通过exit()向父进程返回一个值 [x] 当某子进程调用exit()时,唤醒父进程，将exit()返回值作为父进程中wait的返回值 [x] 进程结束执行时调用exit()，完成进程的部分占用资源的回收 都对 "},"all/05-3-lab4-spoc-discussion.html":{"url":"all/05-3-lab4-spoc-discussion.html","title":"lec13-lab4 SPOC讨论","keywords":"","body":"lec13: lab4 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的ucore_code和os_exercises的git repo上。 视频相关思考题 13.1 总体介绍 为什么讲基本原理时先讲进程后讲线程，而在做实验时先做线程后做进程？ 实现会容易：只需要实现PCB中的子集TCB，不用关注PCB中的资源管理部分； ucore的线程控制块数据结构是什么？ 在ucore中只有一个PCB数据结构，进程和线程都使用这一个数据结构； 13.2 关键数据结构 分析proc_struct数据结构，说明每个字段的用途，是线程控制块或进程控制块的，会在哪些函数中修改。 寄存器状态、堆栈、当前指令指针等信息是线程控制块的； mm, vma等内存管理字段是进程控制块的； 如何知道ucore的两个线程同在一个进程？ 查看线程控制块中cr3是否一致； context和trapframe分别在什么时候用到？ trapframe在中断响应时用到；context在线程切换时用到； 用户态或内核态下的中断处理有什么区别？在trapframe中有什么体现？ 在用户态中断响应时，要切换到内核态；而在内核态中断响应时，没有这种切换； tf_esp, tf_ss字段 分析trapframe数据结构，说明每个字段的用途，是由硬件或软件保存的，在内核态中断响应时是否会保存。 tf_eip, tf_cs等由硬件保存；tf_esp, tf_ss等在用户态响应时由硬件保存； 通用寄存器由软件保存；( lab4/kern/trap/trapentry.S ) 13.3 执行流程 kernel_thread创建的内核线程执行的第一条指令是什么？它是如何过渡到内核线程对应的函数的？ tf.tf_eip = (uint32_t) kernel_thread_entry; /kern-ucore/arch/i386/init/entry.S /kern/process/entry.S 内核线程的堆栈初始化在哪？ setup_stack tf和context中的esp fork()父子进程的返回值是不同的。这在源代码中的体现中哪？ 内核线程initproc的第一次执行流程是什么样的？能跟踪出来吗？ 分析线程切换流程，找到内核堆栈、页表、寄存器切换的代码位置。 分析C语言中调用汇编函数switch_to()的参数传递位置。 分析内核线程idleproc的创建流程，说明线程切换后执行的第一条是什么。 proc->context.eip = forkret; tf.tf_eip = (uint32_t) kernel_thread_entry; 分析内核线程initproc的创建流程，说明线程切换后执行的第一条是什么。 小组练习与思考题 (1)(spoc) 理解内核线程的生命周期。 需写练习报告和简单编码，完成后放到git server 对应的git repo中 掌握知识点 内核线程的启动、运行、就绪、等待、退出 内核线程的管理与简单调度 内核线程的切换过程 练习用的lab4 spoc exercise project source code 请完成如下练习，完成代码填写，并形成spoc练习报告 1. 分析并描述创建分配进程的过程 注意 state、pid、cr3，context，trapframe的含义 练习2：分析并描述新创建的内核线程是如何分配资源的 注意 理解对kstack, trapframe, context等的初始化 当前进程中唯一，操作系统的整个生命周期不唯一，在get_pid中会循环使用pid，耗尽会等待 练习3： 阅读代码，在现有基础上再增加一个内核线程，并通过增加cprintf函数到ucore代码中 能够把内核线程的生命周期和调度动态执行过程完整地展现出来 练习4 （非必须，有空就做）： 增加可以睡眠的内核线程，睡眠的条件和唤醒的条件可自行设计，并给出测试用例，并在spoc练习报告中给出设计实现说明 扩展练习1: 进一步裁剪本练习中的代码，比如去掉页表的管理，只保留段机制，中断，内核线程切换，print功能。看看代码规模会小到什么程度。 思考： switch_to函数的汇编码与编译器生成的C函数的汇编码区别是什么？能否用C语言实现switch_to函数？为什么？ "},"all/05-4-lab5-quiz.html":{"url":"all/05-4-lab5-quiz.html","title":"lec14-lab5 在线练习","keywords":"","body":"lec14: lab５ 用户进程　在线练习 选择题 下列叙述中正确的是() s2 [ ] lab５建立了用户进程，且0~3GB都是用户可访问空间，用户进程可进行正常读写 [ ] lab５建立了用户进程，且3GB～４GB都是内核可访问空间，内核可进行正常读写 [x] lab5中的第一个用户进程是内核创建的。 [x] lab5中的用户进程可通过fork创建新的用户进程。 3,4 lab5通过do_execve函数执行新的程序，为此需要完成（） s3 [x] 更新用户进程的context [x] 更新用户进程的代码内容 [x] 更新用户进程的数据内容 [ ] 更新用户进程的页表基址 1,2,3,4 lab5通过do_icode函数执行新的程序，为此需要完成（）s4 [x] 设置用户堆栈 [x] 修改页表 [x] 根据ELF执行文件的格式描述分配内存并填写内容 [x] 设置用户态的EFLAG寄存器不可屏蔽中断 都包括 关于进程管理的COW(Copy On Write)机制叙述正确的是（）s6 [ ] 父进程创建子进程需要复制父进程的内存空间 [ ] 父进程创建子进程需要给子进程分配内核堆栈 [ ] 父进程创建子进程需要给子进程分配用户堆栈 [x] 父进程创建子进程需要创建子进程的页表,但不复制父进程内存空间 4 "},"all/05-4-lab5-spoc-discussion.html":{"url":"all/05-4-lab5-spoc-discussion.html","title":"lec14-lab5 SPOC讨论","keywords":"","body":"lec14: lab5 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的ucore_code和os_exercises的git repo上。 视频相关思考题 14.1 总体介绍 第一个用户进程创建有什么特殊的？ 用户态代码段的初始化 系统调用的参数传递过程？ 参见：用户态函数syscall()中的汇编代码； Ref: https://www.ibm.com/developerworks/library/l-ia/index.html getpid的返回值放在什么地方了？ 参见：用户态函数syscall()中的汇编代码； 14.2 进程的内存布局 ucore的内存布局中，页表、用户栈、内核栈在逻辑地址空间中的位置？ memlayout.h define VPT 0xFAC00000 define KSTACKPAGE 2 // # of pages in kernel stack define KSTACKSIZE (KSTACKPAGE * PGSIZE) // sizeof kernel stack define USERTOP 0xB0000000 define USTACKTOP USERTOP define USTACKPAGE 256 // # of pages in user stack define USTACKSIZE (USTACKPAGE * PGSIZE) // sizeof user stack (spoc)尝试在panic函数中获取并输出用户栈和内核栈的函数嵌套信息和函数调用参数信息，然后在你希望的地方人为触发panic函数，并输出上述信息。 (spoc)尝试在panic函数中获取和输出页表有效逻辑地址空间范围和在内存中的逻辑地址空间范围，然后在你希望的地方人为触发panic函数，并输出上述信息。 尝试在进程运行过程中获取内核空间中各进程相同的页表项（代码段）和不同的页表项（内核堆栈）？ 14.3 执行ELF格式的二进制代码-do_execve的实现 在do_execve中的的当前进程如何清空地址空间内容的？在什么时候开始使用新加载进程的地址空间？ 清空进程地址空间是在initproc所在进程地址空间 CR3设置成新建好的页表地址后，开始使用新的地址空间 新加载进程的第一级页表的建立代码在哪？ do_execve在处理中是如何正确区分出用户进程和线程的？并为此采取了哪些不同的处理？ 14.4 执行ELF格式的二进制代码-load_icode的实现 第一个内核线程和第一个用户进程的创建有什么不同？ 相应线程的内核栈创建时，多了SS和ESP的设置； 用户进程需要创建用户地址空间，并把用户代码复制到用户地址空间； 尝试跟踪分析新创建的用户进程的开始执行过程？ 14.5 进程复制 为什么新进程的内核堆栈可以先于进程地址空间复制进行创建？ 内核栈在进程的内核地址空间，而各进程的内核地址空间是共享的； 进程复制的代码在哪？复制了哪些内容？ 进程复制过程中有哪些修改？为什么要修改？ 内核栈 页表 trapframe context PCB字段修改 分析第一个用户进程的创建流程，说明进程切换后执行的第一条是什么。 14.6 内存管理的copy-on-write机制 什么是写时复制？ 写时复制的页表在什么时候进行复制？共享地址空间和写时复制有什么不同？ 存在有多个（n>2）进程具有父子关系，且采用了COW机制的情况。这个情况与只有父子两个进程的情况相比，在设计COW时，需要注意的新问题是什么？有何解决方案？ 小组练习与思考题 (1)(spoc) 在真实机器的u盘上启动并运行ucore lab, 请准备一个空闲u盘，然后请参考如下网址完成练习 https://github.com/chyyuu/ucore_lab/blob/master/related_info/lab1/lab1-boot-with-grub2-in-udisk.md 注意，grub_kernel的源码在ucore_lab的lab1_X的git branch上，位于 ucore_lab/labcodes_answer/lab1_result (报告可课后完成)请理解grub multiboot spec的含义，并分析ucore_lab是如何实现符合grub multiboot spec的，并形成spoc练习报告。 (2)(spoc) 理解用户进程的生命周期。 需写练习报告和简单编码，完成后放到网络学堂 OR git server 对应的git repo中 练习用的lab5 spoc exercise project source code 掌握知识点 用户进程的启动、运行、就绪、等待、退出 用户进程的管理与简单调度 用户进程的上下文切换过程 用户进程的特权级切换过程 用户进程的创建过程并完成资源占用 用户进程的退出过程并完成资源回收 注意，请关注：内核如何创建用户进程的？用户进程是如何在用户态开始执行的？用户态的堆栈是保存在哪里的？ 阅读代码，在现有基础上再增加一个用户进程A，并通过增加cprintf函数到ucore代码中， 能够把个人思考题和上述知识点中的内容展示出来：即在ucore运行过程中通过cprintf函数来完整地展现出来进程A相关的动态执行和内部数据/状态变化的细节。(约全面细致约好) 请完成如下练习，完成代码填写，并形成spoc练习报告 "},"all/8-sched.html":{"url":"all/8-sched.html","title":"CPU调度","keywords":"","body":"CPU调度 单选题 若当前进程因时间片用完而让出处理机时，该进程应转变为（）状态。 [x] 就绪 [ ] 等待 [ ] 运行 [ ] 完成 解释：只有处于就绪队列中的进程才能得到时间片，因此因为时间片用完而让出CPU的进程应该再次返回到就绪队列中。时间片是轮循调度算法中的概念，所有的进程都会按照顺序被分配一个时间片，当时间片用完时如果进程执没有结束，那么应该让出CPU进入就绪队列等待下一个属于自己的时间片。 最高响应比优先算法的特点是（） [ ] 有利于短作业但不利于长作业 [x] 有利于短作业又兼顾到长作业 [ ] 不利于短作业也不利于长作业 [ ] 不利于短作业但有利于长作业 解释：最高响应比优先算法的响应值公式为Ｒ＝（ｗ+s)/s，其中w为等待时间，s为服务时间，因此在等待时间相同的情况下优先选择服务时间短的进程，而当服务时间长的进程等待到一定时间后，其响应值会增加到能够被首先选择，避免了一直被服务时间短的进程超过，所以该算法有利于短作业又兼顾到长作业。 在单处理器的多进程系统中，进程什么时候占用处理器和能占用多长时间，取决于（） [ ] 进程相应的程序段的长度 [ ] 进程总共需要运行时间多少 [x] 进程自身和进程调度策略 [ ] 进程完成什么功能 解释：在单处理器的多进程系统中，系统是依靠所使用的调度策略来对进程进行调度的，而其所采用的调度策略可能不止一种，所以什么时候选择什么进程占用处理器和能占用多长时间并不仅仅取决于进程的某一项特性。 时间片轮转调度算法是为了（） [x] 多个终端都能得到系统的及时响应 [ ] 先来先服务 [ ] 优先级高的进程先使用CPU [ ] 紧急事件优先处理 解释：时间片轮转调度算法在选择进程时是按照到达时间进行选择的，所以不存在优先级高的进程，而每个进程每次只能占用同等的CPU时间，所以优先执行的进程并不一定比后执行的进程先完成，对于新加入的进程，只要是队列中等待的进程不是很多，都可以很及时地得到时间片来使用CPU，所以该算法能够使多个终端得到系统的及时响应。 在基于优先级的可抢占的调度机制中，当系统强制使高优先级任务等待低优先级任务时，会发生（） [x] 优先级反转 [ ] 优先级重置 [ ] 系统错误 [ ] 死循环 解释：优先级反转的定义：（1）可以发生在任何基于优先级的可抢占的调度机制中；（2）当系统内的环境强制使高优先级等待低优先级任务时发生。 下面关于硬时限（hard deadlines）和软时限（soft deadlines）的描述错误的是（）。 [ ] 如果错过了硬时限，将会发生严重的后果 [x] 硬时限是通过硬件实现的，软时限是通过软件实现的 [ ] 如果软时限没有被满足，系统也可以继续运行 [ ] 硬时限可以保证系统的确定性 解释：硬时限是指必须满足的时间限制，如果没有满足可能会导致非常严重的后果；软时限是指在理想情况下应该被满足的时间限制，如果没有被满足，系统可以降低对该时限的要求，以保证不会产生太严重的后果。 下面的调度算法中那个是公平的（） [ ] FCFS 先来先服务 [ ] SPN 短进程优先 [x] RR 轮循 [ ] SRT 解释：FCFS算法可能导致某些进程长时间占用CPU，所以并不公平；SPN算法可能会使长进程在很长时间内得不到响应，所以也不公平；RR算法由于每个进程都能及时得到响应，并且不会长时间占用CPU，所以是公平的；SRT也就是SPN。 FCFS调度算法的特点不包括（） [ ] 简单 [ ] 平均等待时间变化大 [x] 不会导致I/O和CPU之间的重叠处理 [ ] 花费时间少的任务可能排在花费时间长的任务后面 解释：FCFS算法的优点是简单，缺点有（1）平均等待时间变化较大；（2）花费时间较少的任务可能排在花费时间较长的任务后面；（3）可能导致i/o和CPU之间的重叠处理。 CPU调度策略的目标不包括（） [ ] 减少响应时间 [x] 提高系统处理单任务的速度 [ ] 减少等待时间 [ ] 增加吞吐量 解释：系统处理单任务的速度不能通过CPU调度策略来改善，只能通过改善硬件性能和改良系统架构来提高。 有5个批处理作业(A,B,C,D,E)几乎同时到达一个计算中心,估计运行时间分别为2,4,6,8,10分钟,在使用时间片轮转作法（时间片为2分钟）,作业的平均周转时间为（） [x] 18分钟 [ ] 6分钟 [ ] 14分钟 [ ] 22分钟 解释：进程A在第一次时间片轮转后就完成了，所以等待时间为0；进程B在第二次时间片轮转后完成，等待时间为2+23=8；进程C在第三次时间片轮转后完成，等待时间为2+2+22+2+2*2=14；进程D在第四次时间片轮转后完成，等待时间为2+2+2+2+2+2+2+2=18；进程E在第五次时间片轮转后完成，等待时间为2+2+2+2+2+2+2+2+2+2+2=20；因此总的周转时间为2+0+4+8+6+14+8+18+10+20=90，所以平均周转时间为90/5=18。 多选题 对上下文切换的描述正确的是（） [x] 切换CPU的当前任务到另一个任务 [ ] 不需要保存当前进程在PCB/TCP中的执行上下文 [x] 需要读取下一个进程的上下文 [ ] 只能读取没有被执行过的进程 解释：上下文切换的相关概念：（1）切换CPU的当前任务，从一个进程到另一个进程；（2）保存当前进程在PCB/TCP的执行上下文；（3）读取下一个进程的上下文。被切换的进程可以是新来的，也可以是之前没有执行完的。 可以作为进程调度算法的有（）。 [x] 先来先服务调度算法 [x] 时间片轮转调度算法 [ ] 最高优先级调度算法 [x] 最高响应比优先调度算法 [ ] 均衡调度算法 解释：不存在最高优先级调度算法和均衡调度算法。 下面可以作为比较调度算法的指标有（） [x] CPU使用率 [x] 吞吐量 [x] 周转时间 [x] 等待时间 [x] 响应时间 解释：衡量调度算法的5个方面：CPU使用率，吞吐量，周转时间，等待时间和响应时间。 CPU调度策略可以通过哪几种方式增加系统的吞吐量（） [x] 减少操作系统开销 [x] 减少上下文切换次数 [ ] 加快系统处理单个任务的速度 [x] 高效利用系统资源 解释：增加吞吐量可以从两个方面入手：（1）减少开销（操作系统开销，上下文切换）；（2）系统资源的高效利用（CPU，I/O设备）。 下面对FFS公平共享调度控制用户对系统资源的访问的描述中，正确的是（） [ ] 所有的用户组都是平等的 [x] 能够保证不重要的用户组无法垄断资源 [x] 未使用的资源按照每个组所分配的资源的比例来分配 [x] 没有达到资源使用率目标的组可以获得更高的优先级 解释：公平共享调度控制用户对系统资源的访问：（1）一些用户组比其他用户组重要；（2）保证不重要的组无法垄断资源；（3）未使用的资源按照每个组所分配的资源的比例来分配；（3）没有达到资源使用率目标的组获得更高的优先级。 判断题 作业调度选择一个作业装入主存后，该作业能否占用处理器必须由作业控制来决定。 [ ] 对 [x] 错 解释：作业能够占用处理器是由进程调度来决定的。 在进行作业调度时，要想兼顾作业等待时间和计算时间，可选取响应比高者优先算法。 [x] 对 [ ] 错 解释：最高响应比优先算法的公式为Ｒ＝（ｗ+s)/s，其中w为等待时间，s为计算时间，所以兼顾作业的等待时间和计算时间。 在作业调度时, 采用最高响应比优先的作业调度算法可以得到最短的作业平均周转时间。 [ ] 对 [x] 错 解释：短进程优先算法的平均等待时间最小。 轮循算法的时间量子越大越好。（错） [ ] 对 [x] 错 解释：轮循算法的时间量子太大的话会导致进程等待的时间过长，极限情况下会退化成FCFS。 可抢占式的调度算法比不可抢占式的调度算法开销要小。（错） [ ] 对 [x] 错 解释：可抢占式的调度算法比不可抢占式的调度算法开销要大，因为其上下文切换比不可抢占式的要多。 "},"all/06-1-quiz.html":{"url":"all/06-1-quiz.html","title":"lec15 在线练习","keywords":"","body":"lec15: 处理器调度　在线练习 选择题 若当前进程因时间片用完而让出处理机时，该进程应转变为（）状态。 s1 [x] 就绪 [ ] 等待 [ ] 运行 [ ] 完成 1 最高响应比优先算法的特点是（） s3 [ ] 有利于短作业但不利于长作业 [x] 有利于短作业又兼顾到长作业 [ ] 不利于短作业也不利于长作业 [ ] 不利于短作业但有利于长作业 2 在单处理器的多进程系统中，进程什么时候占用处理器和能占用多长时间，取决于（） s4 [ ] 进程相应的程序段的长度 [ ] 进程总共需要运行时间多少 [x] 进程自身和进程调度策略 [ ] 进程完成什么功能 3 时间片轮转调度算法是为了（） s4 [x] 多个终端都能得到系统的及时响应 [ ] 先来先服务 [ ] 优先级高的进程先使用CPU [ ] 紧急事件优先处理 1 下面关于硬时限（hard deadlines）和软时限（soft deadlines）的描述错误的是（）。s5 [ ] 如果错过了硬时限，将会发生严重的后果 [x] 硬时限是通过硬件实现的，软时限是通过软件实现的 [ ] 如果软时限没有被满足，系统也可以继续运行 [ ] 硬时限可以保证系统的确定性 2 在基于优先级的可抢占的调度机制中，当系统强制使高优先级任务等待低优先级任务时，会发生（）s6 [x] 优先级反转 [ ] 优先级重置 [ ] 系统错误 [ ] 死循环 1 "},"all/06-1-spoc-discussion.html":{"url":"all/06-1-spoc-discussion.html","title":"lec15 SPOC讨论","keywords":"","body":"lec15: 调度算法概念 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学要在实体课上完成，并按时提交到学生对应的ucore_code和os_exercises的git repo上。 视频相关思考题 15.1 处理机调度概念 处理机调度的功能是什么？ 选线程：从就绪队列中挑选下一个占用CPU运行的线程 选CPU：从多个可用CPU中挑选就绪线程可使用的CPU资源 在什么时候可以进行处理机调度？ 调度时机的所有可能： 占用CPU运行的线程的主动放弃（退出、等待） 当前线程被抢先（时间片用完、高优先级线程就绪） 当操作系统的处理机调度导致线程切换时，暂停线程的当前指令指针可能在什么位置？用户态代码或内核代码？给出理由。 系统调用返回时可能出现线程切换 15.2 调度准则 处理机的使用模式有什么特征？ CPU与I/O交替使用； 每次占用CPU执行指令的时间长度分布多数在10ms以内； 处理机调度的目标是什么？ CPU利用率（CPU使用率、吞吐率、周转时间、等待时间） 用户感受（周转时间、等待时间、响应时间、响应时间的方差） 公平性（CPU时间分配公平性） 尝试在ucore上写一个外排序程序，然后分析它的执行时间分布统计（每次切换后开始执行时间和放弃CPU的时间、当前用户和内核栈信息）。 在Linux上有一个应用程序time，可以统计应用程序的执行时间信息。请分析它是如何统计进程执行时间信息的。如可能，请在ucore上实现相同功能的应用程序。下面是可能的参考。 Linux用户态程序计时方式详解 Get Source Code for any Linux Command How does time command work https://github.com/illumos/illumos-gate/blob/master/usr/src/cmd/time/time.c 尝试获取一个操作系统的调度算法的性能统计数据（CPU使用率、进程执行）。 15.3 先来先服务、短进程优先和最高响应比优先调度算法 尝试描述下列处理机调度算法的工作原理和算法优缺点。 先来先服务算法（FCFC、FIFO） 短进程优先算法（SPN、SJF） 最高响应比优先算法（HRRN） 就绪队列的排队依据：到达时间、进程预期执行时间、按响应比R=(w+s)/s 算法特征：平均等待时间、等待时间方差、资源利用率 为什么短进程优先算法的平均周转时间最优？ 可以证明知进程优先算法的调度顺序的平均周转时间是最短的。 如何调试你的调度算法？ 监控调度算法的执行状态、调度结果、算法特征等信息。 15.4 时间片轮转、多级反馈队列、公平共享调度算法和ucore调度框架 尝试描述下列处理机调度算法的工作原理和算法优缺点。 时间片轮转算法（RR） 多级反馈队列算法（MLFQ） 公平共享调度算法（FSS） 让出CPU的条件：进程执行时间 就绪队列排队依据：多队列、多种排队依据、依据进程特征调整所在队列 算法特征：响应时间、平均周转时间、不同类型进程的调度差异 RR算法选择时间片长度的依据有哪些？ 进程切换开销 进程当前操作占用的CPU时间 切换开销与响应时间的折中权衡 请描述在MLFQ中，如何提升或降低进程的优先级？ I/O操作后提升优先级 时间片用完后降低优先级 尝试跟踪ucore中进程切换和调度算法的就绪进程选择过程。 中断响应、进程的中断现场保存、中断处理、调度判断、进程切换、新进程的中断现场恢复、新进程的继续执行 为什么要引入调度框架？定义调度算法接口需要考虑哪些因素？ 引入调度框架的目的：分离调度操作和调度策略，以支持多种调度算法； 定义调度算法接口的考虑因素：调度算法需要的调度操作类型、调度算法在各调度操作中的体现方式； 通过观察FIFO、SJF和RR调度算法的模拟程序运行结果及其描述文档，理解其工作原理和算法特征。 通过观察MLFQ调度算法的模拟程序运行结果及其描述文档，理解其工作原理和算法特征。 通过观察彩票调度算法(Lottery scheduling)的模拟程序运行结果及其描述文档，理解其工作原理和算法特征。 15.5 实时调度和多处理器调度 什么是实时操作系统？ 实时操作系统是保证在一定时间限制内完成特定功能的操作系统。 参考： http://baike.baidu.com/item/%E5%AE%9E%E6%97%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F 什么是可调度性？ 可调度表示一个实时操作系统能够满足任务时限要求 尝试描述下列处理机调度算法的工作原理和算法优缺点。 速率单调调度算法(RM, Rate Monotonic) 最早截止时间优先算法 (EDF, Earliest Deadline First) 任务优先级定义：按周期大小排队、按截止时间先后排队 RM的可调度条件：CPU利用率小于ln2时，是可调度的。 EDF的可调度条件：CPU利用率小于100%。 有兴趣的同学，请阅读下面论文，然后说明实时调度面临的主要困难是什么？ Buttazzo, “Rate monotonic vs. EDF: Judgement Day”, EMSOFT 2003. 单调速率及其扩展算法的可调度性判定 多处理机调度中每个处理机一个就绪队列与整个系统一个就绪队列有什么不同？ 区别：调度开销、负载均衡程度 15.6 优先级反置 什么是优先级反置现象？ 操作系统中出现高优先级进程长时间等待低优先级进程所占用资源的现象 什么是优先级继承(Priority Inheritance)和优先级天花板协议(priority ceiling protocol)？它们的区别是什么？ 优先级继承：占用资源的低优先级进程继承申请资源的高优先级进程的优先级 优先级天花板协议：占用资源进程的优先级和所有可能申请该资源的进程的最高优先级相同 区别：提升占用资源的低优先级进程的优先级的时机不同 在单CPU情况下，基于以前的OS知识，能否设计一个更简单的方法（也许执行效率会低一些）解决优先级反置现象？ ppt中“优先级继承”页里的图示有误，你能指出来吗？ 小组练习与思考题 参考往届同学的处理机调度算法实现练习，从下列8个算法中选择一个你感兴趣的调度算法，对其实现进行完善，并分析算法特征。 2016春季-第十五讲 课堂思考题回答-向勇班 陈渝班-2016春季-第15讲 课堂思考题回答 (1)(spoc) 理解并实现FIFO调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 请参考scheduler-homework.py代码或独自实现。 最后统计采用不同调度算法的每个任务的相关时间和总体的平均时间： 　- turnaround time　周转时间 　- response time 响应时间 　- wait time　等待时间 对模拟环境的抽象 任务/进程，及其执行时间 Job 0 (length = 1) Job 1 (length = 4) Job 2 (length = 7) 何时切换？ 如何统计？ 执行结果 采用FIFO调度算法 ./scheduler-homework.py -p FIFO ARG policy FIFO ARG jobs 3 ARG maxlen 10 ARG seed 0 Here is the job list, with the run time of each job: Job 0 ( length = 9 ) Job 1 ( length = 8 ) Job 2 ( length = 5 ) ** Solutions ** Execution trace: [ time 0 ] Run job 0 for 9.00 secs ( DONE at 9.00 ) [ time 9 ] Run job 1 for 8.00 secs ( DONE at 17.00 ) [ time 17 ] Run job 2 for 5.00 secs ( DONE at 22.00 ) Final statistics: Job 0 -- Response: 0.00 Turnaround 9.00 Wait 0.00 Job 1 -- Response: 9.00 Turnaround 17.00 Wait 9.00 Job 2 -- Response: 17.00 Turnaround 22.00 Wait 17.00 Average -- Response: 8.67 Turnaround 16.00 Wait 8.67 (2)(spoc) 理解并实现SJF调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 执行结果 采用SJF调度算法 ./scheduler-homework.py -p SJF ARG policy SJF ARG jobs 3 ARG maxlen 10 ARG seed 0 Here is the job list, with the run time of each job: Job 0 ( length = 9 ) Job 1 ( length = 8 ) Job 2 ( length = 5 ) ** Solutions ** Execution trace: [ time 0 ] Run job 2 for 5.00 secs ( DONE at 5.00 ) [ time 5 ] Run job 1 for 8.00 secs ( DONE at 13.00 ) [ time 13 ] Run job 0 for 9.00 secs ( DONE at 22.00 ) Final statistics: Job 2 -- Response: 0.00 Turnaround 5.00 Wait 0.00 Job 1 -- Response: 5.00 Turnaround 13.00 Wait 5.00 Job 0 -- Response: 13.00 Turnaround 22.00 Wait 13.00 Average -- Response: 6.00 Turnaround 13.33 Wait 6.00 (3)(spoc) 理解并实现RR调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 执行结果 采用RR调度算法 ./scheduler-homework.py -p RR ARG policy RR ARG jobs 3 ARG maxlen 10 ARG seed 0 Here is the job list, with the run time of each job: Job 0 ( length = 9 ) Job 1 ( length = 8 ) Job 2 ( length = 5 ) ** Solutions ** Execution trace: [ time 0 ] Run job 0 for 1.00 secs [ time 1 ] Run job 1 for 1.00 secs [ time 2 ] Run job 2 for 1.00 secs [ time 3 ] Run job 0 for 1.00 secs [ time 4 ] Run job 1 for 1.00 secs [ time 5 ] Run job 2 for 1.00 secs [ time 6 ] Run job 0 for 1.00 secs [ time 7 ] Run job 1 for 1.00 secs [ time 8 ] Run job 2 for 1.00 secs [ time 9 ] Run job 0 for 1.00 secs [ time 10 ] Run job 1 for 1.00 secs [ time 11 ] Run job 2 for 1.00 secs [ time 12 ] Run job 0 for 1.00 secs [ time 13 ] Run job 1 for 1.00 secs [ time 14 ] Run job 2 for 1.00 secs ( DONE at 15.00 ) [ time 15 ] Run job 0 for 1.00 secs [ time 16 ] Run job 1 for 1.00 secs [ time 17 ] Run job 0 for 1.00 secs [ time 18 ] Run job 1 for 1.00 secs [ time 19 ] Run job 0 for 1.00 secs [ time 20 ] Run job 1 for 1.00 secs ( DONE at 21.00 ) [ time 21 ] Run job 0 for 1.00 secs ( DONE at 22.00 ) Final statistics: Job 0 -- Response: 0.00 Turnaround 22.00 Wait 13.00 Job 1 -- Response: 1.00 Turnaround 21.00 Wait 13.00 Job 2 -- Response: 2.00 Turnaround 15.00 Wait 10.00 Average -- Response: 1.00 Turnaround 19.33 Wait 12.00 (4)理解并实现MLFQ调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 (5)理解并实现stride调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 (6)理解并实现EDF实时调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 (7)理解并实现RM实时调度算法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 (8)理解并实现优先级反置方法 可基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现，并给出测试，在试验报告写出设计思路和测试结果分析。 "},"all/06-2-lab6-quiz.html":{"url":"all/06-2-lab6-quiz.html","title":"lec16-lab6 在线练习","keywords":"","body":"lec16: lab6 调度算法　在线练习 选择题 lab6的调度过程包括() s2 [x] 触发：trigger scheduling　 [x] 入队：‘enqueue’ [x] 选取：pick up [x] 出队：‘dequeue’ [x] 切换：process switch 全部 lab6中涉及到的调度点包括（） s3 [x] proc.c:do_exit　户线程执行结束，主动放弃CPU [x] proc.c:do_wait　用户线程等待子进程结束，主动放弃CPU [x] proc.c::cpu_idle　idleproc内核线程选取一个就绪进程并切换 [x] ｔrap.c::trap　　若时间片用完，则设置need_resched为1，让当前进程放弃CPU 全部 lab6调度算法支撑框架包括的函数指针有（）s4 [x] (enqueue)(struct run_queue rq, …); [x] (dequeue)(struct run_queue rq, …); [x] (pick_next)(struct run_queue rq); [x] (proc_tick)(struct run_queue rq, …); 都包括 lab6调度算法支撑框架中与时钟中断相关的函数指针有（）s4 [ ] (enqueue)(struct run_queue rq, …); [ ] (dequeue)(struct run_queue rq, …); [ ] (pick_next)(struct run_queue rq); [x] (proc_tick)(struct run_queue rq, …); 4 lab6中的RR调度算法在( )时对当前进程的完成时间片的递减 s5 [ ] 等待进程结束　 [ ] 进程退出 [ ] 进程睡眠 [x] 进程被时钟中断打断 4 "},"all/06-2-lab6-spoc-discussion.html":{"url":"all/06-2-lab6-spoc-discussion.html","title":"lec16-lab6 SPOC讨论","keywords":"","body":"lec16: lab6 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 16.1 总体介绍 进程控制块中与调度相关的字段有哪些？在什么情况下会对其进行修改？ volatile bool need_resched; // bool value: need to be rescheduled to release CPU? uint32_t wait_state; // waiting state list_entry_t run_link; // the entry linked in run queue int time_slice; // time slice for occupying the CPU skew_heap_entry_t lab6_run_pool; // FOR LAB6 ONLY: the entry in the run pool uint32_t lab6_stride; // FOR LAB6 ONLY: the current stride of the process uint32_t lab6_priority; // FOR LAB6 ONLY: the priority of process, set by lab6_set_priority(uint32_t) ucore的就绪队列数据结构在哪定义？在哪进行修改？ kern/schedule/sched.c static struct run_queue __rq; ucore的等待队列数据结构在哪定义？在哪进行修改？ kern/schedule/sched.c static list_entry_t timer_list; 尝试跟踪ucore中的调度过程。 中断响应、线程的中断现场保存、中断处理、调度触发、当前线程入队、选取下一个运行线程、下一个运行线程出队、线程切换、新线程的中断现场恢复、新线程的继续执行 16.2 调度算法支撑框架 调度算法支撑框架中的各个函数指针的功能是啥？会被谁在何种情况下调用？ 初始化、触发、选取、出队、入队、切换 调度函数schedule()的调用函数分析，了解进程调度的原因。请分析ucore中所有可能的调度位置，并说明可能的调用原因。 do_exit do_wait cpu_idle lock init_main trap 16.3 时间片轮转调度算法 时间片轮转调度算法是如何基于调度算法支撑框架实现的？ kern/schedule/default_sched.c struct sched_class default_sched_class 还需要分析并确定调度算法的实现会依赖哪些内核数据和对哪些内核数据有影响； 时钟中断如何调用RR_proc_tick()的？ 时钟中断时会检查时间片的计数，到达零（时间片用完）时，设置可调度标志（need_resched）。 16.4 stride调度算法 stride调度算法的思路？ 步长值stride 步进值pass 以步长为优先级的动态优先级调度算法；每次执行一个时间片，时间片用完时，优先级增加量为“步进”值。 stride算法的特征是什么？ 动态优先级调度算法 确定的调度顺序 线程的执行时间与步进值的倒数成正比 stride调度算法是如何避免stride溢出问题的？ 利用无符号数的有符号比较，从而避免步长值修改时的溢出处理； 无符号数的有符号比较会产生什么效果？ 无符号数的有符号比较会产生什么效果？ 什么是斜堆(skew heap)？斜堆在stride算法的实现中有什么用？ 参考文档：Skew heap 斜堆 斜堆的堆顶是优先级最小的节点；斜堆的合并时间开销为O(logN)，删除最小节点操作和插入操作都可以转换成合并操作，开销很小； 小组练习与思考题 (1)(spoc) 跟踪和展现ucore的处理机调度过程 基于对“视频相关思考题”中16.2节第2小题的回答，在ucore执行处理机调度时，选择一种调度情况进行跟踪并显示上一个让出CPU线程的暂停代码位置和下一个进入执行状态线程的开始执行位置。 (2)(spoc) 理解调度算法支撑框架的执行过程 即在ucore运行过程中通过cprintf函数来完整地展现出来多个进程在调度算法和框架的支撑下，在相关调度点如何动态调度和执行的细节。(越全面细致越好) 请完成如下练习，完成代码填写，并形成spoc练习报告 需写练习报告和简单编码，完成后放到git server 对应的git repo中 练习用的lab6 spoc exercise project source code "},"all/9-sync.html":{"url":"all/9-sync.html","title":"同步","keywords":"","body":"同步 单选题 操作系统中，两个或多个并发进程各自占有某种资源而又都等待别的进程释放它们所占有的资源的现象叫做什么（） [ ] 饥饿 [x] 死锁 [ ] 死机 [ ] 死循环 解释：饥饿状态的进程不会进入等待状态，死锁是指两个或多个进程各自占有某种资源而又等待别的进程释放其所占有的资源。 临界资源是什么类型的共享资源（） [ ] 临界资源不是共享资源 [ ] 用户共享资源 [x] 互斥共享资源 [ ] 同时共享资源 解释：临界资源是指能够被多个进程共享，但是同一时间只能由一个进程访问的资源，因此是互斥的。 要想进程互斥地进入各自的同类资源的临界区，需要（） [ ] 在进程间互斥使用共享资源 [ ] 在进程间非互斥使用临界资源 [x] 在进程间互斥地使用临界资源 [ ] 在进程间不使用临界资源 解释：临界资源位于临界区，共享资源不一定位于临界区，因此无法保证进程进入临界区；非互斥使用临界资源和不使用临界资源均无法保证进程互斥地进入临界区，因为不存在临界资源的互斥使用的话个进程之间不存在互斥关系。 一个进程由阻塞队列进入就绪队列，可能发生了哪种情况（） [x] 一个进程释放一种资源 [ ] 系统新创建了一个进程 [ ] 一个进程从就绪队列进入阻塞队列 [ ] 一个在阻塞队列中的进程被系统取消了 解释：一个进程释放了一种资源后，可能该资源正是位于阻塞队列中的一个进程所必需的资源，因此该进程便可以从阻塞队列进入就绪队列；其余三种情况均不会使某个进程从阻塞队列进入就绪队列。 设两个进程共用一个临界区的互斥信号量mutex，当一个进程进入了临界区，另一个进程等待时，mutex应该等于多少（） [x] -1 [ ] 0 [ ] 1 [ ] 2 解释：两个进程共用一个临界区的互斥信号量mutex，那么mutex的取值范围应该是1到-1，1表示没有进程进入临界区并且也没有进程等待，0表示有一个进程进入临界区，-1表示有一个进程进入临界区并且另一个进程等待。 共享变量是指（）访问的变量 [ ] 只能被系统进程 [ ] 只能被多个进程互斥 [ ] 只能被用户进程 [x] 可被多个进程 解释：共享变量可以被多个进程访问，并且不需要互斥访问，可以访问的进程既可以是系统进程，也可以是用户进程。 临界区是指并发进程中访问共享变量的（）段 [ ] 管理信息 [ ] 信息存储 [ ] 数据 [x] 程序 解释：临界区是指进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域。 假定在一个处理机上执行以下五个作业，其中采用HRN（最高响应比优先）算法时第三个被选择的作业号是（） 作业号 到达时间 运行时间 A 0 4 B 1 3 C 2 5 D 3 2 E 4 4 [ ] A [ ] B [ ] C [x] D [ ] E 解释：A到达时没有其他进程到达，所以先处理A，当A处理完时其余所有进程都到达，此时计算各自的响应比：B=(3+3)/3=2, C=(2+5)/5=1.4, D=(1+2)/2=1.5, E=4/4=1。所以第二个被选择的是B，B完成后再次计算响应比：C=(5+5)/5=2, D=(4+2)/2=3, E=(3+4)/4=1.75，所以第三个被选择的是D。 下面关于Bakery算法的描述错误的是（） [ ] 进入临界区前，每个进程都会得到一个数字 [ ] 得到数字最小的进程可以进入临界区 [x] 如果P2和P4两个进程得到的数字相同，那么P4先进入临界区 [ ] 数字是按照从小到大生成的\\ 解释：Bakery算法描述：（1）进入临界区之前，进程接收一个数字；（2）得到的数字最小的进入临界区；（3）如果进程Pi和Pj收到相同的数字，那么如果i Peterson算法是解决Pi和Pj之间互斥的经典的（）的解决方法 [ ] 基于中断禁用 [x] 基于软件 [ ] 基于硬件 [ ] 基于原子操作 解释：Peterson算法是满足进程Pi和Pj之间互斥的经典的基于软件的解决方法（1981年）。 如果有5个进程共享同一程序段，每次允许3个进程进入该程序段，若用PV操作作为同步机制则信号量S为-1时表示什么（） [ ] 有四个进程进入了该程序段 [ ] 有一个进程在等待 [x] 有三个进程进入了程序段，有一个进程在等待 [ ] 有一个进程进入了该程序段，其余四个进程在等待 解释：S初始为3，当有一个进程进入程序段或等待时，S减一. S为-1，意味着有四次减1的操作，也即3个进程获准进入，1个在等待。 多选题 产生死锁的必要条件（1345） [x] 互斥 [ ] 可抢占 [x] 不可抢占 [x] 占有且申请 [x] 循环等待 解释：产生死锁的四个必要条件：（1）互斥--一个资源每次只能给一个进程使用（2）不可抢占--资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放（3）占有且申请--一个进程在申请新的资源的同时保持对原有资源的占有（只有这样才是动态申请，动态分配）（4）循环等待--存在一个进程等待队列 {P1 , P2 , … , Pn}, 其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路。 锁的实现方法有哪几种（124） [x] 禁用中断 [x] 软件方法 [ ] 添加硬件设备 [x] 原子操作指令 解释：实现锁机制的三种方法：禁用中断（仅限于单处理器），软件方法（复杂）和原子操作指令（单处理器或多处理器均可）。锁机制是高等级的编程抽象，因此无法使用硬件设备实现。 判断题 产生死锁的根本原因是供使用的资源数少于需求资源的进程数。 [x] 对 [ ] 错 解释：死锁是指两个或多个进程各自占有某种资源而又等待别的进程释放其所占有的资源，因此根本原因就是提供的资源少于需求的资源。 一旦出现死锁, 所有进程都不能运行。 [ ] 对 [x] 错 解释：出现死锁后，处于死锁状态的进程无法继续运行，但是其他无关的进程可以继续运行。 所有进程都挂起时, 系统陷入死锁。 [ ] 对 [x] 错 解释：死锁是指两个或多个进程各自占有某种资源而又等待别的进程释放其所占有的资源。所有进程都挂起并不代表其无法被完成。 参与死锁的所有进程都占有资源。 [ ] 对 [x] 错 解释：应该是参与死锁的所有进程都等待资源。不占有资源的进程也可能进入死锁。 有m个进程的操作系统出现死锁时, 死锁进程的个数为1 [x] 对 [ ] 错 解释：死锁并不会将所有的进程都牵扯进去，但出现死锁时一定会有进程参与。 进程间的互斥是一种特殊的同步关系。 [x] 对 [ ] 错 解释：基本概念，互斥是实现同步的一种方式，因此也代表一种同步关系。 所有进程都进入等待状态时，系统陷入死锁。 [ ] 对 [x] 错 解释：产生死锁的四个必要条件：（1）互斥--一个资源每次只能给一个进程使用（2）不可抢占--资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放（3）占有且申请--一个进程在申请新的资源的同时保持对原有资源的占有（只有这样才是动态申请，动态分配）（4）循环等待--存在一个进程等待队列 {P1 , P2 , … , Pn}, 其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路。 "},"all/07-1-quiz.html":{"url":"all/07-1-quiz.html","title":"lec17 在线练习","keywords":"","body":"lec17: 同步互斥　在线练习 选择题 临界资源是什么类型的共享资源（） s2 [ ] 临界资源不是共享资源 [ ] 用户共享资源 [x] 互斥共享资源 [ ] 同时共享资源 ３ 操作系统中，两个或多个并发进程各自占有某种资源而又都等待别的进程释放它们所占有的资源的现象叫做什么（） s２ [ ] 饥饿 [x] 死锁 [ ] 死机 [ ] 死循环 ２ 共享变量是指（）访问的变量　s2 [ ] 只能被系统进程 [ ] 只能被多个进程互斥 [ ] 只能被用户进程 [x] 可被多个进程 ４ 要想进程互斥地进入各自的同类资源的临界区，需要（） s3 [ ] 在进程间互斥使用共享资源 [ ] 在进程间非互斥使用临界资源 [x] 在进程间互斥地使用临界资源 [ ] 在进程间不使用临界资源 3 锁的实现方法有哪几种（） s4 [x] 禁用中断 [x] 软件方法 [ ] 添加硬件设备 [x] 原子操作指令 124 一个进程由阻塞队列进入就绪队列，可能发生了哪种情况（） s5 [x] 一个进程释放一种资源 [ ] 系统新创建了一个进程 [ ] 一个进程从就绪队列进入阻塞队列 [ ] 一个在阻塞队列中的进程被系统取消了 1 "},"all/07-1-spoc-discussion.html":{"url":"all/07-1-spoc-discussion.html","title":"lec17 SPOC讨论","keywords":"","body":"lec 17: 同步互斥spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 17.1 背景 请给出程序正确性的定义或解释。 程序执行的结果是实现预期的功能，并且是确定的和可重现的； 我们只能在确定的限制条件下来讨论“正确性”的定义或解释，没有无条件的“正确”。 在一个新运行环境中程序行为与原来的预期不一致，是错误吗？ 如果预期行为包括明确的运行环境的限定，这就不是错误；否则就是错误； 程序并发执行有什么好处和障碍？ 共享资源 加速处理 方便管理：模块化 什么是原子操作？ 原子操作是指一次不存在任何中断或失败的操作，不会出现部分执行的状态。 17.2 现实生活中的同步问题 家庭采购中的同步问题的5种解决方案的核心思路是什么？举例描述可能的漏洞。 思路的关键点：有人去买，不会重复买；合理的枚举分类； 方案一：先检查，后加相同的标签；漏洞是可能重复采购； 方案二：先加相同的标签，后检查；漏洞是会出现没人去买的情况； 方案三：先加不同的标签，后检查；漏洞是会出现没人去买的情况； 方案四：先加不同的标签，后进行非对称检查；经枚举判断，结果是不会出现漏洞； 方案五：原子操作 家庭采购中的同步问题与操作系统中进程同步有什么区别？ 操作系统的进程切换比人的操作切换快； 操作系统的进程对外界环境的感知手段比人少； 如何通过枚举和分类方法检查同步算法的正确性？ 合理定义枚举分类标准是检查同步算法正确性的关键； 尝试描述方案四的正确性。 依据谁先加标签和加第二个标签的时间进行情况划分 举例说明，互斥、死锁和饥饿的定义是什么？ 互斥：一个进程占用资源，其它进程不能使用； 死锁：多个进程各占用部分资源，形成循环等待； 饥饿：其他进程可能轮流占用资源，一个进程一直得不到资源； 17.3 临界区，禁用硬件中断,硬件原子操作同步方法 什么是临界区？ 操作临界资源的互斥执行代码片段 临界区的访问规则是什么？ 空闲则入、忙则等待、有限等待、让权等待 禁用中断是如何实现对临界区的访问控制的？有什么优缺点？ 禁用中断可以阻止其他进程对临界区访问进程的打断； 优点是简单；缺点是无法中断，临界区代码故障可以导致系统崩溃，其他进程可能出现饥饿； Test&Set原子操作是否可以实现Exchange原子操作? Exchange原子操作是否可以实现Test&Set原子操作? 这两条指令在实现原子操作的功能是等价的。 17.4 基于软件的同步方法 软件同步方法中的5种解决方案（三种尝试方案、Peterson算法和Eisenberg算法）的核心思路是什么？举例描述可能的漏洞。 方案一：turn 表示允许进入临界区的线程标识； 方案漏洞：交替进入临界区； 方案二：flag[i] 表示线程i是否在临界区； 先判断，后修改变量； 方案漏洞：并发判断后，可能出现同时进入临界区； 方案二：flag[i] 表示线程i想要进入临界区； 先修改变量，后判断； 方案漏洞：并发修改变量后，可能出现都无法进入临界区的情况； Peterson算法：turn 表示进入临界区的线程标识，flag[i] 表示线程i想要进入临界区； 先修改变量，后判断；后修改者等待； 只适用于两个进程； 方案正确性枚举判断：按写变量的顺序进行情况分类 Eisenberg算法：flag[i] 表示线程i想要进入临界区，turn 表示进入临界区的线程标识（有多个想进入时）； 进入区：先修改flag，后判断是否有多个想进入；后修改者等待； 退出区：修改turn； 适用于多个进程； 方案正确性枚举判断：按写变量flag[i]的顺序和变量turn当前值进行情况分类 尝试通过枚举和分类方法检查Peterson算法的正确性。 尝试准确描述Eisenberg同步算法，并通过枚举和分类方法检查其正确性。 4.下列二线程同步机制是否有误？请给出分析． CONCEPT: A shared variable named turn is used to keep track of whose turn it is to enter the critical section. INITIALIZATION: shared int turn; ... turn = i ; ENTRY PROTOCOL (for Process i ): /* wait until it's our turn */ while (turn != i ) { } EXIT PROTOCOL (for Process i ): /* pass the turn on */ turn = j ; 5.下列二线程同步机制是否有误？请给出分析． CONCEPT: A shared Boolean array named flags contains a flag for each process. The flag values are BUSY when the process is in its critical section (using the resource), or FREE when it is not. INITIALIZATION: typedef char boolean; ... shared boolean flags[n - 1]; ... flags[i ] = FREE; ... flags[j ] = FREE; ... ENTRY PROTOCOL (for Process i ): /* wait while the other process is in its CS */ while (flags[j ] == BUSY) { } --> /* claim the resource */ flags[i ] = BUSY; EXIT PROTOCOL (for Process i ): /* release the resource */ flags[i ] = FREE; 6.下列二线程同步机制是否有误？请给出分析． CONCEPT: Again we use a shared Boolean array as in Algorithm 2. Each process sets its flag before testing the other flag, thus avoiding the problem of violating mutual exclusion. INITIALIZATION: typedef char boolean; ... shared boolean flags[n -1]; ... flags[i ] = FREE; ... flags[j ] = FREE; ... ENTRY PROTOCOL (for Process i ): /* claim the resource */ flags[i ] = BUSY; --> /* wait if the other process is using the resource */ while (flags[j ] == BUSY) { } EXIT PROTOCOL (for Process i ): /* release the resource */ flags[i ] = FREE; 7.下列二线程同步机制是否有误？请给出分析． CONCEPT: To avoid the deadlock problem of Algorithm 3, we periodically clear and reset our own flag while waiting for the other one. INITIALIZATION: typedef char boolean; ... shared boolean flags[n -1]; ... flags[i ] = FREE; ... flags[j ] = FREE; ... ENTRY PROTOCOL (for Process i ): /* claim the resource */ flags[i ] = BUSY; --> /* wait if the other process is using the resource */ while (flags[j ] == BUSY) { flags[i ] = FREE; delay a while ; flags[i ] = BUSY; } EXIT PROTOCOL (for Process i ): /* release the resource */ flags[i ] = FREE; 8.下列二线程同步机制是否有误？请给出分析． CONCEPT: Both the turn variable and the status flags are combined in a way which we (the requesting process) set our flag and then check our neighbor's flag. INITIALIZATION: typedef char boolean; ... shared boolean flags[n -1]; shared int turn; ... turn = i ; ... flags[i ] = FREE; ... flags[j ] = FREE; ... ENTRY PROTOCOL (for Process i ): /* claim the resource */ flags[i ] = BUSY; /* wait if the other process is using the resource */ while (flags[j ] == BUSY) { /* if waiting for the resource, also wait our turn */ if (turn != i ) { /* but release the resource while waiting */ flags[i ] = FREE; while (turn != i ) { } flags[i ] = BUSY; } } EXIT PROTOCOL (for Process i ): /* pass the turn on, and release the resource */ turn = j ; flags[i ] = FREE; 9.下列二线程同步机制是否有误？请给出分析． CONCEPT: Both the turn variable and the status flags are used. INITIALIZATION: typedef char boolean; ... shared boolean flags[n -1]; shared int turn; ... turn = i ; ... flags[i ] = FREE; ... flags[j ] = FREE; ... ENTRY PROTOCOL (for Process i ): /* claim the resource */ flags[i ] = BUSY; /* give away the turn */ turn = j ; /* wait while the other process is using the resource *and* has the turn */ while ((flags[j ] == BUSY) && (turn != i )) { } EXIT PROTOCOL (for Process i ): /* release the resource */ flags[i ] = FREE; 10.下列N线程同步机制是否有误？请给出分析． CONCEPT: The turn variable and status flags are used as in Dekker's algorithm for the 2-process case. The flags now have three possible values: WAITING for a process in the entry protocol, waiting for the resource' ACTIVE for a process in the critical section, using the resource; and IDLE for other cases. Process priority is maintained in circular order beginning with the one holding the turn. Each process begins the entry protocol by scanning all processes from the one with the turn up to itself. These are the only processes that might have to go first if there is competition. If the scan finds all processes idle, the process advances tentatively to the ACTIVE state. However, it is still possible that another process which started scanning later but belongs before us will also reach this state. We check one more time to be sure there are no active processes. INITIALIZATION: shared enum states {IDLE, WAITING, ACTIVE} flags[n -1]; shared int turn; int index; /* not shared! */ ... turn = 0; ... for (index=0; index= n) && ((turn == i) || (flags[turn] == IDLE))); /* claim the turn and proceed */ turn = i; EXIT PROTOCOL (for Process i ): /* find a process which is not IDLE */ /* (if there are no others, we will find ourselves) */ index = turn+1 mod n; while (flags[index] == IDLE) { index = index+1 mod n; } /* give the turn to someone that needs it, or keep it */ turn = index; /* we're finished now */ flag[i] = IDLE; 11.下列N线程同步机制是否有误？请给出分析． CONCEPT: Both status values and turn values are used. The status array is expanded to an integer value for each process, which is used to track that process' progress in scanning the status of other processes. The turn value is also expanded to an integer array. Its values represent the relative ordering for each pair of processes. INITIALIZATION: shared int flags[NUMPROCS]; shared int turn[NUMPROCS - 1]; int index; for (index = 0; index 12.下列N线程同步机制是否有误？请给出分析． CONCEPT: A process waiting to enter its critical section chooses a number. This number must be greater than all other numbers currently in use. There is a global shared array of current numbers for each process. The entering process checks all other processes sequentially, and waits for each one which has a lower number. Ties are possible; these are resolved using process IDs. INITIALIZATION: typedef char boolean; ... shared boolean choosing[n] shared int num[n]; ... for (j=0; j 0) && ((num[j] 0) {} } } EXIT PROTOCOL (for Process i): /* clear our number */ num[i] = 0; 13.(spoc)基于“python, ruby, C, C++，LISP、JavaScript”等语言模拟实现Eisenberg同步算法，并给出覆盖所有枚举分类的测试用例，在实现报告写出设计思路和测试结果分析。 17.5 高级抽象的同步方法 如何证明TS指令和交换指令的等价性？ 利用一条指令来实现另一条指令的功能； 自旋锁（spinlock）和无忙等待锁是如何实现同步的？它们有什么不同？ 自旋锁是基于TS指令实现同步的，进入区的等待是占用CPU的； 无忙等待锁是在自旋锁的基础上加一个等待队列和进程切换，进入区的等待是不占用CPU的； 为什么硬件原子操作指令能简化同步算法的实现？ 原子操作指令是硬件实现的，与进程数目无关； 缺点是，等待时占用CPU，可能出现饥饿和死锁； 小组思考题 （spoc）阅读简化x86计算机模拟器的使用说明，理解基于简化x86计算机的汇编代码。 （spoc)了解race condition. 进入race-condition代码目录。 执行 ./x86.py -p loop.s -t 1 -i 100 -R dx， 请问dx的值是什么？ 执行 ./x86.py -p loop.s -t 2 -i 100 -a dx=3,dx=3 -R dx ， 请问dx的值是什么？ 执行 ./x86.py -p loop.s -t 2 -i 3 -r -a dx=3,dx=3 -R dx， 请问dx的值是什么？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -t 1 -M 2000, 请问变量x的值是什么？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -t 2 -a bx=3 -M 2000, 请问变量x的值是什么？为何每个线程要循环3次？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -t 2 -M 2000 -i 4 -r -s 0， 请问变量x的值是什么？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -t 2 -M 2000 -i 4 -r -s 1， 请问变量x的值是什么？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -t 2 -M 2000 -i 4 -r -s 2， 请问变量x的值是什么？ 变量x的内存地址为2000, ./x86.py -p looping-race-nolock.s -a bx=1 -t 2 -M 2000 -i 1， 请问变量x的值是什么？ （spoc） 了解software-based lock, hardware-based lock, software-hardware-lock代码目录 理解flag.s,peterson.s,test-and-set.s,ticket.s,test-and-test-and-set.s 请通过x86.py分析这些代码是否实现了锁机制？请给出你的实验过程和结论说明。能否设计新的硬件原子操作指令Compare-And-Swap,Fetch-And-Add？ ``` Compare-And-Swap int CompareAndSwap(int ptr, int expected, int new) { int actual = ptr; if (actual == expected) *ptr = new; return actual; } Fetch-And-Add int FetchAndAdd(int ptr) { int old = ptr; *ptr = old + 1; return old; } ``` "},"all/07-2-quiz.html":{"url":"all/07-2-quiz.html","title":"lec18 在线练习","keywords":"","body":"lec18: 信号量与管程　在线练习 选择题 如果有5个进程共享同一程序段，每次允许3个进程进入该程序段，若用PV操作作为同步机制则信号量S为-1时表示什么（） s1 [ ] 有四个进程进入了该程序段 [ ] 有一个进程在等待 [x] 有三个进程进入了程序段，有一个进程在等待 [ ] 有一个进程进入了该程序段，其余四个进程在等待 3 2元信号量可以初始化为（） s2 [x] 0或1 [ ] 0或-1 [ ] 只能为1 [ ] 任意值 1 多个进程对信号量S进行了6次P操作，2次V操作后，现在信号量的值是-3，与信号量S相关的处于阻塞状态的进程有几个（） s2 [ ] 1个 [ ] 2个 [x] 3个 [ ] 4个 3 (2011年全国统考)有两个并发执行的进程P1和P2，共享初值为1的变量x。P1对x加1，P2对x减一。加1和减1操作的指令序列分别如下所示,两个操作完成后，x的值（）。 s2 加一操作 减一操作 Load R1,x load R2,x inc R1 dec R2 store x,R1 store x,R2 [ ] 可能为-1或3 [ ] 只能为1 [x] 可能为0、1或2 [ ] 可能为-1、0、1、1或2 3 管程的主要特点有（） s3 [x] 局部数据变量只能被管程的过程访问 [x] 一个进程通过调用管程的一个过程进入管程 [ ] 不会出现死锁 [x] 在任何时候，只能有一个进程在管程中执行 124 关于管程的叙述正确的是（） s3 [ ] 管程中的局部数据变量可以被外部直接访问 [ ] 当一个进程在管程中执行时，调用管程的其他进程都不会被阻塞 [ ] 在管程中的signal()与信号量中的signal()操作实现及意义完全相同 [x] 管程通过使用条件变量提供对同步的支持，这些条件变量包含在管程中，并且只有管程才能访问 4 "},"all/07-2-spoc-discussion.html":{"url":"all/07-2-spoc-discussion.html","title":"lec18 SPOC讨论","keywords":"","body":"lec18: 同步互斥(lec 18) spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 18.1 基本理解 什么是信号量？它与软件同步方法的区别在什么地方？ 信号量是由操作系统提供的一种协调共享资源访问的方法。信号量是一种抽象数据类，由一个补保护的整形 (sem)变量和P()和V()两个原子操作组成，表示系统资源的数量。 区别： 软件同步是平等线程间的一种同步协商机制； 信号量是由地位高于进程的管理者OS协调的同步机制； 自旋锁为什么无法按先来先服务方式使用资源？ 原因：自旋锁是由TS指令实现的临界区申请操作，第一个检测到临界区空闲的申请者而不是第一个开始检测的申请者进入； 下面是一种P操作的实现伪码。它能按FIFO顺序进行信号量申请吗？ while (s.count == 0) { //没有可用资源时，进入挂起状态； 调用进程进入等待队列s.queue; 阻塞调用进程; } s.count--; //有可用资源，占用该资源； 参考回答： 它的问题是，不能按FIFO进行信号量申请。 它的一种出错的情况 一个线程A调用P()原语时，由于线程B正在使用该信号量而进入阻塞状态；注意，这时value的值为0。 线程B放弃信号量的使用，线程A被唤醒而进入就绪状态，但没有立即进入运行状态；注意，这里value为1。 在线程A处于就绪状态时，处理机正在执行线程C的代码；线程C这时也正好调用P()原语访问同一个信号量，并得到使用权。注意，这时value又变回0。 线程A进入运行状态后，重新检查value的值，条件不成立，又一次进入阻塞状态。 至此，线程C比线程A后调用P原语，但线程C比线程A先得到信号量。 18.2 信号量使用 什么是条件同步？如何使用信号量来实现条件同步？ 条件同步是指线程间的事件等待； 条件同步的实现方法： 定义初始值为零的信号量，事件触发进程使用V()操作表示事件出现，事件等待进程使用P()操作表示开始等待事件； 什么是生产者-消费者问题？ 生产者生成数据，并放入缓冲区； 消费者从缓冲区取出数据，进行处理； 任何时间只有进程访问缓冲区； 为什么在生产者-消费者问题中先申请互斥信号量会导致死锁？ 在两种情况下会出现循环等待： 缓冲区空时，生产者等待缓冲区的互斥访问，以便放入数据；消费者占有缓冲区访问权，等待生产者放入的数据； 缓冲区满时，生产者占有缓冲区访问权，等待空的缓冲块；消费者等待缓冲区的互斥访问，以便取出数据； 为什么互斥信号量的实现比资源信号量的实现要简单？请说明． 信号量中的整形变量的取值不同，互斥信号量的最大取值为1；而资源信号量的最大取值为资源总数； 18.3 管程 管程的组成包括哪几部分？入口队列和条件变量等待队列的作用是什么？ 管程是一种并发程序的编程方法，由一个与入口队列对应的锁和若干个与共享数据访问的等待队列对应的条件变量组成，从而实现在任一时刻最多只有一个线程执行管程代码； 管程与临界区有什么异同？ 相同点：在任一时刻最多只有一个线程执行管程代码或临界区代码； 不同：正在管程中的线程可临时放弃管程的互斥访问，等待事件出现时恢复；而临界区不支持临时退出； 为什么用管程实现的生产者-消费者问题中，可以在进入管程后才判断缓冲区的状态？ 管程允许临时放弃管程的互斥访问，而信号量并不支持临时放弃互斥访问权； 请描述管程条件变量的三种释放处理方式的区别是什么？条件判断中while和if是如何影响释放处理中的顺序的？ Mesa管程：占用管程的当前进程可在任何时刻释放占用资源并唤醒相应的等待进程，当前进程继续执行，被唤醒放回入口队列队首等待当前进程释放管程访问权； Hoare管程：占用管程的当前进程可在任何时刻释放占用资源并唤醒相应的等待进程，当前进程进入唤醒队列等待，被唤醒进程继续执行直到释放管程访问权；管程空闲时，优先查看唤醒队列中的等待进程，唤醒队列中没有等待进程时再查看入口队列； Hansen管程：占用管程的当前进程只在退出管程时释放占用资源并唤醒相应的等待进程，被唤醒进程继续执行直到释放管程访问权； 条件判断中while和if对释放处理中的执行顺序影响： 在Hansen和Mesa管程中，由于条件变量释放操作signal时并没有立即放弃管程访问权，资源的可用状态可能变化，需使用while()进行重新检查； 在Hoare管程中，由于条件变量释放操作signal同时表示立即放弃管程访问权，资源的可用状态保持不变，可使用if判断，不需要再次检查。 Ref: https://piazza.com/class/i5j09fnsl7k5x0?cid=894 Ref: https://www.andrew.cmu.edu/course/15-440-kesden/applications/ln/lecture6.html 18.4 哲学家就餐问题 哲学家就餐问题的方案2和方案3的性能有什么区别？ 方案2对应为只有一个哲学家在吃饭； 方案3可以有两个哲学家在吃饭 18.5 读者-写者问题 在读者-写者问题的读者优先和写者优先在行为上有什么不同？ 读优先：有读者正在读，且有写者等待时，后到的读者可开始读； 写优先：有读者正在读，且有写者等待时，后到的读者不能开始读； 在读者-写者问题的读者优先实现中优先于读者到达的写者在什么地方等待？ 互斥信号WriteMutex 18.6 信号量，管程，条件变量 如果能用管程实现信号量，也能用信号量实现管程，则我们可以称二者在功能上等价． 请用管程with条件变量来实现信号量 请用信号量来实现管程with条件变量 请评价如下的实现(用信号量来实现管程with条件变量)是否合理？简要说明理由． Implementing a Monitor CONTROL VARIABLES: mutex: semaphore, initial value 1 (FREE) next: record, with 2 fields: next.sem: semaphore, initial value 0 next.count: counter, initial value 0 FOR EACH CONDITION x: x: record, with 2 fields: x.sem: semaphore, initial value 0 x.count: counter, initial value 0 ENTRY PROTOCOL (at the beginning of each monitor function): /* wait for exclusive access to the monitor */ P(mutex); EXIT PROTOCOL (at the end of each monitor function): /* if there are processes in the \"next\" queue, release one */ if (next.count > 0) V(next.sem); /* otherwise, release the monitor */ else V(mutex); WAIT ON CONDITION x (x.wait): /* first perform the exit protocol */ if (next.count > 0) V(next.sem); else V(mutex); /* now wait on the condition queue */ x.count++; P(x.sem); x.count--; SIGNAL CONDITION x (x.signal): /* do nothing unless a process is waiting */ if (x.count > 0) { /* release the next waiting process */ V(x.sem); /* wait on the \"next\" queue */ next.count++; P(next.sem); next.count--; } 小组思考题 （spoc） 每人使用C++或python语言用信号量和条件变量两种手段分别实现40个同步互斥问题中的一题。请先理解python threading 机制的介绍和实例 参考：2015年操作系统课的信号量问题回答 建议参考梁锡豪同学的输出信息显示方式，这种方式的可读性很好。 建议重视测试用例的设计，以检查自己的实现是否有错。 (spoc)设计某个方法，能够动态检查出对于两个或多个进程的同步互斥问题执行中，没有互斥问题，能够同步等，以说明实现的正确性。 (spoc challenge)管程和信号量在解决同步互斥问题上是否等价？请证明/说明你的结论． "},"all/07-3-lab7-quiz.html":{"url":"all/07-3-lab7-quiz.html","title":"lec19 在线练习","keywords":"","body":"lec19: lab7 同步互斥　在线练习 选择题 ucore为支持内核中的信号量机制，需用到的支撑机制包括（） s2 底层支撑 [x] 处理器调度 [x] 屏蔽中断 [x] 等待队列 [ ] 动态内存分配 需用到前三个，动态内存分配不是必须的 ucore实现的信号量机制被用于（） s3 信号量设计与实现 [x] 条件变量实现 [x] mm内存管理实现 [x] 哲学家问题实现 [ ] 中断机制实现 中断机制是支持信号量的，所以不选 关于ucore实现的管程和条件变量的阐述正确的是（） s4 管程和条件变量设计实现 [x] 管程中采用信号量用于互斥操作 [x] 管程中采用信号量用于同步操作 [x] 管程中采用条件变量用于同步操作 [x] 属于管程的共享变量访问的函数需要用互斥机制进行保护 都对 "},"all/07-3-lab7-spoc-discussion.html":{"url":"all/07-3-lab7-spoc-discussion.html","title":"lec19-lab7 SPOC讨论","keywords":"","body":"lec 19: 同步互斥lab7 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 19.1 总体介绍 同步机制、处理机调度、等待队列和定时器有些什么相互影响？ 底层支持：中断禁止、定时器、等待队列 同步机制：信号量、管程（条件变量） 同步管理：处理机调度 19.2 底层支撑 操作系统内核如何利用定时器实现sleep系统？在定时队列中保存的时间格式是什么？ 定时器的数据结构（timer_t）：所有当前还未触发的定时设置形成一个队列（timer_list）； 定时器的设置函数do_sleep() 定时器的触发流程：trap_dispatch()会检查定时器设置是否触发，并在触发时唤醒相应线程； 中断屏蔽控制位在哪个寄存器中？如何修改中断屏蔽控制位？ EFLAGS寄存器 屏蔽中断指令：STI、CLI local_intr_save(x); local_intr_restore(x); 在ucore中有多少种等待队列？ static list_entry_t timer_list; 包含wait_queue_t字段的数据结构通常都会对应有一类等待队列 等待队列的两个基本操作down()和up()对线程状态和等待队列有什么影响？ 等待队列的数据结构、等待队列操作（等待down()、唤醒up()） 关键的等待队列操作实现函数：wait_current_set(), wakeup_wait() proc.h中定义了若干种等待状态（如WT_TIMER），通常一种等待状态会对应有一类等待队列 19.3 信号量设计实现 ucore中的信号量实现能实现是按FIFO获取信号量资源吗？给出你的理由。 semaphore_t 由于线程唤醒原因可能与等待标志可能不一致，可能出现不按FIFO排队的情况； 信号量的实现用到了“屏蔽中断”机制；使用wait_current_set()把当前线程放入等待队列；使用wait_current_del()把等待线程唤醒； ucore中的信号量实现用到自旋锁(spinlock)吗？为什么？ 信号量的实现用到了“屏蔽中断”机制；使用wait_current_set()把当前线程放入等待队列；使用wait_current_del()把等待线程唤醒； spinlock只在多处理机环境下有需求，单处理机环境下仅需要“屏蔽中断”； 为什么down()要加一个_down()函数来进行实质的处理？类似情况还出现在up()和_up()。 参考回答：有多个有小差异的类似函数要使用相同的核心功能实现。类似情况还出现在do_fork()函数。 19.4 管程和条件变量设计实现 管程与信号量是等价的。如何理解？ 等价，原因是可以基于一个机制来实现另一个机制； 基于信号量的管程中在什么地方用到信号量？ 入口队列、唤醒队列和条件变量对应的等待队列等队列的实现中都用到了信号量； 管程实现中的monitor.next的作用是什么？ monitor.next就是唤醒队列，对应三种管程模型中的hoare管程； 分析管程实现中PV操作的配对关系，并解释PV操作的目的。 monitor.mutex monitor.next condvar.sem 基于视频中对管程的17个状态或操作的分析，尝试分析管程在入口队列和条件变量等待队列间的等待和唤醒关系。注意分析各队列在什么情况下会有线程进入等待，在什么时候会被唤醒，以及这个等待和唤醒的依赖关系。 线程A占用管程（0），A进入条件变量等待（1），A唤醒在入口等待队列中等待的线程B（3） B占用管程（5），B唤醒在条件变量等待队列等待的A(6)，B进入唤醒队列等待（9） A占用管程（11），A在结束时唤醒在唤醒队列等待的B（13），B占用管程并执行到结束（15） ucore中的管程实现是Hoare管程吗？为什么？ 是的。占用管程的线程在唤醒条件等待队列中的线程后立即进行唤醒队列等待。 19.5 哲学家就餐问题 哲学家就餐问题的管程实现中的外部操作成员函数有哪几个？ pickup(); putdown(); 哲学家就餐问题的管程实现中用了几个条件变量？每个条件变量的作用是什么？ 5个条件变量，每个条件代表一个哲学家； 小组思考题 (扩展练习) 每人用ucore中的信号量和条件变量两种手段分别实现40个同步问题中的一题。向勇老师的班级从前往后，陈渝老师的班级从后往前。请先理解与采用python threading 机制实现的异同点。 （扩展练习）请在lab7-answer中分析 cvp->count含义是什么？cvp->count是否可能1？请举例或说明原因。 cvp->owner->next_count含义是什么？cvp->owner->next_count是否可能1？请举例或说明原因。 目前的lab7-answer中管程的实现是Hansen管程类型还是Hoare管程类型？请在lab7-answer中实现另外一种类型的管程。 现在的管程（条件变量）实现是否有bug? Piazza上关于count的讨论 "},"all/11-deadlock.html":{"url":"all/11-deadlock.html","title":"死锁和进程间通信","keywords":"","body":"死锁和进程间通信 单选题 若P,V操作的信号量S初值为4,当前值为-1,则表示有（）进程处于等待状态。 [ ] 0 [x] 1 [ ] 2 [ ] 3 p操作会使s减1，如果s 任何两个并发进程之间（）。 [ ] 一定存在互斥关系 [ ] 一定存在同步关系 [ ] 一定彼此独立无关 [x] 可能存在同步或互斥关系 如果两个并发程序为互斥关系，则必定存在临界区，但是实际上不是多有的并发程序之间都存在临界区；我们把异步环境下的一组并发进程因直接制约而互相发送消息、进行互相合作、互相等待，使得各进程按一定的速度执行的过程称为进程间的同步，实际上不是所有的程序间都存在直接制约关系。所有两个并发的程序之间只是有可能存在同步或互斥关系。 银行家算法是一种（）算法。 [ ] 死锁解除 [x] 死锁避免 [ ] 死锁预防 [ ] 死锁检测 银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。 在为多道程序所提供的可共享的系统资源不足时，可能出现死锁。但是，不适当的（）也可能产生死锁。 [ ] 进程优先权 [ ] 资源的线性分配 [x] 进程推进顺序 [ ] 分配队列优先权 不合理的进程推进顺序可能产生死锁的原因是相互等待资源。如进程p1申请资源的顺序是资源1和资源2，进程p2申请资源的顺序是资源2和资源1；这时当两个进行都申请成功了第一个资源后，在申请第二个资源的时候就会出现死锁。 产生死锁的四个必要条件是：互斥、( )、循环等待和不剥夺。 [ ] 请求与阻塞 [x] 请求与保持 [ ] 请求与释放 [ ] 释放与阻塞 互斥是一次只有一个进程可以使用一个资源，其他进程不能访问已分配给其他进程的资源；请求与保持是当一个进程等待其他进程时，继续占有已经分配的资源；不剥夺是不能强行抢占进程已占有的资源；循环等待指存在一个封闭的进程链，使得每个进程至少占有此链中下一个进程所需要的一个资源。这四个是产生死锁的必要条件。 在下列解决死锁的方法中，属于死锁预防策略的是 ( )。 [ ] 银行家算法（死锁避免） [x] 资源有序分配法 [ ] 死锁检测法 [ ] 资源分配图化简法 资源有序分配法将资源按某种规则系统中的所有资源统一编号，申请的时候必须按照编号的顺序申请。对进行必须使用的同类资源，必须一次申请；不同类的资源必须按照资源编号顺序申请，这样就破坏了死锁环路。 采用资源剥夺法可以解除死锁，还可以采用 ( ) 方法解除死锁。 [ ] 执行并行操作 [x] 撤销进程 [ ] 拒绝分配新资源 [ ] 修改信号量 当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。 进程从运行态进入阻塞态可能是由于（）。 [ ] 现运行进程运行结束 [x] 现运行进程执行了P操作 [ ] 现运行进程执行了V操作 [ ] 现运行进程时间片用完 p操作使信号量减1，表明程序申请了资源，当信号量小于0时，表明没有可供使用的资源，程序将从运行态进入阻塞态。 在 ( )情况下，系统出现死锁。 [ ] 计算机系统发生了重大故障 [ ] 有多个封锁的进程同时存在 [x] 若干进程因竞争而无休止地相互等待他方释放已占有的资源 [ ] 资源数远远小于进程数或进程同时申请的资源数量远远超过资源总数 死锁产生的必要条件是互斥、请求与保持、不可抢占、循环等待。所以当若干进程因竞争而无休止地相互等待他方释放已占有的资源时，系统会产生死锁。 若信号量S的初值为2，且有三个进程共享此信号量，则S的取值范围是( )。 [ ] [-3,2] [ ] [-2,2] [x] [-1,2] [ ] [0,2] 因为s的初始值为2，而有3个进行共享信号量，所以s的最小值为2-3=-1，最大值为2-0=2。 对于记录型信号量，在执行一次P操作(wait操作)时，信号量的值应当为减1；当其值为( )时，进程应阻塞。 [ ] 大于0 [x] 小于0 [ ] 大于等于0 [ ] 小于等于0 在执行p操作时，如果信号量的值小于0，则表明没有资源可以分配了，进行应进入等待状态。 预防死锁的论述中，（）条是正确的论述。 [ ] 由于产生死锁的基本原因是系统资源不足，因而预防死锁的有效方法，是根据系统规模，配置足够的系统资源。 [ ] 由于产生死锁的另一种基本原因是进程推进顺序不当，因而预防死锁的有效方法，是使进程的推进顺序合法。 [ ] 因为只要系统不进入不安全状态，便不会产生死锁，故预防死锁的有效方法，是防止系统进入不安全状态。 [x] 可以通过破坏产生死锁的四个必要条件之一或其中几个的方法，来预防发生死锁。 死锁是因为若干进程因竞争而无休止地相互等待他方释放已占有的资源，通过破坏四个必要条件，可以预防死锁产生。通过增加系统资源的方法相当于增加了信号量的初始值，可以一定程度上减少死锁的出现，但是当众多进程申请同一资源时，还是会出现死锁的情况；合理的进程推进顺序可以降低死锁出现的可能，但是当四个必要条件存在时，还是有出现死锁的可能；让系统不进入安全状态是可以预防死锁，但是因为破坏了互斥关系，导致程序执行错误。 操作系统中，进程与程序的重要区别之一是( )。 [ ] 程序有状态而进程没有 [x] 进程有状态而程序没有 [ ] 程序可占有资源而进程不可 [ ] 进程能占有资源而程序不能 进程是一个“执行中的程序”，所以进程是有状态的，而程序只是一个静态的概念，并不存在状态。 进程从阻塞状态进入就绪状态可能是由于( )。 [ ] 现运行进程运行结束 [ ] 现运行进程执行了P操作 [x] 现运行进程执行了V操作 [ ] 现运行进程时间片用完 v操作会使信号量加1，表明有程序释放了资源，而需要该资源的一个进程会被唤醒，成阻塞状态转换成就绪状态，准备获取资源并执行。 发生死锁的必要条件有四个，要防止死锁的发生，可以破坏这四个必要条件，但破坏( )条件是不太实际的。 [x] 互斥 [ ] 不可抢占 [ ] 占有且等待 [ ] 循环等待 互斥是不可能被禁止的，因为如果需要对资源进行互斥访问，那么操作系统必须支持互斥；预防占有且等待可以要求进行一次性请求所有需要的资源，并且阻塞这个进程直到所有请求都同时满足；对于不可抢占可以要求如果占有某些资源的一个进程进一步申请资源时被拒绝，则该进行必须释放它最初占有的资源；循环等待可以通过定义资源类型的线性顺序来预防。 (北京理工大学)资源的有序分配策略可以破坏死锁的（）条件。 [ ] 互斥 [ ] 请求和保持 [ ] 不剥夺 [x] 循环等待 资源的有序分配策略属于死锁预防的一种，死锁预防是通过破坏4个必要条件中的1个或者多个以确保系统不会发生死锁。采用资源有序分配法是破坏了“环路”条件，即破坏了循环等待。 (南京理工大学)一进程在获得资源后，只能在使用完资源后由自己释放，这属于死锁必要条件的（）。 [ ] 互斥条件 [ ] 请求和释放条件 [x] 不剥夺条件 [ ] 环路等待条件 死锁的必要条件包括互斥、请求和保持、不可剥夺、循环等待。如果一个程序占有的资源只能由其使用完后自己释放，则满足其中的不剥夺条件。 (四川大学)死锁产生的原因之一是：（）。 [ ] 系统中没有采用Spooling技术 [ ] 使用PV操作过多 [ ] 有共享资源存在 [x] 资源分配不当 任何系统的资源都是有限的，所以不恰当的资源分配可能会导致死锁的产生。 (南京理工大学)计算机系统产生死锁的根本原因是（）。 [ ] 资源有限 [ ] 进程推进顺序不当 [ ] 系统中进程太多 [x] A和B 产生死锁的原因有两个，一是系统提供的资源不能满足每个进程的使用需求；二是在多道程序运行时，进程推进顺序不合法。 (上海交通大学)某系统中有11台打印机，N个进程共享打印机资源，每个进程要求3台，当N不超过（）时，系统不会死锁。 [ ] 4 [x] 5 [ ] 6 [ ] 7 考虑下面的极端情况，每个进程都刚好分到了2台打印机，则只需要再分到一台打印机，某个进程就可以获得该打印机，完成自己的工作，并释放所有的打印机。其他的进程就可以完成，这样，N*2+1=11,所以N=5 (电子科技大学)死锁定理是用于处理死锁的哪一种方法（）。 [ ] 预防死锁 [ ] 避免死锁 [x] 检测死锁 [ ] 解除死锁 死锁定理是操作系统中用于检测死锁的充分必要条件的方法，所以死锁定理属于检测死锁。 (青岛大学)通常，（）是预防系统死锁的主要策略。 [ ] 动态分配与静态分配相结合 [ ] 静态分配与银行家算法相结合 [ ] 死锁检测与死锁解除相结合 [x] 静态分配、剥夺式分配和按序分配 死锁预防是通过破坏4个必要条件中的1个或者多个以确保系统不会发生死锁。采用资源的静态预分配策略，破坏了保持和请求；运行进程剥夺使用其他进程占有的资源，从而破坏不剥夺性条件，采用资源有序分配法，破坏了循环等待条件。 (兰州大学)死锁检测检查的是（）。 [x] 资源分配图 [ ] 前趋图 [ ] 搜索树 [ ] 安全图 如果资源分配图中不存在环路，则系统不存在死锁；反之如果资源分配图中存在环路，则系统可能存在死锁，也可能不存在死锁。 (兰州大学)采用资源剥夺法可以解除死锁，还可以采用（）方法解除死锁。 [ ] 执行并行操作 [x] 撤销进程 [ ] 拒绝分配资源 [ ] 修改信号量 解除死锁通常的做法有三种：一是撤销处于死锁状态的进程并收回它们的资源；二是资源剥夺法；三是进程回退。所以这里选择撤销进程。 (四川大学)当进程A使用磁带机时，进程B又申请该磁带机，这种情况（）。 [ ] 是不可能出现的 [ ] 是没法解决的 [ ] 就是死锁 [x] 以上均不正确 首先，这种情况在多道程序系统中是可能出现的，甚至是会经常出现的。同时，死锁是指多个进程因竞争资源而形成的一种僵局，若无外力作用，这些进程都将永远不能再向前推进。通常情况下，进程都在等待彼此已经占据的资源。本题中的情况没有构成死锁。 (电子科技大学)下面关于检测死锁的正确描述是（）。 [ ] 银行家算法是典型的检测死锁算法 [ ] 检测死锁中系统需要反复检测各个进程资源申请和分配情况 [ ] 检测死锁是预防卷入了死锁 [x] 检测死锁方法对系统吱呀u年的分配不加限制，只要有则可以进行分配 银行家算法是死锁避免算法，死锁检测方法是对资源分配不加限制，即允许死锁发生。但是系统定时地运行一个死锁检测程序，判断系统是否已发生死锁，若检测到死锁发生，则设法加以解除。 判断题 死锁与程序的死循环一样。 [ ] 对 [x] 错 死锁是因为若干进程因竞争而无休止地相互等待他方释放已占有的资源，造成程序不能顺利执行；而程序的死循环的程序在执行逻辑上存在缺陷，导致程序不能够结束循环。 信号量机制中，P、V操作必须成对出现。 [x] 对 [ ] 错 p操作为申请资源操作，p操作成功执行后，信号量会减1；v操作为释放资源操作，v操作执行成功后，信号量会加1；所有资源的申请和释放必须成对出现。 当系统同时具备了死锁的四个必要条件时就肯定会产生死锁。 [ ] 对 [x] 错 在系统存在死锁的四个必要条件只是表明该系统可能会出现死锁，而不是肯定会产生死锁。在存在这四个必要条件的时候可以通过明智的选择，确保永远都不会到达死锁点。 死锁是指两个或多个进程都处于互等状态而无法继续工作。 [x] 对 [ ] 错 死锁是因为若干进程因竞争而无休止地相互等待他方释放已占有的资源。 死锁避免比死锁预防对系统条件限制更严格，所以使得系统资源利用率不高。 [ ] 对 [x] 错 死锁预防是通过破坏死锁的四个必要条件来预防死锁，但这样会导致低效的资源使用和低效的进程执行；死锁避免则相反，它允许死锁的互斥、占有且等待、不可抢占三个条件，但通过明智的选择，确保永远不会到达死锁点，因此死锁避免比死锁预防允许更多的并发，所以其资源利用率要高于死锁预防。 "},"all/08-1-quiz.html":{"url":"all/08-1-quiz.html","title":"lec20 在线练习","keywords":"","body":"lec20 死锁和进程间通信　在线练习 选择题 死锁产生的必要条件包括（） s1 [x] 互斥 [x] 持有并等待 [x] 非抢占 [x] 循环等待 都是 死锁处理方法主要包括（） s２ [x] 死锁预防(Deadlock Prevention):确保系统永远不会进入死锁状态 [x] 死锁避免(Deadlock Avoidance):在使用前进行判断，只允许不会出现死锁的进程请求资源 [x] 死锁检测和恢复(Deadlock Detection & Recovery)：在检测到运行系统进入死锁状态后，进行恢复 [x] 由应用进程处理死锁：通常操作系统忽略死锁 都是 可以使用银行家算法_ 死锁。s3 [ ] 预防 [ ] 检测 [ ] 解除 [x] 避免 是死锁避免 对于进程个数为n，资源类型为m的死锁检测算法的时间复杂度为（） s4 [x] O(m*n^2) [ ] O(m^2*n) [ ] O(m^2*n^2) [ ] O(m*n) 是O(m*n^2) 关于进程通信原理的阐述正确的是（） s5 [x] 进程通信是进程进行通信和同步的机制 [x] 进程通信可划分为阻塞（同步）或非阻塞（异步） [x] 进程通信可实现为直接通信和间接通信 [x] 进程通信的缓冲区是有限的 都对 关于信号和管道的进程通信机制的阐述正确的是（） s6 [x] 信号（signal）是一种进程间的软件中断通知和处理机制 [x] 信号的接收处理方式包括：捕获(catch)，忽略(Ignore)，屏蔽（Mask） [x] 管道（pipe）是一种进程间基于内存文件（或内存缓冲区 ）的通信机制 [ ] 管道（pipe）的实现需要在磁盘文件系统上创建一个文件 管道（pipe）的实现只需基于内存即可。 关于消息队列和共享内存的进程通信机制的阐述正确的是（） s7 [x] 消息队列是由操作系统维护的以字节序列为基本单位的间接通信机制 [x] 共享内存是把同一个物理内存区域同时映射到多个进程的内存地址空间的通信机制 [x] 消息队列机制可用于进程间的同步操作 [x] 共享内存机制可用于进程间的数据共享 都对 "},"all/08-1-spoc-discussion.html":{"url":"all/08-1-spoc-discussion.html","title":"lec20 SPOC讨论","keywords":"","body":"lec 20 死锁与IPC spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 20.1 死锁概念 什么是死锁？ 死锁：多个进程在执行过程出现无限期循环等待的情况 尝试举一个生活中死锁实例。 双向可行驶的单车道道路 可重用资源和消耗资源有什么区别？ 可重用和不可撤销； 资源分配图中的顶点和有向边代表什么含义？ 顶点代表进程和资源 有向边代表资源的请求关系（进程P请求资源R）和分配关系（资源R分配给了进程P） 出现死锁的4个必要条件是什么？ 互斥 持有并等待 非抢占 循环等待 20.2 死锁处理方法 死锁处理的方法有哪几种？它们的区别在什么地方？ 死锁预防：确保不会出现死锁条件同时出现的情况； 死锁避免：使用前进行判断，只允许不会出现死锁的资源请求； 死锁检测和恢复：发现死锁后，进行恢复； 安全序列的定义是什么？ 进程的最大资源需要量小于当前可用资源与序列中前面进程占用资源的总和； 安全、不安全和死锁有什么区别和联系？ 安全时，不会出现死锁； 不安全表示可能出现死锁，但不是一定出现死锁； 20.3 银行家算法 什么是银行家算法？ 依据客户申请贷款的最大资金量，银行在每笔贷款前判断贷款后系统是否处于安全状态 安全状态判断和安全序列是一回事吗？ 是一回事。存在安全序列表示处于安全状态。 20.4 死锁检测 死锁检测与安全状态判断有什么区别和联系？ 死锁检测是在资源分配后判断是否存在死锁；没有进程最大资源请求量的要求； 安全状态判断是资源分配前依据进程最大资源请求量判断是否存在安全序列； 死锁检测、安全状态判断和安全序列判断的本质就是资源分配图中的循环等待判断。 20.5 进程通信概念 直接通信和间接通信的区别是什么？ 本质上来说，直接通信可以理解为两个直接通信，间接通信中假定有一个永远有效的直接通信方。 同步和异步通信有什么区别？ 同步通信：通信收方和发方都会等待收发成功后才返回； 异步通信：通信收方和发方在完成数据发送或已有数据接收后立即返回，不会等待收发成功信息； 20.6 信号和管道 什么是信号（signal）？ 进程间的软件中断通知和处理机制。 信号通信有什么特点？ 类似于中断，信号通信速度快；信息量小，只有一个信号类型值； 什么是管道？ 管道是进程间基于内存文件的通信机制。 写一个检查本机网络服务工作状态并自动重启相关服务的程序。 20.7 消息队列和共享内存 什么是消息队列？ 由操作系统维护的以字节序列为基本单位的间接通信机制。 (spoc) 用C语言在Linux系统下写测试用例，测试管道、消息队列和共享内存三种通信机制进行不同通信间隔和通信量情况下的通信带宽、通信延时、带宽抖动和延时抖动方面的性能差异。 参考测试用例：在内存中开指定大小数组，生成随机数据写入数组（最后两个字节为16位的校验和），然后创建指定类型的通信信道并发送和接收数据，收到数据后要利用校验和检测数据正确性；数据收发过程重复指定的次数，并计时；最后通过分析计时数据得到通信带宽、通信延时、带宽抖动和延时抖动等性能数据。 管道的例子 小组思考题 （spoc） 每人用python实现银行家算法。大致输出可参考参考输出。除了YOUR CODE部分需要填写代码外，在算法的具体实现上，效率也不高，可进一步改进执行效率。 (spoc) 以小组为单位，请思考在lab1~lab5的基础上，是否能够实现IPC机制，请写出如何实现信号，管道或共享内存（三选一）的设计方案。 (spoc) 扩展：用C语言实现某daemon程序，可检测某网络服务失效或崩溃，并用信号量机制通知重启网络服务。信号机制的例子 "},"all/12-filesystem.html":{"url":"all/12-filesystem.html","title":"文件系统","keywords":"","body":"文件系统 单选题 文件系统的主要目的是（）。 [x] 实现对文件的按名存取 [ ] 实现虚拟存贮器 [ ] 提高外围设备的输入输出速度 [ ] 用于存贮系统文档 在现在操作系统中，几乎都有一个文件管理系统，这个系统的目的主要实现对文件的按名存取。 按逻辑结构划分，文件主要有两类，UNIX中的文件系统采用（）。 [ ] 网状文件 [ ] 只读文件 [ ] 读写文件 [ ] 记录式文件 [ ] 索引文件 [x] 流式文件 按文件的逻辑结构可分为记录文件和流式文件，而UNIX、DOS、WINDOWS系统中的普通文件都是流式文件。 通常，文件的逻辑结构可以分为两大类：无结构的（）和有结构的记录式文件。 [ ] 堆文件 [x] 流式文件 [ ] 索引文件 [ ] 直接（Hash）文件 按文件的逻辑结构可分为记录文件和流式文件。 链接文件解决了顺序结构中存在的问题，它（）。 [x] 提高了存储空间的利用率 [ ] 适合于随机存取方式 [ ] 不适用于顺序存取 [ ] 指针存入主存，速度快 顺序结构 ：把逻辑文件的记录（内容）按其本身的顺序（逻辑记录的顺序）在磁盘上也按序存放在连续的块中。读取时也从第一个记录开始按顺序进行。在文件目录中指出文件名，存放的起始块号和占用块数。其最大优点是存取速度快。而问题主要是存储空间利用率不高、输出文件时难以估计需要多少磁盘块、影响文件扩展。链接结构：如果逻辑文件中的各个逻辑记录任意存放到一些磁盘块中，再用指针把各个块按逻辑记录的顺序链接起来，在文件目录中只记录第一块的地址和最后一块的地址，那么这种文件组织方式就是链接结构。链接结构解决了顺序结构中的所有问题，所有空闲块都可以被利用，在顺序读取时效率较高但需要随机存取时效率低下（因为要从第一个记录开始读取查。 文件管理实际上是对（2）的管理。 [ ] 主存空间 [x] 辅助存储空间 [ ] 逻辑地址空间 [ ] 物理地址空间 从系统角度看，文件系统是一个负责文件存储空间的管理机构，文件管理实际是对辅助存储空间的管理。 下面关于索引文件的论述中，第（）条是正确的论述。 [ ] 索引文件中，索引表的每个表项中含有相应记录的关键字和存放该记录的物理地址。 [x] 对顺序文件进行检索时，首先从FCB中读出文件的第一个盘块号；而对索引文件进行检索时，应先从FCB中读出文件索引表始址。 [ ] 对于一个具有三级索引表的文件，存取一个记录通常要访问三次磁盘。 [ ] 在文件较大时，无论是进行顺序存取还是随机存取，通常都是以索引文件方式为最快。 索引结构 ：索引结构是实现非连续存储的另一种方法，索引结构为每个文件建立一张“索引表”，把指示每个逻辑记录存放位置的指针集中在索引表中。（最直观的索引结构就比如我们的网站，首页就相当于一个索引表，每个链接记录了一个文件的位置，当我们点击时，就可以找到那个文件）。文件目录中指出文件名的索引表位置，而索引表中每个项指出一个逻辑记录的存放位置。存取文件时根据索引表中的登记项来查找磁盘上的逻辑记录。索引结构既适合顺序存取记录，也可以方便地随机存取记录，并且容易实现记录的增删和插入，所以索引结构被广泛应用。但是索引结构增加了索引表，要占用部分空间并增加读写索引表的时间。当索引项很多时，还要考虑采用多级索引结构。 下面关于顺序文件和链接文件的论述中错误的论述是（）。 [x] 顺序文件适于建立在顺序存储设备上，而不适合建立在磁盘上。 [ ] 在链接文件中是在每个盘块中设置一链接指针，用于将文件的所有盘块链接起来。 [ ] 顺序文件必须采用连续分配方式，而链接文件和索引文件则都可采取离散分配方式。 [ ] 在MS-DOS中采用的是链接文件结构。 [ ] 链接文件解决了顺序结构中存在的问题，它提高了存储空间的利用率。 看关于顺序文件、链接文件和索引文件的介绍。 在文件系统中，（）要求逻辑记录顺序与磁盘块顺序一致。 [x] 顺序文件 [ ] 链接文件 [ ] 索引文件 [ ] 串联文件 看4关于顺序文件、链接文件和索引文件的介绍。 下列文件中，（）的物理结构不便于文件的扩充。 [x] 顺序文件 [ ] 链接文件 [ ] 索引文件 [ ] 多级索引文件 看关于顺序文件、链接文件和索引文件的介绍。 (）的物理结构对文件随机存取时必须按指针进行，效率较低。 [ ] 连续文件 [x] 链接文件 [ ] 索引文件 [ ] 多级索引文件 看关于顺序文件、链接文件和索引文件的介绍。 一个采用二级索引文件系统，存取一块盘块信息通常要访问（）次磁盘。 [ ] 1 [ ] 2 [x] 3 [ ] 4 二级索引取需要访问2次，存需要一次，共需要三次。 设有一个包含1000个记录的索引文件，每个记录正好占用一个物理块。一个物理块可以存放10个索引表目。建立索引时，一个物理块应有一个索引表目，试问索引及其文件本身应占（）个物理块？ [ ] 1000 [ ] 1001 [ ] 1011 [x] 1111 共1000个记录，即有1000个索引表目，索引级数：lg1000=3；一个物理块可以放10个索引表目，三级索引需1000/10=100个物理块；二级索引：100/10=10；一级索引10/10=1。所以索引及文件共需1000+100+10+1=1111物理快。 打开文件操作的使用是（）。 [ ] 把整个文件从磁盘拷贝到内存 [x] 把文件目录项(FCB)从磁盘拷贝到内存 [ ] 把整个文件和文件目录项(FCB)从磁盘拷贝到内存 [ ] 把磁盘文件系统的控制管理信息从辅存读到内存 文件目录项是系统管理文件的必须信息结构，是文件存在的唯一标志，打开文件把文件目录项(FCB)从磁盘拷贝到内存。 如果文件系统中有两个文件重名，不应采用（1）。 [x] 单级目录结构 [ ] 树型目录结构 [ ] 二级目录结构 [ ] 单级和二级目录结构 一级目录结构，要求所有的文件名均不相同，一般只适用于微机的单用户系统。 文件系统采用二级文件目录可以（）。 [ ] 缩短访问存储器的时间 [ ] 实现文件共享 [ ] 节省内存空间 [x] 解决不同用户间的文件命名冲突 二级目录结构 则增加一级主文件目录，此目录是为用户建立的独立文件目录，用户访问文件时先要找到用户自己的目录再查找该目录下的指定文件。实际上，二级目录结构中，文件系统把用户名和文件名合起来作为文件标识。 【2010年计算机联考真题】设当前工作目录的主要目的是（）。 [ ] 节省外存空间 [ ] 节省内存空间 [x] 加快文件的索引速度 [ ] 加快文件的读/写速度 当文件系统含有多级目录时，每访问一个文件，都要使用从树根开始到树叶为止、包含中间节点名的全路径名。当前目录又称工作目录，进程对各个文件的访问都是相对于当前目录进行，而不需要一层一层的检索，加快了文件的检索速度。 选项12都是与相对目录无关；选项4加快文件的读/写速度取决于磁盘的性能。 【2009年计算机联考真题】文件系统中，文件访问控制信息存储的合理位置是（）。 [x] 文件控制块 [ ] 文件分配表 [ ] 用户口令表 [ ] 系统注册表 为了实现“按名存取”，文件系统为每个文件设置用于描述和控制文件的数据结构，称为文件控制块（FCB）。在文件控制块中，通常包含三类信息，即基本信息、存取控制信息级使用信息。 【2012年计算机联考真题】若一个用户进程通过read系统调用读取一个磁盘文件中的数据，则下列关于此进程的叙述中，正确的是（）。 I. 若文件的数据不在内存中，则该进程进入睡眠等待状态 II. 请求read系统调用会导致CPU从用户态切到核心态 III. read系统调用的参数应包含文件的名称 [x] 仅I、II [ ] 仅I、III [ ] 仅II、III [ ] I、II和III 对于I，当所读文件的数据不在内存是，产生中断（缺页中断），原进程进入阻塞状态，知道所需数据从外存调入内存后，才将该进程唤醒。对于II，read系统调用通过陷入将CPU从用户态进入核心态，从而获取操作系统提供的服务。对于III，读一个文件首先要用open系统调用打开该文件。open参数包含文件的路径名与文件名，read只需要open返回的文件描述符，不用文件名作为参数。read要求三个输入参数：1文件描述符fd；2buf缓冲区首地址；3传送的字节数n。read的功能试图从fd所指示的文件中读入n个字节的数据，并将它们送到buf所指示的缓冲区中。 【2013年计算机联考真题】用户删除某文件的过程中，操作系统不可能执行的操作是（）。 [x] 删除文件所在的目录 [ ] 删除与此文件关联的目录项 [ ] 删除与此文件对应的文件控制块 [ ] 释放与此文件关联的内存缓冲区 此文件的目录下可能还存在其他的文件，因此删除文件不能删除文件所在的目录，而与此文件关联的目录项和文件控制块需要随着文件一同删除，同时释放文件关联的内存缓冲区。 【2009年计算机联考真题】 设文件F1的当前引用计数值为1，先建立文件F1的符号链接（软链接）文件F2，在建立文件F1的硬链接F3，然后删除文件F1.此时，文件F2和文件F3的引用技术支持分别是（）。 [ ] 0,1 [x] 1,1 [ ] 1,2 [ ] 2,1 建立符号链接时，引用计数直接复制；建立硬链接时，引用计数加1.删除文件时，删除操作对于符号链接是不可见的，这并不影响文件系统，当以后通过符号链接访问文件时，发现文件不存咋，直接删除符号链接；但对于硬链接则不可以直接删除，引用计数值减1，若值不为0，则不能删除文件，因为还有其他的硬链接指向此文件。当建立F2时，F1和F2的引用计数值都为1.当建立F3时，F1和F3的引用计数值都为2了。删除F1，F3的引用计数值为2-1=1，F2的引用计数值不变。 【河北大学】文件系统采用两级索引分配方式，如果每个磁盘块的大小为1KB，每个盘块号占4个字节，则在该系统中，文件的最大长度是（）。 [x] 64MB [ ] 128MB [ ] 32MB [ ] 以上都不对 每个磁盘块大小1KB，每个盘块号占4个字节，则一个盘块可以存放1KB/4B=256个盘块，则2级索引文件的最大长度是2562561KB=64MB。 【2013年统考真题】为支持CD-ROM中视频文件的快速随机播放，播放性能最好的文件数据块组织方式是（）。 [x] 连续结构 [ ] 链式结构 [ ] 直接索引结构 [ ] 多级索引结构 视频文件属于有结构文件中的定长记录文件，适合用连续分配来组织，连续分配的优点主要有顺序访问容易，顺序访问速度快。为了实现快速随机播放，要保证最短时间查询，不宜选取链式和索引结构。 【2013年统考真题】若某文件系统索引节点（inode）中有直接地址项和间接地址项，则下列选项中，与单个文件长度无关的因素是（）。 [x] 索引节点的总数 [ ] 间接地址索引级数 [ ] 地址项的个数 [ ] 文件块大小 一个文件对应一个索引节点，索引节点的总数只能说明有多少个文件，跟单个文件的长度没有关系。而间接地址索引的级数、地址项的个数和文件块大小都跟单个文件长度相关。 【燕山大学，2006年】在磁盘上容易导致存储碎片的物理文件结构式（）。 [ ] 链接 [x] 连续 [ ] 索引 [ ] 索引和链接 连续文件的优点是在顺序存取时速度较快。存在如下缺点：1要求建立文件时就确定它的长度，2不便于文件的动态扩充。3可能出现外部碎片，就是在存储介质上存在很多空闲块，但不连续，无法被连续文件使用。 【南昌大学，2006年】采用直接存取法来读写磁盘上的物理记录时，效率最高的是（）。 [x] 连续结构的文件 [ ] 索引结构的文件 [ ] 链接结构文件 [ ] 其它结构文件 在直接存取法下，连续文件只要知道文件在存储设备上的起始地址和文件长度，就能很快的进行存取。适合随机存取的程度总结为：连续>索引>链接。 多选题 按用途分类，文件主要能分为（） [x] 系统文件 [ ] 档案文件 [x] 用户文件 [x] 库文件 按用途 ：　 系统文件、库文件、用户文件 按保护级别 ：　 可执行文件、只读文件、读写文件 按信息流向： 　 输入文件、输出文件、输入输出文件 按存放时限： 　 临时文件、永久文件、档案文件 按设备类型：　 磁盘文件、磁带文件、卡片文件、打印文件 按文件组织结构：逻辑文件、物理文件（顺序文件、链接文件、索引文件） 允许多个用户同时使用同一个共享文件时，下列（）做法是正确的。 [x] 允许多个用户同时打开共享文件执行读操作 [ ] 允许读者和写者同时使用共享文件 [x] 不允许读者和写者同时使用共享文件 [x] 不允许多个写者同时对共享文件执行写操作 进行文件读写要保持文件的正确性，所以不能进行同时读写，多个同时写等操作。 文件系统的功能有（） [x] 文件系统实现对文件的按名存取 [x] 负责实现数据的逻辑结构到物理结构的转换 [ ] 提高磁盘的读写速度 [x] 提供对文件的存取方法和对文件的操作 文件系统的功能主要有：1、管理文件的存储介质 2、实现文件名到物理地址的映射 3、提供用户对文件和目录的操作命令 4、 提供用户共享文件机制 5、提供文件存取机制，保证文件安全性。 文件的物理结构可分为（） [x] 顺序结构 [x] 链表结构 [x] 索引结构 [ ] 目录结构 文件的物理结构 ：由文件系统在存储介质上的文件构造方式称为文件的物理结构。不论用户看来是什么文件，在存储介质上存储时，按何种构造方式记录呢，因为介质上的存储单位是物理块，那么这些物理快是顺序存放，还是链式结构，或者索引结构，都要由文件系统结构来实现。 从对文件信息的存取次序考虑，存取方法可分为（）。 [x] 顺序存取 [x] 随机存取 [ ] 索引存取 [ ] 连续存取 文件的存取方式有顺序存取和随机存取两种。磁带上的文件只能顺序存取，磁盘上的文件既可采用顺序方式也可用随机方式存取。 "},"all/09-1-quiz.html":{"url":"all/09-1-quiz.html","title":"lec21 在线练习","keywords":"","body":"lec21 文件系统　在线练习 选择题 关于文件系统功能的阐述正确的是（） s1 [x] 负责数据持久保存 [x] 文件分配 [x] 文件管理 [x] 数据可靠和安全 都对 打开文件时，文件系统要维护哪些信息（） s２ [x] 文件指针 [x] 打开文件计数 [x] 文件访问权限 [x] 文件位置和数据缓存 都是 关于目录和别名的阐述正确的是（）s3 [x] 目录是一类特殊的文件 [x] 目录的内容是文件索引表 [x] 可通过硬链接机制实现文件别名 [x] 可通过软链接机制实现文件别名 都对 虚拟文件系统可支持的具体文件系统包括（） s4 [x] 磁盘文件系统 [x] 设备文件系统 [x] 网络文件系统 [x] 系统状态文件系统（proc...） 都对 关于文件缓存和打开文件的阐述正确的是（） s5 [x] 打开文件后，可通过把文件数据块按需读入内存来减少IO操作次数 [x] 文件数据块使用后被缓存在内存中，可用于再次读写，从而减少IO操作次数 [x] 在虚拟地址空间中虚拟页面可映射到本地外存文件中，这样访问文件就像访问内存一样 [ ] 多个进程打开同一文件进行读写访问不需要用锁机制进行互斥保护 文件是共享资源，对于写操作需要互斥保护 关于文件分配的阐述正确的是（） s6 [x] 连续分配会产生外碎片 [ ] 链式分配会产生外碎片 [ ] 索引分配会产生外碎片 [x] 多级索引分配可支持大文件 链式分配和索引分配不会产生外碎片 关于冗余磁盘阵列(RAID, Redundant Array of Inexpensive Disks)的阐述正确的是（） s7 [x] 采用RAID机制可提高磁盘IO的吞吐量(通过并行) [x] 采用RAID机制可提高磁盘IO的可靠性和可用性 (通过冗余) [ ] 采用RAID-0可提高磁盘IO的可靠性和可用性 [ ] 采用RAID-1可提高磁盘IO的吞吐量 RAID-0提高并行性，RAID-1提高可靠性 "},"all/09-1-spoc-discussion.html":{"url":"all/09-1-spoc-discussion.html","title":"lec21 SPOC讨论","keywords":"","body":"lec 21: 文件系统 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。 视频相关思考题 21.1 文件系统和文件 文件系统的功能是什么？ 负责数据持久保存，功能是数据存储和访问 具体功能：文件分配、文件管理、数据可靠和安全 什么是文件、文件属性、文件头？ 文件：文件系统中具有符号名，由字节序列构成的数据项集合。 文件属性：文件系统中保存的与文件相关的属性信息，如文件名、文件访问权限、文件访问时间等。 文件头：文件系统元数据中的文件信息，如文件存储位置等。 文件系统和内存管理在功能和实现算法上有什么异同？ 相同：数据保存、分配、释放 不同：数据保存的持久性、管理的数据量大小、数据可靠性、数据访问安全性、服务对象、服务接口 21.2 文件描述符 打开文件时，文件系统要维护哪些信息？ 打开文件的状态和信息：文件指针、打开文件计数、访问权限、文件的磁盘存储位置和文件数据缓存 文件系统的基本数据访问单位是什么？这对文件系统有什么影响？ 文件是文件系统的基本数据访问单位； 文件访问时操作系统维护的文件描述符信息是对应文件的； 文件的索引访问有什么特点？如何优化索引访问的速度？ 文件的索引访问是，先访问索引，以确定要访问的文件位置；再读写文件内容。 文件索引的访问频率远大于文件内容读写。 优化方法：文件的索引信息和文件内容分别保存在不同的数据块。 文件访问方式有哪几种？文件访问方式对文件系统的设计有什么影响？ 文件访问方式：顺序访问、随机访问、索引访问 文件访问特征对文件系统的要求会影响文件系统存储组织和操作系统中文件系统模块的实现方法选择； 21.3 目录、文件别名和文件系统种类 什么是目录？ 由文件索引项组成的特殊文件。 目录的组织结构是什么样的？ 树结构（分层文件系统）、有向图 目录操作有哪些种类？ 目录读操作：搜索、遍历、列目录 目录写操作：创建、删除、重命名 什么是文件别名？软链接和硬链接有什么区别？ 文件别名：两个或多个文件关联同一个文件； 硬链接：多个文件目录项指向一个文件； 软链接：文件内容是指向文件的路径； 硬链接和软链接的文件删除操作的语义是不同的； 路径遍历的流程是什么样的？如何优化路径遍历？ 路径遍历：从根目录开始，读取路径包含的每一级目录，查找下一级目录项和存储位置，直到最后一级； 路径遍历的优化：目录缓存和当前目录； 什么是文件系统挂载？ 文件系统挂载（mount）：把一个文件卷（文件系统）映射到系统根文件系统的某个挂载目录节点； 为什么会存在大量的文件系统类型？ 数据类型：16位、32位、64位、128位文件系统 存储介质类型：磁盘、光盘等 访问安全要求类型：单用户文件系统、多用户文件系统 数据可靠性要求类型：日志文件系统 应用场景类型：网络、本地 在UFS文件系统中允许创建指向父辈目录（即从根目录到当前目录的路径上的目录）的软链接或硬链接，从而在目录树中形成循环结构。这会影响到目录查找和遍历相关的操作。请尝试给出一种在允许循环目录结构的文件系统中遍历操作的影响的解决方法，并有Linux或ucore上进行实现。 一种可能的解法：在遍历的过程中检查重复的目录，并终止该分支的遍历操作。 21.4 虚拟文件系统 虚拟文件系统的功能是什么？ 对上接口：统一上层应用的文件访问和控制接口 对下接口：实现对多种类型文件的访问和控制交互； 高效访问实现：打开文件信息的管理、高效的路径遍历实现 文件卷控制块、文件控制块和目录项的相互关系是什么？ 文件卷控制块：文件系统描述信息，如数据块大小、存储格式、空余块数目等；每个文件卷对应一个；挂载时读入内存； 文件控制块：文件的描述信息，如文件数据的存储位置和顺序等；每个文件对应一个；打开文件时读入内存； 目录项：每个目录由若干目录项组成，所有目录项共同形成文件系统的树状结构；每个目录项对应一个文件或目录；路径遍历时读入内存； 可以把文件控制块放到目录项中吗？这样做有什么优缺点？ 可以。 优点：实现简单； 缺点：搜索时的数据读入量比较大； 21.5 文件缓存和打开文件 虚拟存储和文件缓存有什么区别和联系？ 联系：虚拟存储和文件缓存同时用到物理内存，占用的内存空间是相互影响的 区别：虚拟存储是用外存来模拟内存、文件缓存是用内存来模拟外存 文件的数据块缓存和页缓存有什么区别和联系？ 联系：物理内存空间的分配 区别：数据缓存是把页面访问映射到数据块访问、页缓存是把文件访问映射到页面访问 为什么要同时维护进程的打开文件表和操作系统的打开文件表？这两个打开文件表有什么区别和联系？为什么没有线程的打开文件表？ 系统打开文件表：目录项和文件控制块信息的缓存、引用计数等 进程打开文件表：进程的打开文件的状态信息，如文件指针、文件访问权限等 联系：针对打开文件在内存中维护的数据缓存和文件状态信息 区别：进程打开文件表维护本进程特有的打开文件状态信息，系统打开文件表维护所有进程共用的打开文件信息； 相同进程中的各线程共享进程的打开文件信息，并没有需求针对线程维护打开文件状态信息； 21.6 文件分配 文件分配的三种方式是如何组织文件数据块的？各有什么特征（存储、文件读写、可靠性）？ 连续分配：文件数据块的存储是连续的；特征：存储位置必须在大于所需空间的空闲空间；读取性能比较好，文件增长开销比较大； 链式分配：用数据块的链表来存储文件数据块；特征：文件修改比较方便，随机文件读取开销大，可靠性比较差； 索引分配：用索引数据块来保存文件数据块的存储位置和顺序；特征：小文件存储开销大；文件读写性能较好； UFS多级索引分配是如何组织文件数据块的位置信息的？ 多种文件分配方式综合使用：直接索引、一级索引、二级索引、三级索引都可能使用； 21.7 空闲空间管理和冗余磁盘阵列RAID 硬盘空闲空间组织和文件分配有什么异同？ 空闲空间组织不需要管顺序，而文件分配需要维护占用数据块的顺序 都需要维护管理有数据块有哪些 RAID-0、1、4和5分别是如何组织磁盘数据块的？各有什么特征？ 条带化：在多个独立硬盘上存储数据块，通过并行读写提高I/O性能； 校验和：按位做校验、按块做校验 实现方式：硬件、软件 RAID-0：条带化 RAID-1：镜像 RAID-4：带校验的磁盘条带化 RAID-5：带分布式校验的磁盘条带化 小组思考题 (spoc)完成Simple File System的功能，支持应用程序的一般文件操作。具体帮助和要求信息请看sfs-homework (spoc)FAT、UFS、YAFFS、NTFS这几种文件系统中选一种，分析它的文件卷结构、目录结构、文件分配方式，以及它的变种。 wikipedia上的文件系统列表参考 http://en.wikipedia.org/wiki/List_of_file_systems http://en.wikipedia.org/wiki/File_system http://en.wikipedia.org/wiki/List_of_file_systems 往届同学的参考回答： FAT文件系统分析 NTFS文件系统分析 UFS文件系统分析 ZFS文件系统分析 YAFFS文件系统分析 "},"all/09-2-lab8-quiz.html":{"url":"all/09-2-lab8-quiz.html","title":"lec22-lab8 在线练习","keywords":"","body":"lec22 lab8 文件系统　在线练习 选择题 ucore实现的文件系统抽象包括（） s1 总体介绍 [x] 文件 [x] 目录项 [x] 索引节点 [x] 安装点 都是 ucore实现的simple FS（简称SFS）采用的文件分配机制是（） s2 ucore 文件系统架构 [ ] 连续分配 [ ] 链式分配 [x] 索引分配 [ ] 位图分配 索引分配 关于ucore实现的SFS阐述正确的是（） s3 Simple File System分析 [x] SFS的超级块保存在硬盘上，在加载simple FS时会读入内存中 [x] SFS的free map结构保存在硬盘上，表示硬盘可用的数据块（扇区） [x] SFS的root-dir inode结构保存在硬盘上，表示SFS的根目录的元数据信息 [ ] 硬盘上的SFS ，除保存上述三种结构外，剩下的都用于保存文件的数据内容 除了前三种结构，剩下的用于保存文件的inode, dir/file的data 关于ucore实现的Virtual FS（简称VFS）阐述正确的是() s4 Virtual File System分析 [x] 已支持磁盘文件系统 [x] 已支持设备文件系统 [ ] 已支持网络文件系统 [ ] 已支持系统状态文件系统 后两种可实现，但现在还没实现 关于ucore文件系统支持的I/O 设备包括() s5 I/O 设备接口分析 [x] 串口设备 [x] 并口设备 [x] CGA设备 [x] 键盘设备 都支持 "},"all/09-2-lab8-spoc-discussion.html":{"url":"all/09-2-lab8-spoc-discussion.html","title":"lec22-lab8 SPOC讨论","keywords":"","body":"lec 22: lab8 文件系统 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。视频相关思考题 22.1 总体介绍 与文件系统相关的系统调用接口、虚拟文件系统VFS、简单文件系统SFS和设备I/O等四个部分各实现什么功能？ 系统调用接口：向应用进程提供文件访问的系统调用； 虚拟文件系统VFS：屏蔽具体文件系统差异，对上提供一个统一的文件系统访问接口； 简单文件系统SFS：解析和读写磁盘数据块中具体的SFS文件系统存储结构 设备I/O：完成实际磁盘设备上数据块的访问； 文件系统中的文件、目录、索引节点(inode)和安装点(挂载点)这几种数据结构分别支持些什么操作？ 文件：open/close, read/write 目录：open/close, read 索引节点：lookup, read/write 挂载点：mount/unmount 22.2 ucore 文件系统架构 请简要阐述ucore 文件系统架构的四个组成部分 系统调用接口：用户应用使用封装后的libc库函数，文件访问的libc库函数利用文件访问系统调用来实现； VFS：内核的系统调用（文件、目录接口）会转换成对VFS抽象的文件访问接口（索引节点、文件卷、设备等接口）的调用，VFS再把抽象的VFS接口转换成具体的文件系统SFS的访问接口； SFS：利用具体文件系统存储结构的解析，把SFS对上接口（索引节点、文件卷、设备等接口）的访问请求转换成设备数据块的访问； I/O接口：不同具体设备上的数据块访问控制； 请简要说明进程proc_struct、文件file、inode之间的关系。 进程控制块数据结构proc_struct中，struct files_struct *filesp指向进程的打开文件表； 进程打开文件表中struct file *file指向系统打开文件中的相应文件状态数据； VFS中的系统打开文件表中struct inode *inode维护打开文件的状态信息，并最终对应到磁盘上的存储数据块； ucore中的进程打开文件表和系统打开文件表对应到具体的哪个数据结构上？ kern-ucore/fs/vfs/inode.h struct inode: union in_info 22.3 Simple File System分析 SFS在硬盘上的四大部分主要是什么，有何作用？ superblock：数据块大小、文件卷名字等文件卷信息 root-dir inode：根目录的inode信息（存储位置等） freemap：数据块占用状态信息 data block：目录和文件的信息 硬盘上的SFS是如何加载到ucore中并初始化的？ sfs_do_mount() 硬盘上的inode和内存中的inode的关系和区别是什么? 内存中的inode数据结构sfs_inode中有一个字段sfs_disk_inode，它对应磁盘上的inode； 描述file, dir, inode在内存和磁盘上的格式和相关操作。 每一种类型的数据块都在SFS层中有对应的操作函数指针和数据结构定义； 22.4 Virtual File System分析 file数据结构的主要内容是什么？与进程的关系是什么？ struct file数据结构的内容：文件状态、文件操作类型、文件指针、对应系统打开文件表项指针等； struct file就是进程打开文件表对应的数据结构； inode数据结构的主要内容是什么？与file的数据结构的关系是什么？ struct inode数据结构的内容：文件类型、引用计数、对下具体文件操作函数指针、对上inode操作函数指针 struct inode就是系统打开文件表对应的数据结构； inode_ops包含哪些与文件相关的操作？ open, close, read, write, getdirentry, create, lookup VFS是如何把键盘、显示输出和磁盘文件统一到一个系统调用访问框架下的？ VFS把键盘、显示和磁盘文件都视为文件，VFS对上提供的访问接口都是文件访问接口； VFS通过区别文件类型、文件操作类型、设备类型等来区别同类操作在不同设备的不同实现； 22.5 I/O 设备接口分析 device数据结构的主要内容是什么？与fs的关系是什么？与inode的关系是什么？ struct device数据结构的内容：数据块大小、设备操作函数指针（d_open, d_close, d_io, d_ioctl） fs和inode通过device数据结构中的设备操作函数指针实现对设备数据块的访问； 比较ucore中I/O接口、SFS文件系统接口和文件系统的系统调用接口的操作函数有什么异同？ 文件系统的系统调用接口：sys_open, sys_close, sys_read, sys_write, sys_seek, sys_fstat, sys_fsync, sys_chdir, sys_getcwd, sys_mkdir, sys_link, sys_rename, sys_unlink, sys_getdirentry, sys_dup, sys_pipe, sys_mkfifo, sys_mount, sys_umount, sys_ioctl VFS文件系统接口：vfs_open, vfs_close, vfs_link, vfs_symlink, vfs_readlink, vfs_mkdir, vfs_unlink, vfs_rename, vfs_chdir, vfs_getcwd SFS文件系统接口：sfs_rblock, sfs_wblock, sfs_rbuf, sfs_wbuf, sfs_sync_super, sfs_sync_freemap, sfs_clear_block, sfs_load_inode I/O接口：d_open, d_close, d_io, d_ioctl 22.6 执行流程分析 (spoc) 理解文件访问的执行过程，即在ucore运行过程中通过cprintf函数来完整地展现出来读一个文件在ucore中的整个执行过程，(越全面细致越好) 完成代码填写，并形成spoc练习报告，需写练习报告和简单编码，完成后放到git server 对应的git repo中。 小组思考题 （spoc） 在下面的实验代码的基础上，实现基于文件系统的pipe IPC机制 练习用的lab8 spoc exercise project source code "},"all/13-io.html":{"url":"all/13-io.html","title":"I/O子系统","keywords":"","body":"I/O子系统 单项选择题 在操作系统中，用户在使用I/O设备时，通常采用（）。 [ ] 物理设备名 [x] 逻辑设备名 [ ] 虚拟设备名 [ ] 设备号 用户程序提出使用设备申请时，使用系统规定的设备类型号和自己规定的设备相对号（即逻辑设备名）由操作系统进行地址转换，变成系统的设备绝对号（物理设备号）。 操作系统中采用缓冲技术的目的是为了增强系统（）的能力。 [ ] 串行操作 [ ] 控制操作 [ ] 重执操作 [x] 并行操作 为了提高CPU和设备之间的并行程度。 操作系统采用缓冲技术，能够减少对CPU的（）次数，从而提高资源的利用率。 [x] 中断 [ ] 访问 [ ] 控制 [ ] 依赖 I/O中断：是指中央处理器和通道协调工作的一种手段。通道借助I/O中断请求CPU进行干预，CPU根据产生的I/O中断事件了解输入输出操作的执行情况，I/O中断事件是由于通道程序的执行或其他外界原因引起的，采用缓冲技术可以减少CPU中断。 CPU输出数据的速度远远高于打印机的打印速度，为了解决这一矛盾，可采用（）。 [ ] 并行技术 [ ] 通道技术 [x] 缓冲技术 [ ] 虚存技术 在设备I/O中引入缓存技术是为了改善CPU与设备I/O直接速度不匹配的矛盾。 缓冲技术用于（）。 [x] 提高主机和设备交换信息的速度 [ ] 提供主、辅存接口 [ ] 提高设备利用率 [ ] 扩充相对地址空间 在设备I/O中引入缓存技术是为了改善CPU与设备I/O直接速度不匹配的矛盾。 通道是一种（）。 [ ] I/O端口 [ ] 数据通道 [x] I/O专用处理机 [ ] 软件工具 通道：计算机系统中能够独立完成输入输出操作的硬件装置，也称为“输入输出处理机”，能接收中央处理机的命令，独立执行通道程序，协助中央处理机控制与管理外部设备。一个独立于CPU的专门I/O控制的处理机，控制设备与内存直接进行数据交换。 设备管理的主要程序之一是设备分配程序，当进程请求在内存和外设之间传送信息时，设备分配程序分配设备的过程通常是（）。 [x] 先分配设备，再分配控制器，最后分配通道 [ ] 先分配控制器，再分配设备，最后分配通道 [ ] 先分配通道，再分配设备，最后分配控制器 [ ] 先分配通道，再分配控制器，最后分配设备 主机对外部设备的控制可分为四个层次：主机、通道、控制器、设备。所以，设备分配过程是先设备、在分控制器、最后是通道。 下列描述中，不是设备管理的功能的是（）。 [ ] 实现外围设备的分配与回收 [ ] 缓冲管理与地址转换 [x] 实现按名存取 [ ] 实现I/O操作 设备管理的功能有：1、缓冲管理。为达到缓解CPU和I/O设备速度不匹配的矛盾，达到提高CPU和I/O设备利用率，提高系统吞吐量的目的，许多操作系统通过设置缓冲区的办法来实现。2、设备分配。设备分配的基本任务是根据用户的I/O请求，为他们分配所需的设备。如果在I/O设备和CPU之间还存在设备控制器和通道，则还需为分配出去的设备分配相应的控制器和通道。3、设备处理。设备处理程序又称设备驱动程序。其基本任务是实现CPU和设备控制器之间的通信。4、设备独立性和虚拟设备。用户向系统申请和使用的设备与实际操作的设备无关。 按名存取是文件管理的功能。 用户编制的程序与实际使用的物理设备无关是由（）功能实现的。 [ ] 设备分配 [ ] 设备驱动 [ ] 虚拟设备 [x] 设备独立性 设备独立性是设备管理要达到的目的之一，就是，用户程序应与实际使用的物理设备无关，由操作系统来考虑因实际设备不同使用不同的驱动等问题。采用“设备类、相对号”方式使用设备时，用户编程就不必指定特定设备，在程序中由“设备类、相对号”定义逻辑设备。程序执行时由系统根据用户指定的逻辑设备转换成与其对应的具体物理设备。所以，用户编程时使用的设备与实际使用哪台设备无关，这就是“设备独立性” SPOOLing技术利用于（）。 [ ] 外设概念 [x] 虚拟设备概念 [ ] 磁带概念 [ ] 存储概念 SPOOLing技术有3个特点：(1)提高了I/O速度。从对低速I/O设备进行的I/O操作变为对输入井或输出井的操作,如同脱机操作一样,提高了I/O速度,缓和了CPU与低速I/O设备速度不匹配的矛盾。(2)设备并没有分配给任何进程。在输入井或输出井中,分配给进程的是一存储区和建立一张I/O请求表。(3)实现了虚拟设备功能。多个进程同时使用一个独享设备,而对每一进程而言,都认为自己独占这一设备,从而实现了设备的虚拟分配。不过,该设备是逻辑上的设备。 【2010年计算机联考真题】本地用户通过键盘登陆系统时，首先获得键盘输入信息的程序是（）。 [ ] 命令解释程序 [x] 中断处理程序 [ ] 系统调用服务程序 [ ] 用户登陆程序 键盘是典型的通过中断I/O方式工作的外设，当用户输入信息时，计算机响应中断并通过中断处理程序获得输入信息。 【2011年计算机联考真题】操作系统的I/O子系统通常有4个层次组成，每一层明确定义了与邻近层次的接口，其合理的层次组织排列顺序是（）。 [x] 用户级I/O软件、设备无关软件、设备驱动程序、中断处理程序 [ ] 用户级I/O软件、设备无关软件、中断处理程序、设备驱动程序 [ ] 用户级I/O软件、设备驱动程序、设备无关软件、中断处理程序 [ ] 用户级I/O软件、中断处理程序、设备无关软件、设备驱动程序 设备管理软件一般分为四个层次：用户层、与设备无关的软件层、设备驱动程序以及中断处理程序。 【2013年计算机联考真题】用户程序发出磁盘I/O请求后，系统的处理流程是：用户程序-系统调用处理程序-设备驱动程序-中断处理程序。其中，计算数据所在磁盘的柱面号、磁头号、扇区号的程序是（）。 [ ] 用户程序 [ ] 系统调用处理程序 [x] 设备驱动程序 [ ] 中断处理程序 计算数据所在磁盘的柱面号、磁头号、扇区号的工作是由设备驱动程序完成的。题中的功能因设备硬件的不用而不同，因此应有厂家提供的设备驱动程序完成。 【2011年计算机统考真题】某文件占用10个磁盘块，现在要把该文件磁盘块逐个读入主缓冲区，并送用户区进行分析。假设一个缓冲区与一个磁盘块大小相同，把一个磁盘块读入缓冲区的时间为100μs，将缓冲区的数据传送到用户区的时间是50μs，CPU对一块数据进行分析的时间为50μs。在单缓冲区和双缓冲区结构下，读入并分析完该文件的时间分别是（）。 [ ] 1500μs，1000μs [x] 1550μs，1100μs [ ] 1550μs，1550μs [ ] 2000μs，2000μs 单缓冲区下，当上一个磁盘块从缓冲区读入用户区完成时下一磁盘块才能开始读入，所以当最后一块磁盘块读入用户区完毕时，所用时间为１５０×１０＝１５００，加上处理最后一个磁盘块的cpu处理时间５０为１５５０.双缓冲区下，读入第一个缓冲区之后可以立刻开始读入第二个缓冲区，读完第二个缓冲区之后，第一个缓冲区的数据已经传送到用户区，因此不存在等待磁盘块从缓冲区读入用户区的问题，也就是１００×１０＝１１００，再加上最后一个缓冲区的数据传输到用户区并有CPU处理的时间50+50=100，总的时间是1000+100=1100。 【2005年，北京理工大学】（）是操作系统中采用的以空间换取时间的技术。 [x] Spooling技术 [ ] 虚拟存储技术 [ ] 覆盖与交换技术 [ ] 通道技术 SPOOLing技术是操作系统中采用的以空间换取时间的技术；虚拟存储技术和覆盖交换技术是为了扩充内存容量，是以时间换空间技术；通道技术是为了提高设备速度, 增加了硬件，不属于这两者的任何一个。 【2012年统考真题】下列选项中，不能改善磁盘设备I/O性能的是（）。 [ ] 重排I/O请求次序 [x] 在一个磁盘上设置多个分区 [ ] 预读和滞后写 [ ] 优化文件物理的分布 重排I/O请求次序就是将磁盘请求访问序列进行重新排序，就是有关磁盘访问调度策略的选择对I/O有性能的影响，不同的调度策略有不同的寻道时间;磁盘分区实质上就是对磁盘的一种格式化。但磁盘设备I/O性能是由调用顺序和磁盘本身性质决定的，和分区的多少无太大关系，如果设置过多分区，还会导致一个I/O需要启动多个分区，反而会减低效率;预读和滞后写是常见的提升磁盘设备I/O速度的方法，具有重复性及阵发性的I/O进程和改善磁盘I/O性能很有帮助;优化文件物理块的分布可以减少寻找时间与延迟时间，从而提高磁盘性能。 【2009年全国统考】假设磁头当前位于第105道，正在向磁道序号增加的方向移动。现有一个磁道访问请求序列为35，45，12，68，110，180，170，195，采用SCAN调度（电梯调度）算法得到的磁道访问序列是() [x] 110，170，180，195，68，45，35，12 [ ] 110，68，45，35，12，170，180，195 [ ] 110，170，180，195，12，35，45，68 [ ] 12，35，45，68，110，170，180，195 SCAN调度算法就是电梯调度算法，顾名思义就是如果开始时磁头往外就一直要到最外面，然后再返回向里（磁头编号一般是最外面为0号往里增加），就像电梯若往下则一直要下到最底层才会再上升一样。 【西安电子科技大学，2000年】在关于SPOOLing的叙述中，（）描述不正确。 [ ] SPOOLing系统必须使用独占设备 [ ] SPOOLing系统加快了作业执行的速度 [ ] SPOOLing系统使独占设备变成共享设备 [x] SPOOLing系统利用了处理器与通道并行工作的能力 SPOOLing是操作系统中采用的一种将独占设备改造为共享设备的技术，它有效减少了进程等待读入读出信息的时间，加快了作业执行的速度。不过，无论有没有通道，SPOOL系统都可以运行，因此4选项不对。 【河北大学】系统设备是通过一些数据结构来进行的，下面的（）不属于设备管理数据结构。 [x] FCB [ ] DCT [ ] SDT [ ] COCT FCB是文件控制块，与设备管理无关。DCT是设备控制表，SDT是系统设备表，COCT控制器控制表，这3者都死设备管理中的重要数据结构。 【电子科技大学】 不属于DMA控制器的是（） [ ] 命令/状态寄存器 [ ] 内存寄存器 [ ] 数据寄存器 [x] 堆栈指针寄存器 DMA控制器与CPU的接口有3类信号线：数据线、地址线和控制线。通常与：数据寄存器、命令/状态寄存器两类寄存器相连。为了将数据送到内存，DMA控制器还需要内存地址寄存器。 "},"all/10-1-quiz.html":{"url":"all/10-1-quiz.html","title":"lec23 在线练习","keywords":"","body":"lec23: IO设备　在线练习 选择题 字符设备包括（） s1 [x] 键盘 [x] 鼠标 [x] 并口 [x] 串口 都是 块设备包括（） s1 [x] 硬盘 [x] 软盘 [x] 光盘 [x] U盘 都是 网络设备包括（） s1 [x] 以太网卡 [x] wifi网卡 [x] 蓝牙设备 [ ] 网盘设备 网盘在模拟实现上应该算块设备 关于CPU与设备的通信方式包括（） s2 [x] 轮询 [x] 设备中断 [x] DMA [ ] PIPE PIPE是用于进程间通信 关于IO数据传输的阐述正确的是（） s3 [x] 程序控制I/O(PIO, Programmed I/O)通过CPU的in/out或者load/store传输所有数据 [x] DMA设备控制器可直接访问系统总线并直接与内存互相传输数据 [ ] DMA机制适合字符设备 [ ] PIO机制适合块设备 DMA机制适合块设备，PIO机制适合简单，低速的字符设备等 常用移臂调度算法包括（） s4 磁盘调度 [x] 先来先服务（FIFO）算法 [x] 最短寻道时间优先（SSTF）算法 [x] 电梯调度（SCAN）算法 [x] 单向扫描（C-SCAN）算法 都对 在设备管理子系统中，引入缓冲区的目的主要有() s5 缓冲区 [x] 缓和CPU与I/O设备间速度不匹配的矛盾 [x] 减少对CPU的中断频率，放宽对CPU中断响应时间的限制 [x] 解决基本数据单元大小（即数据粒度）不匹配的问题 [x] 提高CPU和I/O设备之间的并行性 都对 "},"all/10-1-spoc-discussion.html":{"url":"all/10-1-spoc-discussion.html","title":"lec23 SPOC讨论","keywords":"","body":"lec 23: IO设备 spoc 思考题 有\"spoc\"标记的题是要求拿清华学分的同学在实体课上完成的，对于学堂在线的选课同学是可选题目。视频相关思考题 23.1 IO特点 字符设备的特点是什么？ 以字节为单位顺序访问 块设备的特点是什么？ 以均匀的数据块为单位随机访问 网络设备的特点是什么？ 以格式化报文为单位的复杂交互访问 阻塞I/O、非阻塞I/O和异步I/O这三种I/O方式有什么区别？ 阻塞I/O：数据读写操作后，进程将进入等待状态，直到完成操作时返回； 非阻塞I/O：数据读写操作后，进程将立即返回； 异步I/O：数据读写操作后，进程将立即返回；内核在完成操作时通知进程； 区别：进程发出操作命令后，进程是否等待；操作结果反馈方式； 23.2 I/O结构 请描述I/O请求到完成的整个执行过程。 CPU通过总线与设备相连；CPU通过主动的I/O端口和映射内存读写操作与设备进行信息交互；设备通过中断请求来响应CPU的操作；在CPU的控制下，DMA可直接在设备接口与内存间的数据传输。 进程通过系统调用发送对设备的抽象操作命令；内核把抽象的设备操作命令转换成具体的设备I/O端口和映射内存读写序列，并在设备驱动中实施读写操作；当这个读写序列较长时，CPU会控制DMA进行内存与设备接口的直接数据传送；设备在收到控制序列后，执行操作动作，并在完成时向CPU发出中断请求；CPU通过中断服务例程响应设备的中断请求，并进行后续处理，直到系统调用返回，从而完成整个I/O操作过程。 23.3 IO数据传输 IO数据传输有哪几种？ 程序控制I/O：CPU通过显式的IO指令，如x86的in, out；或者memory读写方式，即把device的寄存器，内存等映射到物理内存中； 直接内存访问DMA：在CPU的控制下，DMA控制器直接在内存与设备接口间传输数据； 轮询方式的特点是什么？ CPU定期检测设备状态 实现简单 持续占用CPU 中断方式的特点是什么？ 设备执行操作命令时，CPU可执行其他任务； 处理不可预测事件效果好 频繁的中断响应开销比较大 DMA方式的特点是什么？ 直接在内存与设备接口间进行数据传输 合适高速和简单的数据传输 CPU的开销小 23.4 磁盘调度 请简要阐述磁盘的工作过程。 磁头移动、盘片旋转 请描述磁盘I/O操作时间组成。 等待设备可用时间 等待通道可用时间 寻道时间 旋转延时 数据传送时间 请说明磁盘调度算法的评价指标。 总的I/O时间开销、公平性 请描述FIFO、SSTF、SCAN、CSCAN、LOOK、C-LOOK、N-step-SCAN和FSCAN等磁盘调度算法的工作原理。 磁盘调度算法就是优化磁盘数据块的访问顺序； 先进先出(FIFO)磁盘调度算法：按请求顺序访问 最短寻道时间优先(SSTF)磁盘调度算法：从当前位置找当前最近的访问数据块位置 扫描(SCAN)磁盘调度算法：保持磁头移动方向到最远处，并顺序访问需要访问的数据块 循环扫描(C-SCAN)磁盘调度算法：只在一个方向上移动时访问数据的SCAN算法； LOOK磁盘调度算法：保持磁头移动方向到已有的最后一个请求，并顺序访问需要访问的数据块 C-LOOK磁盘调度算法：只在一个方向上移动时访问数据的LOOK算法； N步扫描(N-step-SCAN)磁盘调度算法：1）将磁盘请求队列分成长度为N的子队列；2）按FIFO算法依次处理所有子队列；3）按扫描算法处理每个队列 双队列扫描(FSCAN)磁盘调度算法：1）把磁盘I/O请求分成两个队列，交替使用扫描算法处理一个队列；2）新生成的磁盘I/O请求放入另一队列中 23.5 磁盘缓存 磁盘缓存的作用是什么？ 磁盘扇区在内存中的缓存区，作用是通过缓存访问，减少磁盘访问； 请描述单缓存(Single Buffer Cache)的工作原理 只一个缓存区，用户进程和I/O设备只能交替访问缓存区； 请描述双缓存(Double Buffer Cache)的工作原理 设置两个缓存区，任何时刻用户进程和I/O设备可同时访问不同的缓存区； 请描述访问频率置换算法(Frequency-based Replacement)的基本原理 思路：短周期内采用LRU，长周期内采用LFU 做法：把栈分成三个区域：新区域、中间区域、旧区域 新区域中数据块的引用，不计数； 中间区域和旧区域中数据块的引用，引用计数加1； 淘汰只在旧区域中找引用计数最小的数据块 小组思考题 (spoc)请以键盘输入、到标准输出设备stdout的printf输出、串口输出、磁盘文件复制为例，描述ucore操作系统I/O从请求到完成的整个执行过程，并分析I/O过程的时间开销。 (spoc)完成磁盘访问与磁盘寻道算法的作业，然后实现CSCAN、LOOK、C-LOOK、FSCAN等磁盘调度算法中的一个。具体帮助和要求信息请看Chapter 37: Hard Disk Drives、disksim指导信息和disksim参考代码 "}}